{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "dataFrame_x = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataFrame_y = pd.DataFrame(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-96162a759acd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mydata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataFrame_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataFrame_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHAS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mxmesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoly1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "xdata = dataFrame_x['CHAS'][dataFrame_x['CHAS'] < 1].values\n",
    "ydata = dataFrame_y[dataFrame_x['CHAS'] < 1].values.flatten()\n",
    "\n",
    "xmesh = np.linspace(min(xdata), max(xdata), 50)\n",
    "\n",
    "fit = np.poly1d(np.polyfit(xdata, ydata, 1))\n",
    "\n",
    "plt.plot(xdata, ydata, 'bo', label='Data')\n",
    "plt.plot(xmesh, fit(xmesh), '-r', label='Fit')\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('CHAS', fontsize=18)\n",
    "plt.ylabel('Target',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from sklearn.datasets import load_boston \n",
    "from string import ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1a1acf0e1610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Boston housing dataset has {} data points with {} variables each.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Boston housing dataset has {} data points with {} variables each.\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (13, 506), indices imply (1, 506)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   4856\u001b[0m                 blocks = [make_block(values=blocks[0],\n\u001b[1;32m-> 4857\u001b[1;33m                                      placement=slice(0, len(axes[0])))]\n\u001b[0m\u001b[0;32m   4858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   3204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;34m'Wrong number of items passed {val}, placement implies '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 13, placement implies 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ef9749ace3db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'CHAS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 379\u001b[1;33m                                          copy=copy)\n\u001b[0m\u001b[0;32m    380\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[1;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   4864\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4865\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4866\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   4841\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4842\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 4843\u001b[1;33m         passed, implied))\n\u001b[0m\u001b[0;32m   4844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (13, 506), indices imply (1, 506)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(boston.data, columns = ['CHAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize = (16, 10))\n",
    "sns.heatmap(df.corr(), annot= True, cmap = 'RdYlGn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "x = df['NOX']\n",
    "y = df['target']\n",
    "plt.hist((x, normed=True, bins=30), (y, normed=True, bins=30))\n",
    "plt.ylabel('Nitric Oxides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "prices = df['target']\n",
    "features = df.drop('target', axis = 1)\n",
    "    \n",
    "# Success\n",
    "print(\"Boston housing dataset has {} data points with {} variables each.\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = np.amin(prices)\n",
    "\n",
    "# Maximum price of the data\n",
    "maximum_price = np.amax(prices)\n",
    "\n",
    "# Mean price of the data\n",
    "mean_price = np.mean(prices)\n",
    "\n",
    "# Median price of the data\n",
    "median_price = np.median(prices)\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(prices)\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for Boston housing dataset(in thousands):\\n\")\n",
    "print(\"Minimum price: ${:,.2f}\".format(minimum_price)) \n",
    "print(\"Maximum price: ${:,.2f}\".format(maximum_price))\n",
    "print(\"Mean price: ${:,.2f}\".format(mean_price))\n",
    "print(\"Median price ${:,.2f}\".format(median_price))\n",
    "print(\"Standard deviation of prices: ${:,.2f}\".format(std_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline# Calculate and show pairplot\n",
    "sns.pairplot(df, size=2.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np(boston['NOX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MEDV'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = df[['CHAS', 'RM', 'CRIM']]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = df['MEDV']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "#m.add(kr.layers.Dense(10, input_dim=3, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(30, input_dim=3, activation=\"sigmoid\"))\n",
    "m.add(kr.layers.Dense(13, input_dim=3, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(13, input_dim=3, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(13, input_dim=3, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(13, input_dim=3, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(13, input_dim=3, kernel_initializer=\"normal\", activation=\"relu\"))\n",
    "\n",
    "#m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.fit(inputs, output, epochs=100, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.around(m.predict(inputs).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.predict(inputs).T - output.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###difference between what the neuron is predicting and the actual values we told it to predict\n",
    "np.sqrt(np.sum((m.predict(inputs).T - output.as_matrix())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((m.predict(inputs).T - output.as_matrix())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MEDV'] = boston_dataset.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.iloc[:,0:13].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.iloc[:,13].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model asking for accuracy, too:\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y,\n",
    "     batch_size=5,\n",
    "     epochs=100,\n",
    "     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X, Y, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "l = len(Y)\n",
    "acc = sum([np.round(y_pred[i])==Y[i] for i in range(l)])/l\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training data : {train_data.shape}')\n",
    "print(f'Test data : {test_data.shape}')\n",
    "print(f'Training sample : {train_data[0]}')\n",
    "print(f'Training target sample : {train_targets[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(f'Processing fold # {i}')\n",
    "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "                            [train_data[:i * num_val_samples],\n",
    "                            train_data[(i+1) * num_val_samples:]],\n",
    "                            axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "                            [train_targets[:i * num_val_samples],\n",
    "                            train_targets[(i+1)*num_val_samples:]],\n",
    "                            axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data,\n",
    "              partial_train_targets,\n",
    "              epochs=num_epochs,\n",
    "              batch_size=1,\n",
    "              verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'all_scores : {all_scores}')\n",
    "print(f'mean all scores : {np.mean(all_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For neural networks.\n",
    "import keras as kr\n",
    "# For data frames.\n",
    "import pandas as pd\n",
    "# For numerical arrays.\n",
    "import numpy as np\n",
    "# For preprocessing data.\n",
    "import sklearn.preprocessing as pre\n",
    "# For splitting data sets.\n",
    "import sklearn.model_selection as mod\n",
    "# For whitening.\n",
    "import sklearn.decomposition as dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['MEDV'] = boston_dataset.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:13]\n",
    "y = df.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = mod.train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(20, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "m.add(kr.layers.Dense(20, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "m.add(kr.layers.Dense(1, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "m.add(kr.layers.Dense(20, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "m.add(kr.layers.Dense(1, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "m.add(kr.layers.Dense(20, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "m.add(kr.layers.Dense(1, activation=\"relu\", kernel_initializer='random_normal'))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(13,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the variable indicator with string\n",
    "new['CHAS'].replace(0, 'Not River Facing',inplace=True)\n",
    "new['CHAS'].replace(1, 'River Facing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For neural networks.\n",
    "import keras as kr\n",
    "# For data frames.\n",
    "import pandas as pd\n",
    "# For numerical arrays.\n",
    "import numpy as np\n",
    "# For preprocessing data.\n",
    "import sklearn.preprocessing as pre\n",
    "# For splitting data sets.\n",
    "import sklearn.model_selection as mod\n",
    "# For whitening.\n",
    "import sklearn.decomposition as dec\n",
    "from sklearn.datasets import load_boston #load the boston house proce index from the sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.iloc[:,0:13]\n",
    "y = boston.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston['MEDV'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.iloc[:,0:13] # assign all of the training data (with the exception of the target column)\n",
    "y = boston.iloc[:,13] # assign the last column as y (this is the target column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = mod.train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential() # build the lyer of the nueral netowrk up sequentially\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(20, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\")) # We only want 1 output\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"RMSprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-02573bd1eca6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = kr.models.Sequential() # build the lyer of the nueral netowrk up sequentially\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation='elu'))\n",
    "m.add(kr.layers.Dense(20, activation='relu'))\n",
    "m.add(kr.layers.Dense(1, activation='linear')) # We only want 1 output\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 961us/step - loss: 238.1632 - accuracy: 0.0085\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 223us/step - loss: 89.2471 - accuracy: 0.0028\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 81.9440 - accuracy: 0.0141\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 240us/step - loss: 74.8040 - accuracy: 0.0028\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 223us/step - loss: 72.4143 - accuracy: 0.0028\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 64.8417 - accuracy: 0.0085\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 243us/step - loss: 62.6018 - accuracy: 0.0028\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 249us/step - loss: 66.5517 - accuracy: 0.0028\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 243us/step - loss: 63.8462 - accuracy: 0.0056\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 249us/step - loss: 60.0348 - accuracy: 0.0169\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 63.3100 - accuracy: 0.0113\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 58.4264 - accuracy: 0.0169\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 240us/step - loss: 54.4333 - accuracy: 0.0056\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 251us/step - loss: 51.9338 - accuracy: 0.0085\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 240us/step - loss: 48.3352 - accuracy: 0.0113\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 48.6899 - accuracy: 0.0056\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 249us/step - loss: 47.4415 - accuracy: 0.0141\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 52.0986 - accuracy: 0.0085\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 237us/step - loss: 43.5081 - accuracy: 0.0113\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 45.9929 - accuracy: 0.0056\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 263us/step - loss: 45.6799 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 333us/step - loss: 40.3817 - accuracy: 0.0113\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 44.3535 - accuracy: 0.0113\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 41.3324 - accuracy: 0.0085\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 342us/step - loss: 40.2200 - accuracy: 0.0198\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 240us/step - loss: 40.1439 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 40.9501 - accuracy: 0.0056\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 277us/step - loss: 48.0251 - accuracy: 0.0141\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 39.0090 - accuracy: 0.0085\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 347us/step - loss: 38.7791 - accuracy: 0.0056\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 283us/step - loss: 44.3372 - accuracy: 0.0085\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 266us/step - loss: 37.7913 - accuracy: 0.0198\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 319us/step - loss: 40.0164 - accuracy: 0.0113\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 263us/step - loss: 42.7676 - accuracy: 0.0113\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 271us/step - loss: 38.3929 - accuracy: 0.0056\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 342us/step - loss: 36.6840 - accuracy: 0.0141\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 288us/step - loss: 36.3469 - accuracy: 0.0085\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 283us/step - loss: 34.0547 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 34.7514 - accuracy: 0.0113\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 322us/step - loss: 34.4584 - accuracy: 0.0141\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 438us/step - loss: 45.1701 - accuracy: 0.0056\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 34.9784 - accuracy: 0.0113\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 32.7688 - accuracy: 0.0113\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 280us/step - loss: 32.3098 - accuracy: 0.0141\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 274us/step - loss: 34.6615 - accuracy: 0.0113\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 280us/step - loss: 31.5935 - accuracy: 0.0141\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 33.9003 - accuracy: 0.0028\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 240us/step - loss: 31.0872 - accuracy: 0.0113\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 246us/step - loss: 32.1077 - accuracy: 0.0141\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 274us/step - loss: 29.7421 - accuracy: 0.0056\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 268us/step - loss: 31.6451 - accuracy: 0.0113\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 288us/step - loss: 31.9044 - accuracy: 0.0198\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 401us/step - loss: 32.8200 - accuracy: 0.0028\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 33.4833 - accuracy: 0.0085\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 418us/step - loss: 39.8462 - accuracy: 0.0226\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 333us/step - loss: 31.7267 - accuracy: 0.0198\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 396us/step - loss: 32.2667 - accuracy: 0.0141\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 359us/step - loss: 31.2663 - accuracy: 0.0198\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 379us/step - loss: 31.5210 - accuracy: 0.0141\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 308us/step - loss: 29.5596 - accuracy: 0.0282\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 31.1624 - accuracy: 0.0085\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 393us/step - loss: 28.6493 - accuracy: 0.0113\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 322us/step - loss: 28.5348 - accuracy: 0.0113\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 393us/step - loss: 31.8172 - accuracy: 0.0056\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 333us/step - loss: 31.0185 - accuracy: 0.0169\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 415us/step - loss: 30.6221 - accuracy: 0.0198\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 285us/step - loss: 29.8406 - accuracy: 0.0169\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 266us/step - loss: 29.8132 - accuracy: 0.0056\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 251us/step - loss: 28.6423 - accuracy: 0.0198\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 274us/step - loss: 31.0033 - accuracy: 0.0085\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 263us/step - loss: 31.3430 - accuracy: 0.0226\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 333us/step - loss: 28.6033 - accuracy: 0.0113\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 325us/step - loss: 29.1294 - accuracy: 0.0085\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 384us/step - loss: 30.6594 - accuracy: 0.0198\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 27.2346 - accuracy: 0.0169ETA: 0s - loss: 31.5877 - accuracy: 0.0143  \n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 28.0092 - accuracy: 0.0113\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 316us/step - loss: 36.1449 - accuracy: 0.0169\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 322us/step - loss: 31.7752 - accuracy: 0.0226\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 299us/step - loss: 29.7794 - accuracy: 0.0198\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 206us/step - loss: 28.7169 - accuracy: 0.0169\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 232us/step - loss: 27.2723 - accuracy: 0.0056\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 229us/step - loss: 26.9384 - accuracy: 0.0085\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 189us/step - loss: 29.8867 - accuracy: 0.0169\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 31.6466 - accuracy: 0.0198\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 223us/step - loss: 25.8802 - accuracy: 0.0226\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 203us/step - loss: 30.4689 - accuracy: 0.0113\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 240us/step - loss: 30.7142 - accuracy: 0.0141\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 29.0261 - accuracy: 0.0113\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 215us/step - loss: 33.2685 - accuracy: 0.0141\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 206us/step - loss: 26.9991 - accuracy: 0.0198\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 209us/step - loss: 31.8902 - accuracy: 0.0056\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 209us/step - loss: 26.2356 - accuracy: 0.0198\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 218us/step - loss: 29.3429 - accuracy: 0.0113\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 195us/step - loss: 28.2884 - accuracy: 0.0141\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 203us/step - loss: 25.6459 - accuracy: 0.0141\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 206us/step - loss: 28.0933 - accuracy: 0.0198\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 215us/step - loss: 27.6159 - accuracy: 0.0028\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 223us/step - loss: 27.2470 - accuracy: 0.0198\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 212us/step - loss: 25.1084 - accuracy: 0.0113\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 220us/step - loss: 26.4655 - accuracy: 0.0085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x248d6710>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 367us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.553202637171341, 0.016949152573943138]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
