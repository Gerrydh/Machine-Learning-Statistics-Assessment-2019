{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# For neural networks.\n",
    "import keras as kr\n",
    "# For data frames.\n",
    "import pandas as pd\n",
    "# For numerical arrays.\n",
    "import numpy as np\n",
    "# For preprocessing data.\n",
    "import sklearn.preprocessing as pre\n",
    "# For splitting data sets.\n",
    "import sklearn.model_selection as mod\n",
    "# For whitening.\n",
    "import sklearn.decomposition as dec\n",
    "from sklearn.datasets import load_boston #load the boston house proce index from the sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston['MEDV'] = boston_dataset.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>392.53</td>\n",
       "      <td>13.83</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.54</td>\n",
       "      <td>19.88</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.33</td>\n",
       "      <td>16.30</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.88</td>\n",
       "      <td>14.81</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.047</td>\n",
       "      <td>88.8</td>\n",
       "      <td>4.4534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>306.38</td>\n",
       "      <td>17.28</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.77299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.495</td>\n",
       "      <td>94.4</td>\n",
       "      <td>4.4547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>387.94</td>\n",
       "      <td>12.80</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.23</td>\n",
       "      <td>11.98</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.21</td>\n",
       "      <td>18.68</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>379.70</td>\n",
       "      <td>18.03</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>14.33370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.229</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>383.32</td>\n",
       "      <td>13.11</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.82401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.7</td>\n",
       "      <td>3.4242</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.74</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.70818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.750</td>\n",
       "      <td>74.9</td>\n",
       "      <td>3.3317</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.07</td>\n",
       "      <td>7.74</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.73116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>7.061</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.28</td>\n",
       "      <td>7.01</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.92</td>\n",
       "      <td>10.42</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>370.73</td>\n",
       "      <td>13.34</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.62</td>\n",
       "      <td>10.58</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.69175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.114</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3.5459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.68</td>\n",
       "      <td>14.98</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.22</td>\n",
       "      <td>11.45</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.15086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.454</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.8209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>395.09</td>\n",
       "      <td>18.06</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.18337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.414</td>\n",
       "      <td>98.3</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>344.05</td>\n",
       "      <td>23.97</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>318.43</td>\n",
       "      <td>29.68</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.11132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>83.5</td>\n",
       "      <td>2.1099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.35</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.59</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.17899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.670</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>393.29</td>\n",
       "      <td>17.60</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.28960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.390</td>\n",
       "      <td>72.9</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.14</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.10</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.92</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
       "1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
       "2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
       "3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
       "4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
       "5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
       "6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
       "7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
       "8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
       "10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
       "11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
       "12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
       "13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
       "14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
       "15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
       "16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
       "17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
       "19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
       "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
       "22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
       "24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
       "26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
       "28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
       "29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       "476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
       "477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
       "478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
       "479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
       "480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
       "481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
       "482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
       "483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
       "486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
       "487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
       "488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
       "489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
       "490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
       "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       "492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
       "493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
       "495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
       "496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
       "497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
       "498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
       "499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
       "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
       "501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
       "502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
       "503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
       "504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
       "505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "5       18.7  394.12   5.21  28.7  \n",
       "6       15.2  395.60  12.43  22.9  \n",
       "7       15.2  396.90  19.15  27.1  \n",
       "8       15.2  386.63  29.93  16.5  \n",
       "9       15.2  386.71  17.10  18.9  \n",
       "10      15.2  392.52  20.45  15.0  \n",
       "11      15.2  396.90  13.27  18.9  \n",
       "12      15.2  390.50  15.71  21.7  \n",
       "13      21.0  396.90   8.26  20.4  \n",
       "14      21.0  380.02  10.26  18.2  \n",
       "15      21.0  395.62   8.47  19.9  \n",
       "16      21.0  386.85   6.58  23.1  \n",
       "17      21.0  386.75  14.67  17.5  \n",
       "18      21.0  288.99  11.69  20.2  \n",
       "19      21.0  390.95  11.28  18.2  \n",
       "20      21.0  376.57  21.02  13.6  \n",
       "21      21.0  392.53  13.83  19.6  \n",
       "22      21.0  396.90  18.72  15.2  \n",
       "23      21.0  394.54  19.88  14.5  \n",
       "24      21.0  394.33  16.30  15.6  \n",
       "25      21.0  303.42  16.51  13.9  \n",
       "26      21.0  376.88  14.81  16.6  \n",
       "27      21.0  306.38  17.28  14.8  \n",
       "28      21.0  387.94  12.80  18.4  \n",
       "29      21.0  380.23  11.98  21.0  \n",
       "..       ...     ...    ...   ...  \n",
       "476     20.2  396.21  18.68  16.7  \n",
       "477     20.2  349.48  24.91  12.0  \n",
       "478     20.2  379.70  18.03  14.6  \n",
       "479     20.2  383.32  13.11  21.4  \n",
       "480     20.2  396.90  10.74  23.0  \n",
       "481     20.2  393.07   7.74  23.7  \n",
       "482     20.2  395.28   7.01  25.0  \n",
       "483     20.2  392.92  10.42  21.8  \n",
       "484     20.2  370.73  13.34  20.6  \n",
       "485     20.2  388.62  10.58  21.2  \n",
       "486     20.2  392.68  14.98  19.1  \n",
       "487     20.2  388.22  11.45  20.6  \n",
       "488     20.1  395.09  18.06  15.2  \n",
       "489     20.1  344.05  23.97   7.0  \n",
       "490     20.1  318.43  29.68   8.1  \n",
       "491     20.1  390.11  18.07  13.6  \n",
       "492     20.1  396.90  13.35  20.1  \n",
       "493     19.2  396.90  12.01  21.8  \n",
       "494     19.2  396.90  13.59  24.5  \n",
       "495     19.2  393.29  17.60  23.1  \n",
       "496     19.2  396.90  21.14  19.7  \n",
       "497     19.2  396.90  14.10  18.3  \n",
       "498     19.2  396.90  12.92  21.2  \n",
       "499     19.2  395.77  15.10  17.5  \n",
       "500     19.2  396.90  14.33  16.8  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = boston.iloc[:,0:13]\n",
    "y = boston.iloc[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = mod.train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 565us/step - loss: 33452.4475\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4473.6313\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 952.8871\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 562.2830\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 352.4595\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 247.1915\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 196.8452\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 176.0780\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 160.2760\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 150.3923\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 142.1311\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 135.2828\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 128.9041\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 121.0954\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 116.7759\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 110.1495\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 105.8230\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 100.4829\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 96.8592\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 94.0510\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 260us/step - loss: 90.0547\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 86.4995\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 297us/step - loss: 83.1055\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 186us/step - loss: 81.9730\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 77.9204\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 77.2903\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 73.9231\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 71.9581\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 70.0170\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 232us/step - loss: 69.15260s - loss: 70.39\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 67.6226\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 64.9714\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 64.3933\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 260us/step - loss: 63.6937\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 61.0601\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 60.4386\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 59.4446\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 57.8134\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 57.1507\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 260us/step - loss: 56.1829\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 55.5571\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 55.0168\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 232us/step - loss: 54.8026\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 53.4262\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.4873\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.0036\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 49.9050\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.6800\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.5772\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 47.8029\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 47.3943\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.0587\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 48.3077\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.4712\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.2676\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 45.8822\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 44.4682\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.4013\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.6806\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 42.8969\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.1039\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.9207\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.2240\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.3538\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.0318\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 41.1740\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.8604\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.6534\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.2670\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 40.6870\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.5535\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 39.2450\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.4566\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.7620\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.6912\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.9569\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 38.4798\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.0787\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.4185\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2289\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.4965\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 37.5628\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2672\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.6984\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.5769\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.0777\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.4952\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.0969\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.3414\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.5813\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8276\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 34.8025\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.9633\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8192\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.1105\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 35.1338\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 35.9525\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.7114\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.6064\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.6430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x5854080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.,  8., 33., 25., 26., 30., 25., 14., 16., 13., 26., 21., 22.,\n",
       "        19., 24.,  5., 32., 27., 26., 34., 31., 13., 27., 29., 23., 27.,\n",
       "        27., 29., 21., 13., 28., 22., 33., 29., 28., 14., 27., 28., 22.,\n",
       "        20., 24., 27., 20., 11., 22., 21., 18., 28., 22., 11., 20., 28.,\n",
       "        24., 27., 27., 30., 24., 30.,  7., 20., 24., 13., 16., 13., 32.,\n",
       "        29., 16., 22., 24., 27., 25., 30., 21., 19., 23., 21., 28., 32.,\n",
       "        31., 10.,  6., 34., 15., 15., 19., 27.,  2., 28., 14., 23., 15.,\n",
       "        20., 40., 21., 18., 21., 22., 23.,  3., 22., 27.,  8., 20., 21.,\n",
       "        28., 23., 17., 26., 21., 26., 27., 26., 24., 33., 27., 28., 26.,\n",
       "        28., 30., 36., 30., 23., 32., 14., 31., 30., 42., 28., 18., 21.,\n",
       "        20., 27., 35., 30., 28., 23., 32., 19., 24., 21., 25., 26., 27.,\n",
       "         9., 11., 21., 22., 19., 34., 31., 27., 25.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 329us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.69088845503958"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 424us/step - loss: 134.4960\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 82.7350\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 70.5340\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 67.0629\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 63.7141\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 61.1665\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 55.1983\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 53.2349\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.8724\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 50.2747\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 46.5096\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 48.3309\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 48.3226\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 46.3039\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.6084\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 42.5299\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 41.5316\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.8653\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.7306\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.8355\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.4056\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 39.2632\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 39.7066\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 38.6522\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.0524\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.9922\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.3295\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 37.0845\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.5624\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.3117\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.9738\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.7399\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.2424\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.8444\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.7203\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.6062\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.8883\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 35.5162\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 39.6129\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.0697\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.0319\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.5641\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.7030\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.1145\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.6584\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.4622\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.2531\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.8072\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.4498\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.2492\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.2842\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.9922\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.6196\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.8007\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.4331\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 33.2056\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.8633\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.6919\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 34.8741\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8966\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.2778\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.2050\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.6438\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.8971\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5904\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 35.3867\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.8750\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.2494\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 33.7092\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.3455\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 34.5793\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.6210\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 32.5840\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.3881\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.4021\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.0466\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.4066\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5709\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.4007\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5969\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9174\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.3884\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7423\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9597\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9133\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6264\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1159\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 32.8701\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2068\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0431\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.4680\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8941\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.3153\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6535\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.4734\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 32.0899\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5556\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.0298\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.3001\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.6017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xf4b28d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 12., 28., 21., 21., 27., 21.,  8., 13., 11., 20., 21., 18.,\n",
       "        15., 23.,  7., 30., 23., 20., 34., 30., 15., 33., 23., 20., 22.,\n",
       "        22., 22., 20., 11., 23., 22., 34., 27., 26., 11., 22., 32., 19.,\n",
       "        15., 28., 23., 12.,  7., 18., 17., 16., 23., 16.,  6., 14., 26.,\n",
       "        21., 28., 20., 27., 18., 25.,  2., 17., 22.,  6., 16., 11., 33.,\n",
       "        27., 12., 20., 23., 24., 25., 28., 18., 15., 17., 19., 25., 32.,\n",
       "        28.,  1., -0., 32., 11., 12., 15., 24., -1., 25., 10., 19., 11.,\n",
       "        16., 40., 23., 15., 17., 19., 19.,  3., 19., 26.,  5., 16., 20.,\n",
       "        26., 20., 10., 19., 19., 19., 25., 23., 17., 34., 27., 25., 20.,\n",
       "        24., 23., 30., 25., 16., 26.,  8., 26., 24., 44., 26., 14., 19.,\n",
       "        17., 24., 32., 31., 23., 19., 30., 16., 19., 17., 20., 20., 23.,\n",
       "         6.,  5., 21., 21., 16., 30., 26., 24., 21.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 526us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.530512408206334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080348</td>\n",
       "      <td>-0.394817</td>\n",
       "      <td>-0.890183</td>\n",
       "      <td>0.371012</td>\n",
       "      <td>-0.729959</td>\n",
       "      <td>0.941728</td>\n",
       "      <td>2.038580</td>\n",
       "      <td>0.344230</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>-0.748164</td>\n",
       "      <td>-0.248955</td>\n",
       "      <td>-0.280126</td>\n",
       "      <td>0.092254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.115092</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>1.081599</td>\n",
       "      <td>-1.335076</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>-1.591981</td>\n",
       "      <td>0.471225</td>\n",
       "      <td>-0.110589</td>\n",
       "      <td>0.393893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.678670</td>\n",
       "      <td>0.109902</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>-0.192856</td>\n",
       "      <td>-0.352267</td>\n",
       "      <td>-0.167803</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>0.755681</td>\n",
       "      <td>-0.028307</td>\n",
       "      <td>-0.310263</td>\n",
       "      <td>-0.552134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.957708</td>\n",
       "      <td>2.691383</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.575203</td>\n",
       "      <td>0.883537</td>\n",
       "      <td>-0.790650</td>\n",
       "      <td>-0.139723</td>\n",
       "      <td>-0.029203</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>-1.924215</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>-0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.009087</td>\n",
       "      <td>0.196193</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>-1.122527</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.184398</td>\n",
       "      <td>-0.654900</td>\n",
       "      <td>-0.433389</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>-0.310646</td>\n",
       "      <td>0.314520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.611866</td>\n",
       "      <td>0.137828</td>\n",
       "      <td>-0.531281</td>\n",
       "      <td>-0.444828</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>-0.188192</td>\n",
       "      <td>-1.068207</td>\n",
       "      <td>-0.249310</td>\n",
       "      <td>-0.612161</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>-0.404626</td>\n",
       "      <td>-0.524731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.338056</td>\n",
       "      <td>-0.323253</td>\n",
       "      <td>1.205601</td>\n",
       "      <td>1.744052</td>\n",
       "      <td>-0.362501</td>\n",
       "      <td>-0.347251</td>\n",
       "      <td>-0.274208</td>\n",
       "      <td>1.125857</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>-0.353582</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.391402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.249902</td>\n",
       "      <td>-1.540512</td>\n",
       "      <td>-0.316446</td>\n",
       "      <td>0.389658</td>\n",
       "      <td>1.098720</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>-0.371540</td>\n",
       "      <td>-0.349467</td>\n",
       "      <td>-0.161251</td>\n",
       "      <td>-0.315329</td>\n",
       "      <td>-1.166842</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>0.014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.960374</td>\n",
       "      <td>2.726205</td>\n",
       "      <td>0.573851</td>\n",
       "      <td>-0.488915</td>\n",
       "      <td>2.904541</td>\n",
       "      <td>-1.689157</td>\n",
       "      <td>1.238750</td>\n",
       "      <td>0.475148</td>\n",
       "      <td>0.423293</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.657942</td>\n",
       "      <td>-0.054441</td>\n",
       "      <td>-0.837061</td>\n",
       "      <td>-0.077872</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.086200</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>0.306190</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>1.069730</td>\n",
       "      <td>-0.342973</td>\n",
       "      <td>0.129854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.636011</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-1.239630</td>\n",
       "      <td>0.456554</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>-0.860661</td>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.563122</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>-0.569178</td>\n",
       "      <td>-0.148434</td>\n",
       "      <td>0.493215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.009365</td>\n",
       "      <td>0.191193</td>\n",
       "      <td>2.148391</td>\n",
       "      <td>2.001960</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>-1.530055</td>\n",
       "      <td>1.489968</td>\n",
       "      <td>-2.731570</td>\n",
       "      <td>0.459341</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>-0.264038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.277053</td>\n",
       "      <td>1.865595</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>-0.430563</td>\n",
       "      <td>-0.528763</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>1.725652</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-1.158937</td>\n",
       "      <td>0.687860</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>-0.771315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.985661</td>\n",
       "      <td>2.895293</td>\n",
       "      <td>0.544915</td>\n",
       "      <td>-0.480189</td>\n",
       "      <td>-1.177606</td>\n",
       "      <td>-0.463066</td>\n",
       "      <td>-0.338959</td>\n",
       "      <td>-0.379896</td>\n",
       "      <td>0.370657</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>-0.022322</td>\n",
       "      <td>0.673355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.155687</td>\n",
       "      <td>-1.017810</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>-0.715356</td>\n",
       "      <td>-1.729263</td>\n",
       "      <td>2.308184</td>\n",
       "      <td>-0.125476</td>\n",
       "      <td>-1.382472</td>\n",
       "      <td>0.852165</td>\n",
       "      <td>-1.760670</td>\n",
       "      <td>-1.251921</td>\n",
       "      <td>-0.786614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.943787</td>\n",
       "      <td>0.191897</td>\n",
       "      <td>2.283650</td>\n",
       "      <td>3.452496</td>\n",
       "      <td>0.053454</td>\n",
       "      <td>-0.170607</td>\n",
       "      <td>-0.112187</td>\n",
       "      <td>-1.098166</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>0.608938</td>\n",
       "      <td>0.653165</td>\n",
       "      <td>-0.266726</td>\n",
       "      <td>-0.091649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.535033</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>-0.641210</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>0.202774</td>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>0.833602</td>\n",
       "      <td>2.085996</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.404678</td>\n",
       "      <td>-0.613735</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.308832</td>\n",
       "      <td>-0.178946</td>\n",
       "      <td>1.354895</td>\n",
       "      <td>-1.057672</td>\n",
       "      <td>-0.458506</td>\n",
       "      <td>-0.332231</td>\n",
       "      <td>-0.585559</td>\n",
       "      <td>-0.053712</td>\n",
       "      <td>-0.211421</td>\n",
       "      <td>-1.758293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.196783</td>\n",
       "      <td>-0.414817</td>\n",
       "      <td>1.490226</td>\n",
       "      <td>-2.874329</td>\n",
       "      <td>-0.251195</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.518385</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-0.317663</td>\n",
       "      <td>-0.738418</td>\n",
       "      <td>-0.211338</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>-0.686020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.898128</td>\n",
       "      <td>2.359720</td>\n",
       "      <td>0.329719</td>\n",
       "      <td>-0.233685</td>\n",
       "      <td>-1.512660</td>\n",
       "      <td>-0.211246</td>\n",
       "      <td>-0.626046</td>\n",
       "      <td>-0.492962</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.065852</td>\n",
       "      <td>-0.662386</td>\n",
       "      <td>-0.185006</td>\n",
       "      <td>0.625654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.351897</td>\n",
       "      <td>-0.876389</td>\n",
       "      <td>0.301938</td>\n",
       "      <td>-0.427105</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>2.323010</td>\n",
       "      <td>-0.937386</td>\n",
       "      <td>-0.412936</td>\n",
       "      <td>-0.766805</td>\n",
       "      <td>-1.074004</td>\n",
       "      <td>-1.122226</td>\n",
       "      <td>-0.137080</td>\n",
       "      <td>0.442295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.843534</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.592639</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>-1.092255</td>\n",
       "      <td>-0.577864</td>\n",
       "      <td>1.215063</td>\n",
       "      <td>-0.036064</td>\n",
       "      <td>-0.900039</td>\n",
       "      <td>-0.542748</td>\n",
       "      <td>-0.305855</td>\n",
       "      <td>0.150305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050379</td>\n",
       "      <td>-0.584889</td>\n",
       "      <td>-1.041110</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>-0.818853</td>\n",
       "      <td>0.079107</td>\n",
       "      <td>2.221296</td>\n",
       "      <td>0.277487</td>\n",
       "      <td>1.849282</td>\n",
       "      <td>-0.427553</td>\n",
       "      <td>-0.648227</td>\n",
       "      <td>-0.398190</td>\n",
       "      <td>0.193268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.779425</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>1.043213</td>\n",
       "      <td>-0.670624</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.533982</td>\n",
       "      <td>-1.080526</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>1.450427</td>\n",
       "      <td>0.390579</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>0.948641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.304556</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.066358</td>\n",
       "      <td>-0.485542</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>1.877667</td>\n",
       "      <td>0.472362</td>\n",
       "      <td>-0.851668</td>\n",
       "      <td>-0.475440</td>\n",
       "      <td>0.433045</td>\n",
       "      <td>0.416610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.545173</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>-0.127907</td>\n",
       "      <td>0.237873</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>-0.648339</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>-0.167001</td>\n",
       "      <td>-0.170500</td>\n",
       "      <td>0.992560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.225336</td>\n",
       "      <td>-0.140532</td>\n",
       "      <td>0.457158</td>\n",
       "      <td>0.209959</td>\n",
       "      <td>-0.100670</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>2.007666</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>-0.460942</td>\n",
       "      <td>-0.511064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.808280</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>-0.837358</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.093117</td>\n",
       "      <td>-1.640965</td>\n",
       "      <td>-0.719455</td>\n",
       "      <td>1.428069</td>\n",
       "      <td>0.283175</td>\n",
       "      <td>-0.634228</td>\n",
       "      <td>-2.059973</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.548719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.994640</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>2.200903</td>\n",
       "      <td>2.732752</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>-0.152012</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>-1.081080</td>\n",
       "      <td>0.102347</td>\n",
       "      <td>-1.146830</td>\n",
       "      <td>-0.437390</td>\n",
       "      <td>-0.314694</td>\n",
       "      <td>-0.672085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.275527</td>\n",
       "      <td>-1.331517</td>\n",
       "      <td>0.176396</td>\n",
       "      <td>-0.262578</td>\n",
       "      <td>-0.404761</td>\n",
       "      <td>0.388403</td>\n",
       "      <td>-0.596450</td>\n",
       "      <td>-0.757497</td>\n",
       "      <td>-0.202598</td>\n",
       "      <td>-0.207741</td>\n",
       "      <td>-0.193679</td>\n",
       "      <td>-0.247489</td>\n",
       "      <td>0.767546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.448404</td>\n",
       "      <td>3.017727</td>\n",
       "      <td>-0.447951</td>\n",
       "      <td>-0.095226</td>\n",
       "      <td>-0.986589</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>1.900239</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>-1.736481</td>\n",
       "      <td>0.142566</td>\n",
       "      <td>0.208303</td>\n",
       "      <td>3.278740</td>\n",
       "      <td>3.117442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.637666</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.803028</td>\n",
       "      <td>-2.211732</td>\n",
       "      <td>0.133059</td>\n",
       "      <td>-0.773462</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>-0.569493</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-1.386104</td>\n",
       "      <td>0.410985</td>\n",
       "      <td>-0.254111</td>\n",
       "      <td>0.349224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.742337</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>-0.303305</td>\n",
       "      <td>-0.809501</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.673318</td>\n",
       "      <td>1.440644</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>-1.025311</td>\n",
       "      <td>0.145561</td>\n",
       "      <td>-0.137611</td>\n",
       "      <td>-0.612576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.863527</td>\n",
       "      <td>0.151054</td>\n",
       "      <td>-0.621895</td>\n",
       "      <td>1.102764</td>\n",
       "      <td>0.127329</td>\n",
       "      <td>-0.637058</td>\n",
       "      <td>-0.923254</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>-2.615026</td>\n",
       "      <td>-1.113191</td>\n",
       "      <td>-0.353638</td>\n",
       "      <td>-0.942371</td>\n",
       "      <td>1.263226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.250864</td>\n",
       "      <td>-1.539722</td>\n",
       "      <td>-0.320317</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>1.494396</td>\n",
       "      <td>1.996060</td>\n",
       "      <td>-0.855019</td>\n",
       "      <td>-0.153564</td>\n",
       "      <td>-0.572640</td>\n",
       "      <td>-0.513297</td>\n",
       "      <td>-0.060177</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>0.233746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.845037</td>\n",
       "      <td>2.016857</td>\n",
       "      <td>0.079042</td>\n",
       "      <td>0.082106</td>\n",
       "      <td>-0.680868</td>\n",
       "      <td>-0.186099</td>\n",
       "      <td>-0.529998</td>\n",
       "      <td>-0.301536</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>-0.029481</td>\n",
       "      <td>-1.333357</td>\n",
       "      <td>-0.259586</td>\n",
       "      <td>-1.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.330616</td>\n",
       "      <td>-1.041621</td>\n",
       "      <td>-0.163635</td>\n",
       "      <td>0.216016</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>-0.562350</td>\n",
       "      <td>-0.604425</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>0.441959</td>\n",
       "      <td>1.107620</td>\n",
       "      <td>-0.197033</td>\n",
       "      <td>-1.626711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.038869</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>-1.058361</td>\n",
       "      <td>0.544799</td>\n",
       "      <td>-0.519040</td>\n",
       "      <td>-0.246005</td>\n",
       "      <td>1.843414</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>-1.608033</td>\n",
       "      <td>1.175863</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>-0.930218</td>\n",
       "      <td>-1.208786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.802686</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>2.691830</td>\n",
       "      <td>2.205935</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.910832</td>\n",
       "      <td>0.617372</td>\n",
       "      <td>0.393352</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>-0.563892</td>\n",
       "      <td>-0.681889</td>\n",
       "      <td>-0.061548</td>\n",
       "      <td>-0.110975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.248989</td>\n",
       "      <td>-1.540390</td>\n",
       "      <td>-0.259678</td>\n",
       "      <td>0.338137</td>\n",
       "      <td>1.419395</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>0.247133</td>\n",
       "      <td>-0.372901</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>-0.375925</td>\n",
       "      <td>-1.600665</td>\n",
       "      <td>-0.439351</td>\n",
       "      <td>0.211505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.509456</td>\n",
       "      <td>0.064296</td>\n",
       "      <td>2.700187</td>\n",
       "      <td>1.597607</td>\n",
       "      <td>-0.144598</td>\n",
       "      <td>0.310441</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>0.585163</td>\n",
       "      <td>3.476441</td>\n",
       "      <td>1.317026</td>\n",
       "      <td>0.872823</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>1.922435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.231409</td>\n",
       "      <td>-1.538950</td>\n",
       "      <td>0.688780</td>\n",
       "      <td>-0.936760</td>\n",
       "      <td>-0.398978</td>\n",
       "      <td>-0.730870</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>-0.940533</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>0.675256</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>-0.217405</td>\n",
       "      <td>-1.520989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.534067</td>\n",
       "      <td>-0.182972</td>\n",
       "      <td>2.735200</td>\n",
       "      <td>1.545595</td>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.187525</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>-0.256181</td>\n",
       "      <td>-0.892626</td>\n",
       "      <td>1.122224</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>-0.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-0.188002</td>\n",
       "      <td>-0.354648</td>\n",
       "      <td>1.814985</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>-0.423748</td>\n",
       "      <td>-0.521735</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.755776</td>\n",
       "      <td>-1.094067</td>\n",
       "      <td>0.626996</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>-0.217247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.069057</td>\n",
       "      <td>-0.099665</td>\n",
       "      <td>-1.132815</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>-0.730913</td>\n",
       "      <td>-1.100634</td>\n",
       "      <td>2.043489</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-1.495209</td>\n",
       "      <td>0.700378</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>-1.033186</td>\n",
       "      <td>3.565111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-1.086996</td>\n",
       "      <td>0.369113</td>\n",
       "      <td>0.343296</td>\n",
       "      <td>-0.357972</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>1.026568</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>-0.774167</td>\n",
       "      <td>0.254745</td>\n",
       "      <td>-1.067171</td>\n",
       "      <td>0.603821</td>\n",
       "      <td>-0.176953</td>\n",
       "      <td>-0.166501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.190903</td>\n",
       "      <td>-0.402475</td>\n",
       "      <td>1.511917</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>-0.407703</td>\n",
       "      <td>-0.352837</td>\n",
       "      <td>-0.155576</td>\n",
       "      <td>1.782732</td>\n",
       "      <td>-1.411651</td>\n",
       "      <td>-1.642066</td>\n",
       "      <td>0.222688</td>\n",
       "      <td>-0.066098</td>\n",
       "      <td>-1.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.918492</td>\n",
       "      <td>2.448586</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.520436</td>\n",
       "      <td>-0.741136</td>\n",
       "      <td>-0.175211</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>-0.164630</td>\n",
       "      <td>-1.124253</td>\n",
       "      <td>-0.171095</td>\n",
       "      <td>0.864909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-1.036607</td>\n",
       "      <td>0.232198</td>\n",
       "      <td>-0.630966</td>\n",
       "      <td>-0.585621</td>\n",
       "      <td>0.471721</td>\n",
       "      <td>1.047169</td>\n",
       "      <td>-0.671226</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>1.669281</td>\n",
       "      <td>0.383386</td>\n",
       "      <td>-0.356056</td>\n",
       "      <td>-0.501093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.593573</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>-1.209316</td>\n",
       "      <td>1.399069</td>\n",
       "      <td>0.283667</td>\n",
       "      <td>2.809910</td>\n",
       "      <td>-1.617712</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>-1.553295</td>\n",
       "      <td>2.757605</td>\n",
       "      <td>-0.812138</td>\n",
       "      <td>-0.679586</td>\n",
       "      <td>-0.578312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.793258</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>-1.138782</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>0.694742</td>\n",
       "      <td>-1.275697</td>\n",
       "      <td>-0.662284</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>-0.241130</td>\n",
       "      <td>-0.972592</td>\n",
       "      <td>-0.584089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.858731</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>-0.984352</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>0.148730</td>\n",
       "      <td>-0.576002</td>\n",
       "      <td>-1.127209</td>\n",
       "      <td>0.135239</td>\n",
       "      <td>-2.526001</td>\n",
       "      <td>-0.874003</td>\n",
       "      <td>-0.672065</td>\n",
       "      <td>-1.024450</td>\n",
       "      <td>1.060107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.246741</td>\n",
       "      <td>-1.540688</td>\n",
       "      <td>-0.173736</td>\n",
       "      <td>0.186121</td>\n",
       "      <td>0.273360</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>-0.735751</td>\n",
       "      <td>-0.534623</td>\n",
       "      <td>-0.272326</td>\n",
       "      <td>-0.240316</td>\n",
       "      <td>0.196462</td>\n",
       "      <td>-0.218107</td>\n",
       "      <td>1.164912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.181469</td>\n",
       "      <td>1.443857</td>\n",
       "      <td>-0.453647</td>\n",
       "      <td>-0.179776</td>\n",
       "      <td>-0.862378</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>1.993915</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>-1.710368</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>-0.781257</td>\n",
       "      <td>-1.071121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.819563</td>\n",
       "      <td>0.096842</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>-1.586421</td>\n",
       "      <td>0.071846</td>\n",
       "      <td>-1.046755</td>\n",
       "      <td>-0.297640</td>\n",
       "      <td>1.274354</td>\n",
       "      <td>-0.194642</td>\n",
       "      <td>-1.549125</td>\n",
       "      <td>-1.857324</td>\n",
       "      <td>-0.234793</td>\n",
       "      <td>0.067342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.849991</td>\n",
       "      <td>0.205352</td>\n",
       "      <td>-0.888543</td>\n",
       "      <td>1.466501</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>-1.092184</td>\n",
       "      <td>-0.933734</td>\n",
       "      <td>0.064675</td>\n",
       "      <td>-2.440991</td>\n",
       "      <td>-1.015456</td>\n",
       "      <td>-0.059666</td>\n",
       "      <td>-0.988334</td>\n",
       "      <td>1.042627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.229282</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>-1.121209</td>\n",
       "      <td>0.570964</td>\n",
       "      <td>-0.437700</td>\n",
       "      <td>-0.485966</td>\n",
       "      <td>-0.532777</td>\n",
       "      <td>1.497981</td>\n",
       "      <td>1.544072</td>\n",
       "      <td>-1.200528</td>\n",
       "      <td>-0.152799</td>\n",
       "      <td>-0.081302</td>\n",
       "      <td>-0.440124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.569485</td>\n",
       "      <td>-0.151394</td>\n",
       "      <td>2.260648</td>\n",
       "      <td>2.176295</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>-0.292190</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>1.312312</td>\n",
       "      <td>-1.773981</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>-0.416606</td>\n",
       "      <td>-0.314958</td>\n",
       "      <td>-0.636563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.257425</td>\n",
       "      <td>-1.486130</td>\n",
       "      <td>-0.288594</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>-0.495139</td>\n",
       "      <td>-0.636809</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>-0.162717</td>\n",
       "      <td>-0.565589</td>\n",
       "      <td>-0.377851</td>\n",
       "      <td>0.389921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.786884</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>-0.801586</td>\n",
       "      <td>-0.232461</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>1.257130</td>\n",
       "      <td>-0.209978</td>\n",
       "      <td>-0.291861</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.478781</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.409151</td>\n",
       "      <td>-0.691410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0    0.080348 -0.394817 -0.890183  0.371012 -0.729959  0.941728  2.038580   \n",
       "1   -1.115092  0.278251  1.081599 -1.335076  0.450709  0.342844  0.530724   \n",
       "2   -0.678670  0.109902  0.841250  0.052771  0.031168 -0.192856 -0.352267   \n",
       "3    1.957708  2.691383  0.204966 -0.059570 -0.575203  0.883537 -0.790650   \n",
       "4   -1.009087  0.196193  1.046665 -1.122527  0.320851 -0.093841  0.184398   \n",
       "5   -0.611866  0.137828 -0.531281 -0.444828  0.115007 -0.188192 -1.068207   \n",
       "6   -0.338056 -0.323253  1.205601  1.744052 -0.362501 -0.347251 -0.274208   \n",
       "7    1.249902 -1.540512 -0.316446  0.389658  1.098720  0.224061 -0.371540   \n",
       "8    1.960374  2.726205  0.573851 -0.488915  2.904541 -1.689157  1.238750   \n",
       "9   -0.657942 -0.054441 -0.837061 -0.077872 -0.043811 -0.086200  0.009856   \n",
       "10  -0.636011 -0.072869 -1.239630  0.456554  0.231618  0.878649 -0.860661   \n",
       "11  -1.009365  0.191193  2.148391  2.001960  0.143939 -0.012545  0.671094   \n",
       "12  -0.175675 -0.277053  1.865595  0.199379 -0.430563 -0.528763  0.068854   \n",
       "13   1.985661  2.895293  0.544915 -0.480189 -1.177606 -0.463066 -0.338959   \n",
       "14  -0.080628 -0.155687 -1.017810  0.497181 -0.715356 -1.729263  2.308184   \n",
       "15  -0.943787  0.191897  2.283650  3.452496  0.053454 -0.170607 -0.112187   \n",
       "16  -0.535033 -0.084668  0.958809 -0.641210  0.074573  0.202774 -0.423037   \n",
       "17   1.404678 -0.613735 -0.231168  0.308832 -0.178946  1.354895 -1.057672   \n",
       "18  -0.196783 -0.414817  1.490226 -2.874329 -0.251195  0.331195  1.518385   \n",
       "19   1.898128  2.359720  0.329719 -0.233685 -1.512660 -0.211246 -0.626046   \n",
       "20   1.351897 -0.876389  0.301938 -0.427105  0.437554  2.323010 -0.937386   \n",
       "21  -0.843534  0.090307 -0.500667 -0.592639  0.019766 -1.092255 -0.577864   \n",
       "22   0.050379 -0.584889 -1.041110  0.572919 -0.818853  0.079107  2.221296   \n",
       "23  -0.779425  0.097954  1.043213 -0.670624  0.244888 -0.056817 -0.533982   \n",
       "24  -0.176788 -0.304556  3.399690  2.066358 -0.485542  0.191075  0.487928   \n",
       "25   1.545173  0.222524 -0.127907  0.237873  0.282217  0.656231 -0.648339   \n",
       "26  -0.984151  0.225336 -0.140532  0.457158  0.209959 -0.100670 -0.462245   \n",
       "27  -0.808280  0.055035 -0.837358 -0.115261 -0.093117 -1.640965 -0.719455   \n",
       "28  -0.994640  0.314741  2.200903  2.732752  0.037579 -0.152012  0.626242   \n",
       "29   1.275527 -1.331517  0.176396 -0.262578 -0.404761  0.388403 -0.596450   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324  0.448404  3.017727 -0.447951 -0.095226 -0.986589  0.186189  1.900239   \n",
       "325 -0.637666  0.119517  0.803028 -2.211732  0.133059 -0.773462 -0.165652   \n",
       "326 -0.742337  0.495750 -0.303305 -0.809501 -0.052632 -0.898387 -0.673318   \n",
       "327 -0.863527  0.151054 -0.621895  1.102764  0.127329 -0.637058 -0.923254   \n",
       "328  1.250864 -1.539722 -0.320317  0.369770  1.494396  1.996060 -0.855019   \n",
       "329  1.845037  2.016857  0.079042  0.082106 -0.680868 -0.186099 -0.529998   \n",
       "330  1.330616 -1.041621 -0.163635  0.216016 -0.180344 -0.059550 -0.562350   \n",
       "331 -0.038869  0.083404 -1.058361  0.544799 -0.519040 -0.246005  1.843414   \n",
       "332 -0.802686  0.054897  2.691830  2.205935  0.040140  0.910832  0.617372   \n",
       "333  1.248989 -1.540390 -0.259678  0.338137  1.419395 -1.254890  0.247133   \n",
       "334 -0.509456  0.064296  2.700187  1.597607 -0.144598  0.310441 -0.006960   \n",
       "335  1.231409 -1.538950  0.688780 -0.936760 -0.398978 -0.730870  0.026377   \n",
       "336 -0.534067 -0.182972  2.735200  1.545595 -0.155897  0.187525  0.503330   \n",
       "337 -0.188002 -0.354648  1.814985  0.266498 -0.423748 -0.521735  0.005338   \n",
       "338 -0.069057 -0.099665 -1.132815  0.642774 -0.730913 -1.100634  2.043489   \n",
       "339 -1.086996  0.369113  0.343296 -0.357972  0.485442  1.026568 -0.074474   \n",
       "340 -0.190903 -0.402475  1.511917  0.657549 -0.407703 -0.352837 -0.155576   \n",
       "341  1.918492  2.448586  0.081510  0.095092 -0.600437  0.520436 -0.741136   \n",
       "342 -1.036607  0.232198 -0.630966 -0.585621  0.471721  1.047169 -0.671226   \n",
       "343 -0.593573  0.027279 -1.209316  1.399069  0.283667  2.809910 -1.617712   \n",
       "344 -0.793258  0.099612 -1.138782  0.220145 -0.077865 -0.385340  0.694742   \n",
       "345 -0.858731  0.142945 -0.984352  1.583382  0.148730 -0.576002 -1.127209   \n",
       "346  1.246741 -1.540688 -0.173736  0.186121  0.273360  0.841098 -0.735751   \n",
       "347  0.181469  1.443857 -0.453647 -0.179776 -0.862378 -0.038269  1.993915   \n",
       "348 -0.819563  0.096842  0.264932 -1.586421  0.071846 -1.046755 -0.297640   \n",
       "349 -0.849991  0.205352 -0.888543  1.466501  0.024785 -1.092184 -0.933734   \n",
       "350 -0.229282 -0.369674 -1.121209  0.570964 -0.437700 -0.485966 -0.532777   \n",
       "351 -0.569485 -0.151394  2.260648  2.176295 -0.257481 -0.292190  0.280509   \n",
       "352  1.257425 -1.486130 -0.288594  0.357705 -0.014140 -0.290924 -0.495139   \n",
       "353 -0.786884  0.135389 -0.801586 -0.232461  0.242451  1.257130 -0.209978   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.344230  1.603922 -0.748164 -0.248955 -0.280126  0.092254  \n",
       "1   -0.992543  0.171785 -1.591981  0.471225 -0.110589  0.393893  \n",
       "2   -0.167803 -0.456787  0.755681 -0.028307 -0.310263 -0.552134  \n",
       "3   -0.139723 -0.029203 -0.473747 -1.924215 -0.190591 -0.187401  \n",
       "4   -0.654900 -0.433389  1.050608 -0.023740 -0.310646  0.314520  \n",
       "5   -0.249310 -0.612161 -0.099950  0.827616 -0.404626 -0.524731  \n",
       "6    1.125857  0.471972 -0.353582  0.172697  0.022303  0.391402  \n",
       "7   -0.349467 -0.161251 -0.315329 -1.166842 -0.349731  0.014179  \n",
       "8    0.475148  0.423293 -0.043176  0.395698  0.118429  0.235490  \n",
       "9    0.189647  0.306190  0.377249  1.069730 -0.342973  0.129854  \n",
       "10   0.708222  1.563122 -0.154623 -0.569178 -0.148434  0.493215  \n",
       "11  -1.530055  1.489968 -2.731570  0.459341  0.036337 -0.264038  \n",
       "12   1.725652 -1.356036 -1.158937  0.687860  0.026640 -0.771315  \n",
       "13  -0.379896  0.370657  0.345026  0.494635 -0.022322  0.673355  \n",
       "14  -0.125476 -1.382472  0.852165 -1.760670 -1.251921 -0.786614  \n",
       "15  -1.098166 -0.018907  0.608938  0.653165 -0.266726 -0.091649  \n",
       "16  -0.009278  0.833602  2.085996  0.073895  0.009437  0.349866  \n",
       "17  -0.458506 -0.332231 -0.585559 -0.053712 -0.211421 -1.758293  \n",
       "18   0.603767 -0.317663 -0.738418 -0.211338  0.043863 -0.686020  \n",
       "19  -0.492962  0.273988  0.065852 -0.662386 -0.185006  0.625654  \n",
       "20  -0.412936 -0.766805 -1.074004 -1.122226 -0.137080  0.442295  \n",
       "21   1.215063 -0.036064 -0.900039 -0.542748 -0.305855  0.150305  \n",
       "22   0.277487  1.849282 -0.427553 -0.648227 -0.398190  0.193268  \n",
       "23  -1.080526  1.165125  1.450427  0.390579 -0.020257  0.948641  \n",
       "24   1.877667  0.472362 -0.851668 -0.475440  0.433045  0.416610  \n",
       "25  -0.269487 -0.078472 -0.102407 -0.167001 -0.170500  0.992560  \n",
       "26  -0.424416 -0.047900  2.007666  0.541705 -0.460942 -0.511064  \n",
       "27   1.428069  0.283175 -0.634228 -2.059973 -0.474163 -0.548719  \n",
       "28  -1.081080  0.102347 -1.146830 -0.437390 -0.314694 -0.672085  \n",
       "29  -0.757497 -0.202598 -0.207741 -0.193679 -0.247489  0.767546  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324  0.300365 -1.736481  0.142566  0.208303  3.278740  3.117442  \n",
       "325 -0.569493 -0.943414 -1.386104  0.410985 -0.254111  0.349224  \n",
       "326  1.440644  0.015810 -1.025311  0.145561 -0.137611 -0.612576  \n",
       "327  0.052150 -2.615026 -1.113191 -0.353638 -0.942371  1.263226  \n",
       "328 -0.153564 -0.572640 -0.513297 -0.060177 -0.138515  0.233746  \n",
       "329 -0.301536  0.243190 -0.029481 -1.333357 -0.259586 -1.784060  \n",
       "330 -0.604425  0.084291  0.441959  1.107620 -0.197033 -1.626711  \n",
       "331  0.062016 -1.608033  1.175863  0.911292 -0.930218 -1.208786  \n",
       "332  0.393352 -0.427835 -0.563892 -0.681889 -0.061548 -0.110975  \n",
       "333 -0.372901  0.121113 -0.375925 -1.600665 -0.439351  0.211505  \n",
       "334  0.585163  3.476441  1.317026  0.872823  0.785367  1.922435  \n",
       "335 -0.940533  0.054370  0.675256  0.089150 -0.217405 -1.520989  \n",
       "336  0.394356 -0.256181 -0.892626  1.122224  0.152020 -0.519524  \n",
       "337  1.755776 -1.094067  0.626996  0.061140 -0.036445 -0.217247  \n",
       "338 -0.061708 -1.495209  0.700378  0.447174 -1.033186  3.565111  \n",
       "339 -0.774167  0.254745 -1.067171  0.603821 -0.176953 -0.166501  \n",
       "340  1.782732 -1.411651 -1.642066  0.222688 -0.066098 -1.138598  \n",
       "341 -0.175211  0.105444 -0.164630 -1.124253 -0.171095  0.864909  \n",
       "342 -0.113630 -0.024870  1.669281  0.383386 -0.356056 -0.501093  \n",
       "343  0.692484 -1.553295  2.757605 -0.812138 -0.679586 -0.578312  \n",
       "344 -1.275697 -0.662284  0.814229 -0.241130 -0.972592 -0.584089  \n",
       "345  0.135239 -2.526001 -0.874003 -0.672065 -1.024450  1.060107  \n",
       "346 -0.534623 -0.272326 -0.240316  0.196462 -0.218107  1.164912  \n",
       "347  0.082282 -1.710368  0.748365  0.861978 -0.781257 -1.071121  \n",
       "348  1.274354 -0.194642 -1.549125 -1.857324 -0.234793  0.067342  \n",
       "349  0.064675 -2.440991 -1.015456 -0.059666 -0.988334  1.042627  \n",
       "350  1.497981  1.544072 -1.200528 -0.152799 -0.081302 -0.440124  \n",
       "351  1.312312 -1.773981  0.703413 -0.416606 -0.314958 -0.636563  \n",
       "352 -0.636809  0.011451 -0.162717 -0.565589 -0.377851  0.389921  \n",
       "353 -0.291861  0.157986  0.478781  0.014941 -0.409151 -0.691410  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(100, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 480us/step - loss: 1472.5145\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 104.7506\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 69.5631\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 65.6143\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 61.2053\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 59.5092\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 58.3558\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 57.2817\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 55.8379\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 53.4575\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 51.4516\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.4949\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.5503\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.8996\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 43.3654\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 42.7191\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.7227\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 42.7509\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.0206\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.5124\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.2958\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 40.2190\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.4965\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.0080\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.3740\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.3518\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 39.8117\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.4406\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 36.6204\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.3044\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.5277\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 39.7782\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 41.8056\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.0160\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.1049\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.8148\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.1597\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.4681\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.6925\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.6615\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.3879\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.2120\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.0658\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.7749\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.5006\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 38.0377\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.7726\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 33.6799\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.8416\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.2352\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.9087\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.7003\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.0552\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.5460\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.0286\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8199\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0162\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2100\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.9468\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.0559\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 29.2501\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3712\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.6740\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.4179\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.9951\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.4274\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1021\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8185\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.5455\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8997\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3561\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1632\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1487\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.9231\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 31.6031\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.4317\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.9790\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2751\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.9405\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3345\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.2351\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5351\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7182\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6504\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.3814\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7134\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.6971\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.7906\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9675\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.7366\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.8026\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.4509\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6574\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.6319\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4114\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 26.7991\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.0396\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 23.6834\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.9735\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xfa726a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32., 18., 46., 24., 25., 26., 27., 15., 26., 13., 24., 23., 28.,\n",
       "        24., 27., 14., 33., 26., 26., 41., 31., 24., 33., 27., 29., 27.,\n",
       "        33., 26., 25., 12., 27., 26., 37., 32., 30., 18., 27., 34., 23.,\n",
       "        19., 29., 27., 24., 15., 16., 22., 23., 27., 22., 15., 19., 33.,\n",
       "        26., 32., 24., 35., 22., 30., 11., 26., 27., 14., 16., 18., 34.,\n",
       "        32., 17., 23., 21., 28., 26., 33., 24., 23., 20., 23., 32., 37.,\n",
       "        29., 14., 10., 39., 19., 18., 24., 30., 13., 29., 18., 23., 19.,\n",
       "        25., 42., 23., 22., 22., 27., 23., 13., 23., 30., 13., 22., 24.,\n",
       "        30., 30., 17., 24., 26., 24., 30., 26., 23., 40., 32., 24., 26.,\n",
       "        28., 28., 38., 32., 22., 33., 13., 45., 29., 44., 29., 22., 26.,\n",
       "        22., 29., 35., 36., 28., 29., 33., 25., 22., 26., 23., 26., 29.,\n",
       "        13., 15., 20., 27., 27., 35., 32., 28., 25.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 526us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.078954997815586"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(20, activation=\"linear\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 763us/step - loss: 3633.5924\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 550.2207\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 287.6641\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 316us/step - loss: 186.4626\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 123.4524\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 92.0826\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 79.8624\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 77.4490\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 69.0341\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 65.1821\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 61.4230\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 59.8888\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 60.6101\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 56.1428\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 54.6321\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 54.9219\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 53.7170\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 54.6848\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 53.9541\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 57.7558\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 54.0455\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 51.4859\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 47.6450\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 47.8233\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 59.1934\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 48.2513\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 47.1209\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 48.8188\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.9077\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 47.1077\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.8997\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 47.6439\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.4353\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.7513\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.2192\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.0620\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.7918\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.6953\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.3269\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.2183\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.8195\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.7984\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.6001\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.2382\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.4175\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.2700\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.1630\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 45.9362\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.1344\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2114\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.4512\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.6310\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.3131\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.6379\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 47.6528\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.8475\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.6579\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.3934\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.3201\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.8788\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.3324\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.9129\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.2508\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.5095\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.9621\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.4858\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1203\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.5426\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.4714\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2962\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.2116\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.2660\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.1561\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.2622\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.4781\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.4091\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.5286\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.8894\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.8234\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.8177\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.7862\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.4754\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.0189\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.9041\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.7449\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.9353\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 52.3474\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.1118\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.0718\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.5498\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.9081\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.3263\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.9423\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.6740\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.2979\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 36.4184\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.2636\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.7526\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9738\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.2714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13fdf1d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25., 15., 35., 20., 22., 23., 24., 10., 20., 10., 21., 19., 22.,\n",
       "        19., 23.,  4., 29., 23., 23., 35., 28., 16., 29., 24., 22., 24.,\n",
       "        24., 24., 18.,  5., 23., 20., 32., 28., 26., 12., 25., 31., 20.,\n",
       "        17., 25., 24., 16.,  9., 17., 17., 15., 24., 19.,  8., 16., 28.,\n",
       "        21., 28., 22., 29., 20., 26.,  4., 21., 23., 10., 11., 12., 30.,\n",
       "        28., 12., 18., 20., 25., 21., 29., 20., 15., 19., 19., 26., 31.,\n",
       "        26.,  5.,  2., 33., 14., 14., 19., 25.,  6., 26., 11., 20., 13.,\n",
       "        20., 36., 18., 17., 18., 21., 20.,  9., 19., 25.,  3., 18., 19.,\n",
       "        27., 23., 14., 21., 20., 21., 25., 23., 19., 34., 26., 22., 24.,\n",
       "        25., 26., 33., 28., 18., 29., 12., 34., 27., 36., 26., 18., 19.,\n",
       "        19., 25., 32., 29., 25., 22., 29., 19., 20., 21., 21., 22., 25.,\n",
       "         6.,  7., 17., 22., 19., 32., 28., 25., 22.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 592us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.161125936006243"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(20, activation=\"linear\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 989us/step - loss: 10752.6436\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 456.7277\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 182.9043\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 152.2712\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 133.5126\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 115.8702\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 102.0947\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 87.9102\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 81.4459\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 73.7432\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 66.3215\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 66.8129\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.5090\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 62.2998\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 61.4228\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 60.5442\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 61.2101\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 59.4244\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.4822\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 57.2875\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.3192\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 56.3210\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.0285\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 55.6094\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.9256\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 53.2347\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.9551\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 229us/step - loss: 54.9907\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 51.3116\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.0307\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 54.2266\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 260us/step - loss: 56.1859\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.2087\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 229us/step - loss: 53.0448\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 52.4603\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 280us/step - loss: 49.1643\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 49.0257\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.4718\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.2563\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 51.5360\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 48.1643\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 47.4491\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 48.7440\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 46.8686\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 49.2461\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 48.4035\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 47.0848\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 47.2497\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.4987\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 46.4688\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.3404\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 44.7575\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.5502\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 46.5094\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.5278\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.8483\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 43.6799\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.6757\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.3132\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.4512\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.6466\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.5638\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.3104\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.0537\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 46.5217\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 46.0391\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 46.0752\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.8257\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.2071\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.3718\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.7733\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.7215\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.8513\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.7097\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.5717\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.5314\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.7259\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.2960\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.0303\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.8561\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 52.3136\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.6944\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.5285\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 18.80 - 0s 141us/step - loss: 40.1633\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.2311\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.0374\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.1053\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.0281\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.0943\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.8686\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.8814\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 119us/step - loss: 38.2586\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.7561\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.4362\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.6883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.9896\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.5787\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.4596\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.7737\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x10bd3b00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.,  7., 27., 23., 25., 28., 23., 12., 12., 15., 24., 23., 15.,\n",
       "        15., 26.,  3., 34., 27., 24., 39., 34.,  8., 37., 27., 19., 26.,\n",
       "        22., 28., 23.,  8., 25., 25., 38., 29., 26., 12., 26., 37., 23.,\n",
       "        21., 32., 27., 15.,  9., 19., 21., 17., 25., 22., 12., 16., 26.,\n",
       "        23., 29., 27., 30., 23., 30.,  5., 14., 25., 13., 14., 18., 38.,\n",
       "        29., 18., 22., 22., 27., 23., 31., 22., 24., 23., 21., 25., 36.,\n",
       "        32.,  7., 10., 36., 11., 12., 15., 26., -0., 28., 14., 22., 13.,\n",
       "        16., 45., 23., 12., 20., 18., 23.,  2., 22., 27.,  5., 19., 24.,\n",
       "        29., 18., 17., 23., 21., 23., 26., 26., 22., 38., 27., 26., 23.,\n",
       "        26., 28., 37., 31., 21., 31.,  9., 26., 27., 47., 31., 14., 18.,\n",
       "        27., 27., 38., 30., 27., 17., 34., 16., 20., 17., 24., 24., 25.,\n",
       "         8., 11., 20., 22., 15., 37., 30., 28., 24.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 658us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.06066211901213"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080348</td>\n",
       "      <td>-0.394817</td>\n",
       "      <td>-0.890183</td>\n",
       "      <td>0.371012</td>\n",
       "      <td>-0.729959</td>\n",
       "      <td>0.941728</td>\n",
       "      <td>2.038580</td>\n",
       "      <td>0.344230</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>-0.748164</td>\n",
       "      <td>-0.248955</td>\n",
       "      <td>-0.280126</td>\n",
       "      <td>0.092254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.115092</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>1.081599</td>\n",
       "      <td>-1.335076</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>-1.591981</td>\n",
       "      <td>0.471225</td>\n",
       "      <td>-0.110589</td>\n",
       "      <td>0.393893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.678670</td>\n",
       "      <td>0.109902</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>-0.192856</td>\n",
       "      <td>-0.352267</td>\n",
       "      <td>-0.167803</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>0.755681</td>\n",
       "      <td>-0.028307</td>\n",
       "      <td>-0.310263</td>\n",
       "      <td>-0.552134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.957708</td>\n",
       "      <td>2.691383</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.575203</td>\n",
       "      <td>0.883537</td>\n",
       "      <td>-0.790650</td>\n",
       "      <td>-0.139723</td>\n",
       "      <td>-0.029203</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>-1.924215</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>-0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.009087</td>\n",
       "      <td>0.196193</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>-1.122527</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.184398</td>\n",
       "      <td>-0.654900</td>\n",
       "      <td>-0.433389</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>-0.310646</td>\n",
       "      <td>0.314520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.611866</td>\n",
       "      <td>0.137828</td>\n",
       "      <td>-0.531281</td>\n",
       "      <td>-0.444828</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>-0.188192</td>\n",
       "      <td>-1.068207</td>\n",
       "      <td>-0.249310</td>\n",
       "      <td>-0.612161</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>-0.404626</td>\n",
       "      <td>-0.524731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.338056</td>\n",
       "      <td>-0.323253</td>\n",
       "      <td>1.205601</td>\n",
       "      <td>1.744052</td>\n",
       "      <td>-0.362501</td>\n",
       "      <td>-0.347251</td>\n",
       "      <td>-0.274208</td>\n",
       "      <td>1.125857</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>-0.353582</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.391402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.249902</td>\n",
       "      <td>-1.540512</td>\n",
       "      <td>-0.316446</td>\n",
       "      <td>0.389658</td>\n",
       "      <td>1.098720</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>-0.371540</td>\n",
       "      <td>-0.349467</td>\n",
       "      <td>-0.161251</td>\n",
       "      <td>-0.315329</td>\n",
       "      <td>-1.166842</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>0.014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.960374</td>\n",
       "      <td>2.726205</td>\n",
       "      <td>0.573851</td>\n",
       "      <td>-0.488915</td>\n",
       "      <td>2.904541</td>\n",
       "      <td>-1.689157</td>\n",
       "      <td>1.238750</td>\n",
       "      <td>0.475148</td>\n",
       "      <td>0.423293</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.657942</td>\n",
       "      <td>-0.054441</td>\n",
       "      <td>-0.837061</td>\n",
       "      <td>-0.077872</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.086200</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>0.306190</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>1.069730</td>\n",
       "      <td>-0.342973</td>\n",
       "      <td>0.129854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.636011</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-1.239630</td>\n",
       "      <td>0.456554</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>-0.860661</td>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.563122</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>-0.569178</td>\n",
       "      <td>-0.148434</td>\n",
       "      <td>0.493215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.009365</td>\n",
       "      <td>0.191193</td>\n",
       "      <td>2.148391</td>\n",
       "      <td>2.001960</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>-1.530055</td>\n",
       "      <td>1.489968</td>\n",
       "      <td>-2.731570</td>\n",
       "      <td>0.459341</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>-0.264038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.277053</td>\n",
       "      <td>1.865595</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>-0.430563</td>\n",
       "      <td>-0.528763</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>1.725652</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-1.158937</td>\n",
       "      <td>0.687860</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>-0.771315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.985661</td>\n",
       "      <td>2.895293</td>\n",
       "      <td>0.544915</td>\n",
       "      <td>-0.480189</td>\n",
       "      <td>-1.177606</td>\n",
       "      <td>-0.463066</td>\n",
       "      <td>-0.338959</td>\n",
       "      <td>-0.379896</td>\n",
       "      <td>0.370657</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>-0.022322</td>\n",
       "      <td>0.673355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.155687</td>\n",
       "      <td>-1.017810</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>-0.715356</td>\n",
       "      <td>-1.729263</td>\n",
       "      <td>2.308184</td>\n",
       "      <td>-0.125476</td>\n",
       "      <td>-1.382472</td>\n",
       "      <td>0.852165</td>\n",
       "      <td>-1.760670</td>\n",
       "      <td>-1.251921</td>\n",
       "      <td>-0.786614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.943787</td>\n",
       "      <td>0.191897</td>\n",
       "      <td>2.283650</td>\n",
       "      <td>3.452496</td>\n",
       "      <td>0.053454</td>\n",
       "      <td>-0.170607</td>\n",
       "      <td>-0.112187</td>\n",
       "      <td>-1.098166</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>0.608938</td>\n",
       "      <td>0.653165</td>\n",
       "      <td>-0.266726</td>\n",
       "      <td>-0.091649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.535033</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>-0.641210</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>0.202774</td>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>0.833602</td>\n",
       "      <td>2.085996</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.404678</td>\n",
       "      <td>-0.613735</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.308832</td>\n",
       "      <td>-0.178946</td>\n",
       "      <td>1.354895</td>\n",
       "      <td>-1.057672</td>\n",
       "      <td>-0.458506</td>\n",
       "      <td>-0.332231</td>\n",
       "      <td>-0.585559</td>\n",
       "      <td>-0.053712</td>\n",
       "      <td>-0.211421</td>\n",
       "      <td>-1.758293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.196783</td>\n",
       "      <td>-0.414817</td>\n",
       "      <td>1.490226</td>\n",
       "      <td>-2.874329</td>\n",
       "      <td>-0.251195</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.518385</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-0.317663</td>\n",
       "      <td>-0.738418</td>\n",
       "      <td>-0.211338</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>-0.686020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.898128</td>\n",
       "      <td>2.359720</td>\n",
       "      <td>0.329719</td>\n",
       "      <td>-0.233685</td>\n",
       "      <td>-1.512660</td>\n",
       "      <td>-0.211246</td>\n",
       "      <td>-0.626046</td>\n",
       "      <td>-0.492962</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.065852</td>\n",
       "      <td>-0.662386</td>\n",
       "      <td>-0.185006</td>\n",
       "      <td>0.625654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.351897</td>\n",
       "      <td>-0.876389</td>\n",
       "      <td>0.301938</td>\n",
       "      <td>-0.427105</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>2.323010</td>\n",
       "      <td>-0.937386</td>\n",
       "      <td>-0.412936</td>\n",
       "      <td>-0.766805</td>\n",
       "      <td>-1.074004</td>\n",
       "      <td>-1.122226</td>\n",
       "      <td>-0.137080</td>\n",
       "      <td>0.442295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.843534</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.592639</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>-1.092255</td>\n",
       "      <td>-0.577864</td>\n",
       "      <td>1.215063</td>\n",
       "      <td>-0.036064</td>\n",
       "      <td>-0.900039</td>\n",
       "      <td>-0.542748</td>\n",
       "      <td>-0.305855</td>\n",
       "      <td>0.150305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050379</td>\n",
       "      <td>-0.584889</td>\n",
       "      <td>-1.041110</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>-0.818853</td>\n",
       "      <td>0.079107</td>\n",
       "      <td>2.221296</td>\n",
       "      <td>0.277487</td>\n",
       "      <td>1.849282</td>\n",
       "      <td>-0.427553</td>\n",
       "      <td>-0.648227</td>\n",
       "      <td>-0.398190</td>\n",
       "      <td>0.193268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.779425</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>1.043213</td>\n",
       "      <td>-0.670624</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.533982</td>\n",
       "      <td>-1.080526</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>1.450427</td>\n",
       "      <td>0.390579</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>0.948641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.304556</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.066358</td>\n",
       "      <td>-0.485542</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>1.877667</td>\n",
       "      <td>0.472362</td>\n",
       "      <td>-0.851668</td>\n",
       "      <td>-0.475440</td>\n",
       "      <td>0.433045</td>\n",
       "      <td>0.416610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.545173</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>-0.127907</td>\n",
       "      <td>0.237873</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>-0.648339</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>-0.167001</td>\n",
       "      <td>-0.170500</td>\n",
       "      <td>0.992560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.225336</td>\n",
       "      <td>-0.140532</td>\n",
       "      <td>0.457158</td>\n",
       "      <td>0.209959</td>\n",
       "      <td>-0.100670</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>2.007666</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>-0.460942</td>\n",
       "      <td>-0.511064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.808280</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>-0.837358</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.093117</td>\n",
       "      <td>-1.640965</td>\n",
       "      <td>-0.719455</td>\n",
       "      <td>1.428069</td>\n",
       "      <td>0.283175</td>\n",
       "      <td>-0.634228</td>\n",
       "      <td>-2.059973</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.548719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.994640</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>2.200903</td>\n",
       "      <td>2.732752</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>-0.152012</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>-1.081080</td>\n",
       "      <td>0.102347</td>\n",
       "      <td>-1.146830</td>\n",
       "      <td>-0.437390</td>\n",
       "      <td>-0.314694</td>\n",
       "      <td>-0.672085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.275527</td>\n",
       "      <td>-1.331517</td>\n",
       "      <td>0.176396</td>\n",
       "      <td>-0.262578</td>\n",
       "      <td>-0.404761</td>\n",
       "      <td>0.388403</td>\n",
       "      <td>-0.596450</td>\n",
       "      <td>-0.757497</td>\n",
       "      <td>-0.202598</td>\n",
       "      <td>-0.207741</td>\n",
       "      <td>-0.193679</td>\n",
       "      <td>-0.247489</td>\n",
       "      <td>0.767546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.448404</td>\n",
       "      <td>3.017727</td>\n",
       "      <td>-0.447951</td>\n",
       "      <td>-0.095226</td>\n",
       "      <td>-0.986589</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>1.900239</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>-1.736481</td>\n",
       "      <td>0.142566</td>\n",
       "      <td>0.208303</td>\n",
       "      <td>3.278740</td>\n",
       "      <td>3.117442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.637666</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.803028</td>\n",
       "      <td>-2.211732</td>\n",
       "      <td>0.133059</td>\n",
       "      <td>-0.773462</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>-0.569493</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-1.386104</td>\n",
       "      <td>0.410985</td>\n",
       "      <td>-0.254111</td>\n",
       "      <td>0.349224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.742337</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>-0.303305</td>\n",
       "      <td>-0.809501</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.673318</td>\n",
       "      <td>1.440644</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>-1.025311</td>\n",
       "      <td>0.145561</td>\n",
       "      <td>-0.137611</td>\n",
       "      <td>-0.612576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.863527</td>\n",
       "      <td>0.151054</td>\n",
       "      <td>-0.621895</td>\n",
       "      <td>1.102764</td>\n",
       "      <td>0.127329</td>\n",
       "      <td>-0.637058</td>\n",
       "      <td>-0.923254</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>-2.615026</td>\n",
       "      <td>-1.113191</td>\n",
       "      <td>-0.353638</td>\n",
       "      <td>-0.942371</td>\n",
       "      <td>1.263226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.250864</td>\n",
       "      <td>-1.539722</td>\n",
       "      <td>-0.320317</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>1.494396</td>\n",
       "      <td>1.996060</td>\n",
       "      <td>-0.855019</td>\n",
       "      <td>-0.153564</td>\n",
       "      <td>-0.572640</td>\n",
       "      <td>-0.513297</td>\n",
       "      <td>-0.060177</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>0.233746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.845037</td>\n",
       "      <td>2.016857</td>\n",
       "      <td>0.079042</td>\n",
       "      <td>0.082106</td>\n",
       "      <td>-0.680868</td>\n",
       "      <td>-0.186099</td>\n",
       "      <td>-0.529998</td>\n",
       "      <td>-0.301536</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>-0.029481</td>\n",
       "      <td>-1.333357</td>\n",
       "      <td>-0.259586</td>\n",
       "      <td>-1.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.330616</td>\n",
       "      <td>-1.041621</td>\n",
       "      <td>-0.163635</td>\n",
       "      <td>0.216016</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>-0.562350</td>\n",
       "      <td>-0.604425</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>0.441959</td>\n",
       "      <td>1.107620</td>\n",
       "      <td>-0.197033</td>\n",
       "      <td>-1.626711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.038869</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>-1.058361</td>\n",
       "      <td>0.544799</td>\n",
       "      <td>-0.519040</td>\n",
       "      <td>-0.246005</td>\n",
       "      <td>1.843414</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>-1.608033</td>\n",
       "      <td>1.175863</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>-0.930218</td>\n",
       "      <td>-1.208786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.802686</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>2.691830</td>\n",
       "      <td>2.205935</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.910832</td>\n",
       "      <td>0.617372</td>\n",
       "      <td>0.393352</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>-0.563892</td>\n",
       "      <td>-0.681889</td>\n",
       "      <td>-0.061548</td>\n",
       "      <td>-0.110975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.248989</td>\n",
       "      <td>-1.540390</td>\n",
       "      <td>-0.259678</td>\n",
       "      <td>0.338137</td>\n",
       "      <td>1.419395</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>0.247133</td>\n",
       "      <td>-0.372901</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>-0.375925</td>\n",
       "      <td>-1.600665</td>\n",
       "      <td>-0.439351</td>\n",
       "      <td>0.211505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.509456</td>\n",
       "      <td>0.064296</td>\n",
       "      <td>2.700187</td>\n",
       "      <td>1.597607</td>\n",
       "      <td>-0.144598</td>\n",
       "      <td>0.310441</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>0.585163</td>\n",
       "      <td>3.476441</td>\n",
       "      <td>1.317026</td>\n",
       "      <td>0.872823</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>1.922435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.231409</td>\n",
       "      <td>-1.538950</td>\n",
       "      <td>0.688780</td>\n",
       "      <td>-0.936760</td>\n",
       "      <td>-0.398978</td>\n",
       "      <td>-0.730870</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>-0.940533</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>0.675256</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>-0.217405</td>\n",
       "      <td>-1.520989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.534067</td>\n",
       "      <td>-0.182972</td>\n",
       "      <td>2.735200</td>\n",
       "      <td>1.545595</td>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.187525</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>-0.256181</td>\n",
       "      <td>-0.892626</td>\n",
       "      <td>1.122224</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>-0.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-0.188002</td>\n",
       "      <td>-0.354648</td>\n",
       "      <td>1.814985</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>-0.423748</td>\n",
       "      <td>-0.521735</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.755776</td>\n",
       "      <td>-1.094067</td>\n",
       "      <td>0.626996</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>-0.217247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.069057</td>\n",
       "      <td>-0.099665</td>\n",
       "      <td>-1.132815</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>-0.730913</td>\n",
       "      <td>-1.100634</td>\n",
       "      <td>2.043489</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-1.495209</td>\n",
       "      <td>0.700378</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>-1.033186</td>\n",
       "      <td>3.565111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-1.086996</td>\n",
       "      <td>0.369113</td>\n",
       "      <td>0.343296</td>\n",
       "      <td>-0.357972</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>1.026568</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>-0.774167</td>\n",
       "      <td>0.254745</td>\n",
       "      <td>-1.067171</td>\n",
       "      <td>0.603821</td>\n",
       "      <td>-0.176953</td>\n",
       "      <td>-0.166501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.190903</td>\n",
       "      <td>-0.402475</td>\n",
       "      <td>1.511917</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>-0.407703</td>\n",
       "      <td>-0.352837</td>\n",
       "      <td>-0.155576</td>\n",
       "      <td>1.782732</td>\n",
       "      <td>-1.411651</td>\n",
       "      <td>-1.642066</td>\n",
       "      <td>0.222688</td>\n",
       "      <td>-0.066098</td>\n",
       "      <td>-1.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.918492</td>\n",
       "      <td>2.448586</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.520436</td>\n",
       "      <td>-0.741136</td>\n",
       "      <td>-0.175211</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>-0.164630</td>\n",
       "      <td>-1.124253</td>\n",
       "      <td>-0.171095</td>\n",
       "      <td>0.864909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-1.036607</td>\n",
       "      <td>0.232198</td>\n",
       "      <td>-0.630966</td>\n",
       "      <td>-0.585621</td>\n",
       "      <td>0.471721</td>\n",
       "      <td>1.047169</td>\n",
       "      <td>-0.671226</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>1.669281</td>\n",
       "      <td>0.383386</td>\n",
       "      <td>-0.356056</td>\n",
       "      <td>-0.501093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.593573</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>-1.209316</td>\n",
       "      <td>1.399069</td>\n",
       "      <td>0.283667</td>\n",
       "      <td>2.809910</td>\n",
       "      <td>-1.617712</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>-1.553295</td>\n",
       "      <td>2.757605</td>\n",
       "      <td>-0.812138</td>\n",
       "      <td>-0.679586</td>\n",
       "      <td>-0.578312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.793258</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>-1.138782</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>0.694742</td>\n",
       "      <td>-1.275697</td>\n",
       "      <td>-0.662284</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>-0.241130</td>\n",
       "      <td>-0.972592</td>\n",
       "      <td>-0.584089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.858731</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>-0.984352</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>0.148730</td>\n",
       "      <td>-0.576002</td>\n",
       "      <td>-1.127209</td>\n",
       "      <td>0.135239</td>\n",
       "      <td>-2.526001</td>\n",
       "      <td>-0.874003</td>\n",
       "      <td>-0.672065</td>\n",
       "      <td>-1.024450</td>\n",
       "      <td>1.060107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.246741</td>\n",
       "      <td>-1.540688</td>\n",
       "      <td>-0.173736</td>\n",
       "      <td>0.186121</td>\n",
       "      <td>0.273360</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>-0.735751</td>\n",
       "      <td>-0.534623</td>\n",
       "      <td>-0.272326</td>\n",
       "      <td>-0.240316</td>\n",
       "      <td>0.196462</td>\n",
       "      <td>-0.218107</td>\n",
       "      <td>1.164912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.181469</td>\n",
       "      <td>1.443857</td>\n",
       "      <td>-0.453647</td>\n",
       "      <td>-0.179776</td>\n",
       "      <td>-0.862378</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>1.993915</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>-1.710368</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>-0.781257</td>\n",
       "      <td>-1.071121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.819563</td>\n",
       "      <td>0.096842</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>-1.586421</td>\n",
       "      <td>0.071846</td>\n",
       "      <td>-1.046755</td>\n",
       "      <td>-0.297640</td>\n",
       "      <td>1.274354</td>\n",
       "      <td>-0.194642</td>\n",
       "      <td>-1.549125</td>\n",
       "      <td>-1.857324</td>\n",
       "      <td>-0.234793</td>\n",
       "      <td>0.067342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.849991</td>\n",
       "      <td>0.205352</td>\n",
       "      <td>-0.888543</td>\n",
       "      <td>1.466501</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>-1.092184</td>\n",
       "      <td>-0.933734</td>\n",
       "      <td>0.064675</td>\n",
       "      <td>-2.440991</td>\n",
       "      <td>-1.015456</td>\n",
       "      <td>-0.059666</td>\n",
       "      <td>-0.988334</td>\n",
       "      <td>1.042627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.229282</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>-1.121209</td>\n",
       "      <td>0.570964</td>\n",
       "      <td>-0.437700</td>\n",
       "      <td>-0.485966</td>\n",
       "      <td>-0.532777</td>\n",
       "      <td>1.497981</td>\n",
       "      <td>1.544072</td>\n",
       "      <td>-1.200528</td>\n",
       "      <td>-0.152799</td>\n",
       "      <td>-0.081302</td>\n",
       "      <td>-0.440124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.569485</td>\n",
       "      <td>-0.151394</td>\n",
       "      <td>2.260648</td>\n",
       "      <td>2.176295</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>-0.292190</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>1.312312</td>\n",
       "      <td>-1.773981</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>-0.416606</td>\n",
       "      <td>-0.314958</td>\n",
       "      <td>-0.636563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.257425</td>\n",
       "      <td>-1.486130</td>\n",
       "      <td>-0.288594</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>-0.495139</td>\n",
       "      <td>-0.636809</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>-0.162717</td>\n",
       "      <td>-0.565589</td>\n",
       "      <td>-0.377851</td>\n",
       "      <td>0.389921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.786884</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>-0.801586</td>\n",
       "      <td>-0.232461</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>1.257130</td>\n",
       "      <td>-0.209978</td>\n",
       "      <td>-0.291861</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.478781</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.409151</td>\n",
       "      <td>-0.691410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0    0.080348 -0.394817 -0.890183  0.371012 -0.729959  0.941728  2.038580   \n",
       "1   -1.115092  0.278251  1.081599 -1.335076  0.450709  0.342844  0.530724   \n",
       "2   -0.678670  0.109902  0.841250  0.052771  0.031168 -0.192856 -0.352267   \n",
       "3    1.957708  2.691383  0.204966 -0.059570 -0.575203  0.883537 -0.790650   \n",
       "4   -1.009087  0.196193  1.046665 -1.122527  0.320851 -0.093841  0.184398   \n",
       "5   -0.611866  0.137828 -0.531281 -0.444828  0.115007 -0.188192 -1.068207   \n",
       "6   -0.338056 -0.323253  1.205601  1.744052 -0.362501 -0.347251 -0.274208   \n",
       "7    1.249902 -1.540512 -0.316446  0.389658  1.098720  0.224061 -0.371540   \n",
       "8    1.960374  2.726205  0.573851 -0.488915  2.904541 -1.689157  1.238750   \n",
       "9   -0.657942 -0.054441 -0.837061 -0.077872 -0.043811 -0.086200  0.009856   \n",
       "10  -0.636011 -0.072869 -1.239630  0.456554  0.231618  0.878649 -0.860661   \n",
       "11  -1.009365  0.191193  2.148391  2.001960  0.143939 -0.012545  0.671094   \n",
       "12  -0.175675 -0.277053  1.865595  0.199379 -0.430563 -0.528763  0.068854   \n",
       "13   1.985661  2.895293  0.544915 -0.480189 -1.177606 -0.463066 -0.338959   \n",
       "14  -0.080628 -0.155687 -1.017810  0.497181 -0.715356 -1.729263  2.308184   \n",
       "15  -0.943787  0.191897  2.283650  3.452496  0.053454 -0.170607 -0.112187   \n",
       "16  -0.535033 -0.084668  0.958809 -0.641210  0.074573  0.202774 -0.423037   \n",
       "17   1.404678 -0.613735 -0.231168  0.308832 -0.178946  1.354895 -1.057672   \n",
       "18  -0.196783 -0.414817  1.490226 -2.874329 -0.251195  0.331195  1.518385   \n",
       "19   1.898128  2.359720  0.329719 -0.233685 -1.512660 -0.211246 -0.626046   \n",
       "20   1.351897 -0.876389  0.301938 -0.427105  0.437554  2.323010 -0.937386   \n",
       "21  -0.843534  0.090307 -0.500667 -0.592639  0.019766 -1.092255 -0.577864   \n",
       "22   0.050379 -0.584889 -1.041110  0.572919 -0.818853  0.079107  2.221296   \n",
       "23  -0.779425  0.097954  1.043213 -0.670624  0.244888 -0.056817 -0.533982   \n",
       "24  -0.176788 -0.304556  3.399690  2.066358 -0.485542  0.191075  0.487928   \n",
       "25   1.545173  0.222524 -0.127907  0.237873  0.282217  0.656231 -0.648339   \n",
       "26  -0.984151  0.225336 -0.140532  0.457158  0.209959 -0.100670 -0.462245   \n",
       "27  -0.808280  0.055035 -0.837358 -0.115261 -0.093117 -1.640965 -0.719455   \n",
       "28  -0.994640  0.314741  2.200903  2.732752  0.037579 -0.152012  0.626242   \n",
       "29   1.275527 -1.331517  0.176396 -0.262578 -0.404761  0.388403 -0.596450   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324  0.448404  3.017727 -0.447951 -0.095226 -0.986589  0.186189  1.900239   \n",
       "325 -0.637666  0.119517  0.803028 -2.211732  0.133059 -0.773462 -0.165652   \n",
       "326 -0.742337  0.495750 -0.303305 -0.809501 -0.052632 -0.898387 -0.673318   \n",
       "327 -0.863527  0.151054 -0.621895  1.102764  0.127329 -0.637058 -0.923254   \n",
       "328  1.250864 -1.539722 -0.320317  0.369770  1.494396  1.996060 -0.855019   \n",
       "329  1.845037  2.016857  0.079042  0.082106 -0.680868 -0.186099 -0.529998   \n",
       "330  1.330616 -1.041621 -0.163635  0.216016 -0.180344 -0.059550 -0.562350   \n",
       "331 -0.038869  0.083404 -1.058361  0.544799 -0.519040 -0.246005  1.843414   \n",
       "332 -0.802686  0.054897  2.691830  2.205935  0.040140  0.910832  0.617372   \n",
       "333  1.248989 -1.540390 -0.259678  0.338137  1.419395 -1.254890  0.247133   \n",
       "334 -0.509456  0.064296  2.700187  1.597607 -0.144598  0.310441 -0.006960   \n",
       "335  1.231409 -1.538950  0.688780 -0.936760 -0.398978 -0.730870  0.026377   \n",
       "336 -0.534067 -0.182972  2.735200  1.545595 -0.155897  0.187525  0.503330   \n",
       "337 -0.188002 -0.354648  1.814985  0.266498 -0.423748 -0.521735  0.005338   \n",
       "338 -0.069057 -0.099665 -1.132815  0.642774 -0.730913 -1.100634  2.043489   \n",
       "339 -1.086996  0.369113  0.343296 -0.357972  0.485442  1.026568 -0.074474   \n",
       "340 -0.190903 -0.402475  1.511917  0.657549 -0.407703 -0.352837 -0.155576   \n",
       "341  1.918492  2.448586  0.081510  0.095092 -0.600437  0.520436 -0.741136   \n",
       "342 -1.036607  0.232198 -0.630966 -0.585621  0.471721  1.047169 -0.671226   \n",
       "343 -0.593573  0.027279 -1.209316  1.399069  0.283667  2.809910 -1.617712   \n",
       "344 -0.793258  0.099612 -1.138782  0.220145 -0.077865 -0.385340  0.694742   \n",
       "345 -0.858731  0.142945 -0.984352  1.583382  0.148730 -0.576002 -1.127209   \n",
       "346  1.246741 -1.540688 -0.173736  0.186121  0.273360  0.841098 -0.735751   \n",
       "347  0.181469  1.443857 -0.453647 -0.179776 -0.862378 -0.038269  1.993915   \n",
       "348 -0.819563  0.096842  0.264932 -1.586421  0.071846 -1.046755 -0.297640   \n",
       "349 -0.849991  0.205352 -0.888543  1.466501  0.024785 -1.092184 -0.933734   \n",
       "350 -0.229282 -0.369674 -1.121209  0.570964 -0.437700 -0.485966 -0.532777   \n",
       "351 -0.569485 -0.151394  2.260648  2.176295 -0.257481 -0.292190  0.280509   \n",
       "352  1.257425 -1.486130 -0.288594  0.357705 -0.014140 -0.290924 -0.495139   \n",
       "353 -0.786884  0.135389 -0.801586 -0.232461  0.242451  1.257130 -0.209978   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.344230  1.603922 -0.748164 -0.248955 -0.280126  0.092254  \n",
       "1   -0.992543  0.171785 -1.591981  0.471225 -0.110589  0.393893  \n",
       "2   -0.167803 -0.456787  0.755681 -0.028307 -0.310263 -0.552134  \n",
       "3   -0.139723 -0.029203 -0.473747 -1.924215 -0.190591 -0.187401  \n",
       "4   -0.654900 -0.433389  1.050608 -0.023740 -0.310646  0.314520  \n",
       "5   -0.249310 -0.612161 -0.099950  0.827616 -0.404626 -0.524731  \n",
       "6    1.125857  0.471972 -0.353582  0.172697  0.022303  0.391402  \n",
       "7   -0.349467 -0.161251 -0.315329 -1.166842 -0.349731  0.014179  \n",
       "8    0.475148  0.423293 -0.043176  0.395698  0.118429  0.235490  \n",
       "9    0.189647  0.306190  0.377249  1.069730 -0.342973  0.129854  \n",
       "10   0.708222  1.563122 -0.154623 -0.569178 -0.148434  0.493215  \n",
       "11  -1.530055  1.489968 -2.731570  0.459341  0.036337 -0.264038  \n",
       "12   1.725652 -1.356036 -1.158937  0.687860  0.026640 -0.771315  \n",
       "13  -0.379896  0.370657  0.345026  0.494635 -0.022322  0.673355  \n",
       "14  -0.125476 -1.382472  0.852165 -1.760670 -1.251921 -0.786614  \n",
       "15  -1.098166 -0.018907  0.608938  0.653165 -0.266726 -0.091649  \n",
       "16  -0.009278  0.833602  2.085996  0.073895  0.009437  0.349866  \n",
       "17  -0.458506 -0.332231 -0.585559 -0.053712 -0.211421 -1.758293  \n",
       "18   0.603767 -0.317663 -0.738418 -0.211338  0.043863 -0.686020  \n",
       "19  -0.492962  0.273988  0.065852 -0.662386 -0.185006  0.625654  \n",
       "20  -0.412936 -0.766805 -1.074004 -1.122226 -0.137080  0.442295  \n",
       "21   1.215063 -0.036064 -0.900039 -0.542748 -0.305855  0.150305  \n",
       "22   0.277487  1.849282 -0.427553 -0.648227 -0.398190  0.193268  \n",
       "23  -1.080526  1.165125  1.450427  0.390579 -0.020257  0.948641  \n",
       "24   1.877667  0.472362 -0.851668 -0.475440  0.433045  0.416610  \n",
       "25  -0.269487 -0.078472 -0.102407 -0.167001 -0.170500  0.992560  \n",
       "26  -0.424416 -0.047900  2.007666  0.541705 -0.460942 -0.511064  \n",
       "27   1.428069  0.283175 -0.634228 -2.059973 -0.474163 -0.548719  \n",
       "28  -1.081080  0.102347 -1.146830 -0.437390 -0.314694 -0.672085  \n",
       "29  -0.757497 -0.202598 -0.207741 -0.193679 -0.247489  0.767546  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324  0.300365 -1.736481  0.142566  0.208303  3.278740  3.117442  \n",
       "325 -0.569493 -0.943414 -1.386104  0.410985 -0.254111  0.349224  \n",
       "326  1.440644  0.015810 -1.025311  0.145561 -0.137611 -0.612576  \n",
       "327  0.052150 -2.615026 -1.113191 -0.353638 -0.942371  1.263226  \n",
       "328 -0.153564 -0.572640 -0.513297 -0.060177 -0.138515  0.233746  \n",
       "329 -0.301536  0.243190 -0.029481 -1.333357 -0.259586 -1.784060  \n",
       "330 -0.604425  0.084291  0.441959  1.107620 -0.197033 -1.626711  \n",
       "331  0.062016 -1.608033  1.175863  0.911292 -0.930218 -1.208786  \n",
       "332  0.393352 -0.427835 -0.563892 -0.681889 -0.061548 -0.110975  \n",
       "333 -0.372901  0.121113 -0.375925 -1.600665 -0.439351  0.211505  \n",
       "334  0.585163  3.476441  1.317026  0.872823  0.785367  1.922435  \n",
       "335 -0.940533  0.054370  0.675256  0.089150 -0.217405 -1.520989  \n",
       "336  0.394356 -0.256181 -0.892626  1.122224  0.152020 -0.519524  \n",
       "337  1.755776 -1.094067  0.626996  0.061140 -0.036445 -0.217247  \n",
       "338 -0.061708 -1.495209  0.700378  0.447174 -1.033186  3.565111  \n",
       "339 -0.774167  0.254745 -1.067171  0.603821 -0.176953 -0.166501  \n",
       "340  1.782732 -1.411651 -1.642066  0.222688 -0.066098 -1.138598  \n",
       "341 -0.175211  0.105444 -0.164630 -1.124253 -0.171095  0.864909  \n",
       "342 -0.113630 -0.024870  1.669281  0.383386 -0.356056 -0.501093  \n",
       "343  0.692484 -1.553295  2.757605 -0.812138 -0.679586 -0.578312  \n",
       "344 -1.275697 -0.662284  0.814229 -0.241130 -0.972592 -0.584089  \n",
       "345  0.135239 -2.526001 -0.874003 -0.672065 -1.024450  1.060107  \n",
       "346 -0.534623 -0.272326 -0.240316  0.196462 -0.218107  1.164912  \n",
       "347  0.082282 -1.710368  0.748365  0.861978 -0.781257 -1.071121  \n",
       "348  1.274354 -0.194642 -1.549125 -1.857324 -0.234793  0.067342  \n",
       "349  0.064675 -2.440991 -1.015456 -0.059666 -0.988334  1.042627  \n",
       "350  1.497981  1.544072 -1.200528 -0.152799 -0.081302 -0.440124  \n",
       "351  1.312312 -1.773981  0.703413 -0.416606 -0.314958 -0.636563  \n",
       "352 -0.636809  0.011451 -0.162717 -0.565589 -0.377851  0.389921  \n",
       "353 -0.291861  0.157986  0.478781  0.014941 -0.409151 -0.691410  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(100, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(100, activation=\"linear\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 621us/step - loss: 312.1671\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 76.5509\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 101.7072\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 184us/step - loss: 91.9897\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 75.10 - 0s 169us/step - loss: 88.7789\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 66.3299\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 77.3192\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 65.4841\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.6279\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.5336\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 69.8342\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 56.8326\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 124us/step - loss: 55.6189\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 223us/step - loss: 47.6768\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 60.2101\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 57.5561\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 79.8113\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 45.4927\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 41.5123\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.5742\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.0504\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.3170\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 52.5734\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.0410\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 72.0019\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 74.8936\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.7530\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 58.6099\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 52.9725\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.7551\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.1248\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 42.3158\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.1546\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.4879\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 45.6786\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.8684\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.8857\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.8947\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.7155\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.6927\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.6705\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.7218\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 38.8665\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 30.4358\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 45.2799\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.7755\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 138us/step - loss: 31.9769\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 37.5913\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.8814\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 31.0268\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 72.0704\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 29.0081\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.2036\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.3986\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.2355\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3018\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 88us/step - loss: 34.6708\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 192us/step - loss: 36.1836\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.2348\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.5219\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.9836\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.7009\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.1224\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.7343\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.2736\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.0498\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.7672\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.2792\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.9917\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9789\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0197\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.7045\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5311\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.7275\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.3897\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7238\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6311\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.6135\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.5514\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.4650\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.8600\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.8823\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 100.479 - 0s 113us/step - loss: 37.2151\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 61.6057\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.5073\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6702\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2390\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 24.0089\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.3114\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.1728\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.7872\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.3562\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.1046\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.2093\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 23.5083\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 23.3371\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4501\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.4633\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5658\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.7873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14b8ef60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22., 13., 36., 20., 25., 27., 22., 12., 17.,  8., 23., 17., 17.,\n",
       "        14., 27.,  5., 38., 21., 21., 43., 32., 14., 37., 22., 20., 26.,\n",
       "        25., 24., 21., 13., 23., 22., 41., 32., 30.,  9., 24., 40., 22.,\n",
       "        15., 34., 26., 17.,  8., 15., 21., 14., 28., 17., 14., 21., 30.,\n",
       "        21., 34., 22., 30., 22., 24.,  5., 16., 27., 12., 17.,  9., 35.,\n",
       "        31., 15., 19., 23., 28., 21., 32., 24., 13., 21., 17., 29., 38.,\n",
       "        30.,  7.,  8., 40., 14., 13., 13., 30., 10., 30., 16., 22., 10.,\n",
       "        16., 46., 17., 12., 19., 18., 23.,  5., 18., 26.,  3., 21., 19.,\n",
       "        31., 20., 15., 20., 21., 25., 30., 26., 24., 41., 28., 25., 22.,\n",
       "        27., 26., 38., 30., 22., 31.,  7., 35., 26., 49., 31., 12., 17.,\n",
       "        14., 30., 33., 32., 26., 19., 34., 15., 21., 17., 21., 25., 26.,\n",
       "         6., 13., 22., 21., 16., 33., 28., 26., 25.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 724us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.416759490966797"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 593us/step - loss: 1430.2860\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 140.0522\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 115.4861\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 108.8594\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 103.3437\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 99.0583\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 91.6159\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 87.3324\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 81.5590\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 79.0324\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 76.2486\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 72.6326\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 71.4991\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 67.5641\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 65.7541\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 67.1840\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 61.9021\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 60.9951\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 59.7458\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 59.8866\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 57.6200\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 55.4759\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 54.2292\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.8961\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 53.1836\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 50.9152\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 51.6085\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 51.4088\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 52.8541\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.3300\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.1606\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 45.4626\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.4048\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 43.8994\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.7424\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.3451\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.5972\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.9654\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.3363\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.2372\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.6647\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.1343\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.5804\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.8044\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.1631\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.9608\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.9554\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.9999\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.9206\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.8804\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.7405\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.2825\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.2430\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.9517\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.4815\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.1299\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.2849\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.6670\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.8234\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.5231\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.7075\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.0377\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 32.5514\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.1911\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.7293\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.6269\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2469\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7495\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 33.1725\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8157\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5459\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8356\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7850\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.2217\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.3146\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.2465\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.3584\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3034\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3787\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2018\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.4619\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5501\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2197\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7754\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1844\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3732\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3590\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1024\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9009\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 32.4023\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5347\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.3175\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.9960\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1439\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.9645\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 29.2946\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6571\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2069\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2259\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 17.37 - 0s 85us/step - loss: 30.8356\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0796\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.6932\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1093\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3681\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.5496\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.5051\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1302\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.5423\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.0615\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6773\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 31.5459\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3351\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6547\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1032\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1353\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2597\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1532\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.4686\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1637\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.0405\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.0830\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.4435\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 27.8302\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.1411\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0250\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4829\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5414\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5555\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.8995\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9162\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6843\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8331\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0096\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.0064\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7588\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1040\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8423\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.7951\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.7247\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.9576\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4062\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0617\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9644\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3764\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8172\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.0791\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.5037\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.3816\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9566\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9445\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2563\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3211\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0469\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9884\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8800\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1686\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.8654\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1664\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6309\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6157\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9118\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2873\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 27.2698\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8605\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2483\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1010\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.2762\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9446\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9722\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4194\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4818\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1639\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8178\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6242\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.1341\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9679\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8571\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9185\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4472\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.6111\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.2267\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0552\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4027\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1796\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.9111\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2747\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.1724\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8242\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1163\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 24.1867\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8718\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.0213\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3789\n",
      "Epoch 194/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.3910\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3774\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.4749\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3412\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2871\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2260\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.0894\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7311\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0292\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.1462\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.7200\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.6382\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.7409\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.7101\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.1579\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.6240\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.7071\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.1643\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9349\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2379\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2659\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.6499\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7187\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5702\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7268\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.2331\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.3625\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0698\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2711\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9019\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8441\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3555\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4236\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.7398\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.1865\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.6382\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7325\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.4986\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4415\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1082\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7397\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.7805\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.6512\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 23.8870\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8032\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7838\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9511\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9221\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8637\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.7415\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6999\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.5923\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.5153\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2701\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1811\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6478\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5829\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8852\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0299\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5822\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5664\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5528\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2436\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9056\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4220\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7814\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.2324\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.2708\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9678\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.3606\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8289\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.4456\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5581\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3930\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3297\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8248\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5364\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.7692\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.8091\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.0792\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.3320\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.9491\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1656\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.7821\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7851\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.2162\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5371\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7678\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6600\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.6375\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 85us/step - loss: 24.6214\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0140\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.6957\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.2658\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1550\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.2930\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.2249\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 23.9479\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.2778\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.6823\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.2642\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.5463\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1861\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.3559\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.3250\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.8318\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.7813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12fb3ac8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25., 12., 35., 21., 23., 26., 27., 11., 21., 12., 22., 19., 23.,\n",
       "        19., 27., 10., 34., 20., 27., 41., 34., 17., 35., 25., 22., 26.,\n",
       "        25., 23., 25., 13., 23., 25., 37., 31., 31., 12., 25., 35., 22.,\n",
       "        17., 30., 26., 20., 10., 20., 19., 16., 24., 19., 13., 19., 31.,\n",
       "        22., 34., 22., 31., 20., 28.,  5., 22., 28., 12., 15., 15., 37.,\n",
       "        31., 14., 22., 21., 27., 20., 30., 22., 18., 20., 19., 31., 37.,\n",
       "        30.,  5., 12., 38., 14., 15., 18., 30.,  8., 29., 15., 21., 14.,\n",
       "        20., 43., 15., 20., 17., 21., 21.,  4., 20., 29.,  9., 19., 23.,\n",
       "        30., 26., 14., 23., 23., 22., 31., 25., 22., 39., 30., 28., 26.,\n",
       "        30., 27., 36., 29., 22., 31., 11., 35., 27., 42., 27., 18., 19.,\n",
       "        16., 29., 35., 36., 24., 25., 36., 19., 22., 20., 20., 25., 28.,\n",
       "         8., 13., 19., 25., 22., 34., 29., 26., 24.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 724us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.22670078277588"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 593us/step - loss: 1715.8811\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 236.1659\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 125.4137\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 103.8847\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 88.4467\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 79.2411\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 74.3393\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 70.0307\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 67.8342\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 63.9746\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 61.7509\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 60.1469\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 56.7534\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 54.0142\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 55.5238\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 51.1749\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 51.9219\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 48.4462\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 47.2763\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 49.8506\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 46.2598\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.3168\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 43.7778\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.2700\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.4249\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.9171\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.3520\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 38.1600\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 41.2817\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.6760\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.2371\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2145\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.9389\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.2401\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.2384\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.4299\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.8391\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.3381\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 38.3242\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 37.3766\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 34.5515\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.6604\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.3510\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.9227\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8661\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.8760\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.7851\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.9093\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.2496\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.8107\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.5252\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.3020\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.1255\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.6315\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 35.4434\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.9285\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.0993\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.3339\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.1187\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.6201\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.2814\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.0217\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.2311\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.3634\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.1371\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.1648\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.8379\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.0871\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.1297\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.8434\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 32.9993\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.9725\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.1823\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.9435\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9692\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8430\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9294\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5608\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6836\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.9943\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.2618\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 31.5288\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.5435\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.2713\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9726\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.3898\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.4398\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.4896\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.8013\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.9311\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 31.3127\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.7860\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5225\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.1184\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.7432\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 37.0815\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2107\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.3812\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.4268\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2567\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8655\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.0428\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5345\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1343\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7648\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.4743\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5518\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2246\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9351\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.6849\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5318\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5081\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.5510\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1699\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 37.4330\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.6267\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 29.2182\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9813\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2613\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8290\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.6510\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 32.9139\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.0168\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.2235\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.8679\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2753\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0673\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.6450\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.6062\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1909\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.7590\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.0045\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.4284\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4615\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1799\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.0936\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3084\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0633\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.7207\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.0973\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2069\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1789\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 27.6878\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.0939\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2619\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.9193\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1555\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.6660\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.0462\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0951\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.2448\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8784\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.2747\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.3266\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.8348\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2099\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1928\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6072\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4787\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.2449\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.3381\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6301\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.3086\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.8358\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5172\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5097\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.6536\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2077\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3242\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4620\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0642\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.3868\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2214\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1253\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6133\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8666\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5544\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5815\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1495\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8430\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.5104\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9200\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.6004\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5583\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8827\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.9550\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1771\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8815\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9517\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 27.5428\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.6819\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4471\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5187\n",
      "Epoch 194/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.4554\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.5637\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4235\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.6776\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 27.5824\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4229\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9873\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0307\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9205\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.7871\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.6064\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2603\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9444\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4753\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6108\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2923\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8568\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.8702\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.5247\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8251\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4688\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4851\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.2455\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.5915\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9671\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0530\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4078\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2907\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7442\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9643\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5107\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.6618\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1127\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1961\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8546\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.2339\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.0667\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.9864\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9889\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1654\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.7784\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.7369\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.8287\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.9199\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9086\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4886\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5300\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4603\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5110\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.1839\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3280\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5191\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.1796\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4671\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7827\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6529\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0552\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3689\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7468\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7428\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.8720\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3731\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3466\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1490\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.6311\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2857\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4005\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1808\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5436\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5535\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2772\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8660\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.6460\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 23.4998\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2207\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.6104\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1329\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4607\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.8967\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1086\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7551\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.3941\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.0046\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4663\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.5190\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.9479\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.6615\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.4609\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0089\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2866\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 25.4026\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8840\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1252\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0474\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7888\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3414\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3299\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6930\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8803\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3482\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.7214\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5157\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.5731\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9499\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.3349\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.4598\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.0668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1734e128>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27., 15., 34., 23., 25., 28., 29., 15., 21., 16., 25., 24., 24.,\n",
       "        22., 25., 10., 36., 26., 26., 43., 33., 17., 38., 25., 23., 27.,\n",
       "        27., 25., 25., 13., 25., 25., 39., 32., 30., 16., 26., 39., 23.,\n",
       "        19., 32., 27., 18., 13., 20., 20., 19., 28., 22., 14., 20., 30.,\n",
       "        24., 32., 26., 32., 23., 27.,  7., 24., 27., 13., 17., 16., 35.,\n",
       "        32., 18., 23., 22., 28., 26., 31., 23., 22., 21., 23., 32., 37.,\n",
       "        29., 12.,  7., 39., 19., 18., 22., 29., 14., 29., 18., 23., 15.,\n",
       "        22., 47., 24., 22., 21., 24., 24.,  9., 23., 29., 11., 22., 24.,\n",
       "        29., 28., 16., 23., 23., 24., 29., 25., 23., 41., 32., 26., 28.,\n",
       "        29., 29., 36., 30., 23., 33., 12., 34., 28., 45., 27., 22., 22.,\n",
       "        19., 28., 36., 35., 28., 28., 36., 20., 21., 22., 23., 27., 30.,\n",
       "         9., 14., 21., 26., 20., 35., 31., 28., 24.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 921us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.49707794189453"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080348</td>\n",
       "      <td>-0.394817</td>\n",
       "      <td>-0.890183</td>\n",
       "      <td>0.371012</td>\n",
       "      <td>-0.729959</td>\n",
       "      <td>0.941728</td>\n",
       "      <td>2.038580</td>\n",
       "      <td>0.344230</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>-0.748164</td>\n",
       "      <td>-0.248955</td>\n",
       "      <td>-0.280126</td>\n",
       "      <td>0.092254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.115092</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>1.081599</td>\n",
       "      <td>-1.335076</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>-1.591981</td>\n",
       "      <td>0.471225</td>\n",
       "      <td>-0.110589</td>\n",
       "      <td>0.393893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.678670</td>\n",
       "      <td>0.109902</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>-0.192856</td>\n",
       "      <td>-0.352267</td>\n",
       "      <td>-0.167803</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>0.755681</td>\n",
       "      <td>-0.028307</td>\n",
       "      <td>-0.310263</td>\n",
       "      <td>-0.552134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.957708</td>\n",
       "      <td>2.691383</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.575203</td>\n",
       "      <td>0.883537</td>\n",
       "      <td>-0.790650</td>\n",
       "      <td>-0.139723</td>\n",
       "      <td>-0.029203</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>-1.924215</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>-0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.009087</td>\n",
       "      <td>0.196193</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>-1.122527</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.184398</td>\n",
       "      <td>-0.654900</td>\n",
       "      <td>-0.433389</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>-0.310646</td>\n",
       "      <td>0.314520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.611866</td>\n",
       "      <td>0.137828</td>\n",
       "      <td>-0.531281</td>\n",
       "      <td>-0.444828</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>-0.188192</td>\n",
       "      <td>-1.068207</td>\n",
       "      <td>-0.249310</td>\n",
       "      <td>-0.612161</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>-0.404626</td>\n",
       "      <td>-0.524731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.338056</td>\n",
       "      <td>-0.323253</td>\n",
       "      <td>1.205601</td>\n",
       "      <td>1.744052</td>\n",
       "      <td>-0.362501</td>\n",
       "      <td>-0.347251</td>\n",
       "      <td>-0.274208</td>\n",
       "      <td>1.125857</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>-0.353582</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.391402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.249902</td>\n",
       "      <td>-1.540512</td>\n",
       "      <td>-0.316446</td>\n",
       "      <td>0.389658</td>\n",
       "      <td>1.098720</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>-0.371540</td>\n",
       "      <td>-0.349467</td>\n",
       "      <td>-0.161251</td>\n",
       "      <td>-0.315329</td>\n",
       "      <td>-1.166842</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>0.014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.960374</td>\n",
       "      <td>2.726205</td>\n",
       "      <td>0.573851</td>\n",
       "      <td>-0.488915</td>\n",
       "      <td>2.904541</td>\n",
       "      <td>-1.689157</td>\n",
       "      <td>1.238750</td>\n",
       "      <td>0.475148</td>\n",
       "      <td>0.423293</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.657942</td>\n",
       "      <td>-0.054441</td>\n",
       "      <td>-0.837061</td>\n",
       "      <td>-0.077872</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.086200</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>0.306190</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>1.069730</td>\n",
       "      <td>-0.342973</td>\n",
       "      <td>0.129854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.636011</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-1.239630</td>\n",
       "      <td>0.456554</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>-0.860661</td>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.563122</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>-0.569178</td>\n",
       "      <td>-0.148434</td>\n",
       "      <td>0.493215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.009365</td>\n",
       "      <td>0.191193</td>\n",
       "      <td>2.148391</td>\n",
       "      <td>2.001960</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>-1.530055</td>\n",
       "      <td>1.489968</td>\n",
       "      <td>-2.731570</td>\n",
       "      <td>0.459341</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>-0.264038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.277053</td>\n",
       "      <td>1.865595</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>-0.430563</td>\n",
       "      <td>-0.528763</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>1.725652</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-1.158937</td>\n",
       "      <td>0.687860</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>-0.771315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.985661</td>\n",
       "      <td>2.895293</td>\n",
       "      <td>0.544915</td>\n",
       "      <td>-0.480189</td>\n",
       "      <td>-1.177606</td>\n",
       "      <td>-0.463066</td>\n",
       "      <td>-0.338959</td>\n",
       "      <td>-0.379896</td>\n",
       "      <td>0.370657</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>-0.022322</td>\n",
       "      <td>0.673355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.155687</td>\n",
       "      <td>-1.017810</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>-0.715356</td>\n",
       "      <td>-1.729263</td>\n",
       "      <td>2.308184</td>\n",
       "      <td>-0.125476</td>\n",
       "      <td>-1.382472</td>\n",
       "      <td>0.852165</td>\n",
       "      <td>-1.760670</td>\n",
       "      <td>-1.251921</td>\n",
       "      <td>-0.786614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.943787</td>\n",
       "      <td>0.191897</td>\n",
       "      <td>2.283650</td>\n",
       "      <td>3.452496</td>\n",
       "      <td>0.053454</td>\n",
       "      <td>-0.170607</td>\n",
       "      <td>-0.112187</td>\n",
       "      <td>-1.098166</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>0.608938</td>\n",
       "      <td>0.653165</td>\n",
       "      <td>-0.266726</td>\n",
       "      <td>-0.091649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.535033</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>-0.641210</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>0.202774</td>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>0.833602</td>\n",
       "      <td>2.085996</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.404678</td>\n",
       "      <td>-0.613735</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.308832</td>\n",
       "      <td>-0.178946</td>\n",
       "      <td>1.354895</td>\n",
       "      <td>-1.057672</td>\n",
       "      <td>-0.458506</td>\n",
       "      <td>-0.332231</td>\n",
       "      <td>-0.585559</td>\n",
       "      <td>-0.053712</td>\n",
       "      <td>-0.211421</td>\n",
       "      <td>-1.758293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.196783</td>\n",
       "      <td>-0.414817</td>\n",
       "      <td>1.490226</td>\n",
       "      <td>-2.874329</td>\n",
       "      <td>-0.251195</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.518385</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-0.317663</td>\n",
       "      <td>-0.738418</td>\n",
       "      <td>-0.211338</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>-0.686020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.898128</td>\n",
       "      <td>2.359720</td>\n",
       "      <td>0.329719</td>\n",
       "      <td>-0.233685</td>\n",
       "      <td>-1.512660</td>\n",
       "      <td>-0.211246</td>\n",
       "      <td>-0.626046</td>\n",
       "      <td>-0.492962</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.065852</td>\n",
       "      <td>-0.662386</td>\n",
       "      <td>-0.185006</td>\n",
       "      <td>0.625654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.351897</td>\n",
       "      <td>-0.876389</td>\n",
       "      <td>0.301938</td>\n",
       "      <td>-0.427105</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>2.323010</td>\n",
       "      <td>-0.937386</td>\n",
       "      <td>-0.412936</td>\n",
       "      <td>-0.766805</td>\n",
       "      <td>-1.074004</td>\n",
       "      <td>-1.122226</td>\n",
       "      <td>-0.137080</td>\n",
       "      <td>0.442295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.843534</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.592639</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>-1.092255</td>\n",
       "      <td>-0.577864</td>\n",
       "      <td>1.215063</td>\n",
       "      <td>-0.036064</td>\n",
       "      <td>-0.900039</td>\n",
       "      <td>-0.542748</td>\n",
       "      <td>-0.305855</td>\n",
       "      <td>0.150305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050379</td>\n",
       "      <td>-0.584889</td>\n",
       "      <td>-1.041110</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>-0.818853</td>\n",
       "      <td>0.079107</td>\n",
       "      <td>2.221296</td>\n",
       "      <td>0.277487</td>\n",
       "      <td>1.849282</td>\n",
       "      <td>-0.427553</td>\n",
       "      <td>-0.648227</td>\n",
       "      <td>-0.398190</td>\n",
       "      <td>0.193268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.779425</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>1.043213</td>\n",
       "      <td>-0.670624</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.533982</td>\n",
       "      <td>-1.080526</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>1.450427</td>\n",
       "      <td>0.390579</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>0.948641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.304556</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.066358</td>\n",
       "      <td>-0.485542</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>1.877667</td>\n",
       "      <td>0.472362</td>\n",
       "      <td>-0.851668</td>\n",
       "      <td>-0.475440</td>\n",
       "      <td>0.433045</td>\n",
       "      <td>0.416610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.545173</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>-0.127907</td>\n",
       "      <td>0.237873</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>-0.648339</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>-0.167001</td>\n",
       "      <td>-0.170500</td>\n",
       "      <td>0.992560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.225336</td>\n",
       "      <td>-0.140532</td>\n",
       "      <td>0.457158</td>\n",
       "      <td>0.209959</td>\n",
       "      <td>-0.100670</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>2.007666</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>-0.460942</td>\n",
       "      <td>-0.511064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.808280</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>-0.837358</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.093117</td>\n",
       "      <td>-1.640965</td>\n",
       "      <td>-0.719455</td>\n",
       "      <td>1.428069</td>\n",
       "      <td>0.283175</td>\n",
       "      <td>-0.634228</td>\n",
       "      <td>-2.059973</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.548719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.994640</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>2.200903</td>\n",
       "      <td>2.732752</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>-0.152012</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>-1.081080</td>\n",
       "      <td>0.102347</td>\n",
       "      <td>-1.146830</td>\n",
       "      <td>-0.437390</td>\n",
       "      <td>-0.314694</td>\n",
       "      <td>-0.672085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.275527</td>\n",
       "      <td>-1.331517</td>\n",
       "      <td>0.176396</td>\n",
       "      <td>-0.262578</td>\n",
       "      <td>-0.404761</td>\n",
       "      <td>0.388403</td>\n",
       "      <td>-0.596450</td>\n",
       "      <td>-0.757497</td>\n",
       "      <td>-0.202598</td>\n",
       "      <td>-0.207741</td>\n",
       "      <td>-0.193679</td>\n",
       "      <td>-0.247489</td>\n",
       "      <td>0.767546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.448404</td>\n",
       "      <td>3.017727</td>\n",
       "      <td>-0.447951</td>\n",
       "      <td>-0.095226</td>\n",
       "      <td>-0.986589</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>1.900239</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>-1.736481</td>\n",
       "      <td>0.142566</td>\n",
       "      <td>0.208303</td>\n",
       "      <td>3.278740</td>\n",
       "      <td>3.117442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.637666</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.803028</td>\n",
       "      <td>-2.211732</td>\n",
       "      <td>0.133059</td>\n",
       "      <td>-0.773462</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>-0.569493</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-1.386104</td>\n",
       "      <td>0.410985</td>\n",
       "      <td>-0.254111</td>\n",
       "      <td>0.349224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.742337</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>-0.303305</td>\n",
       "      <td>-0.809501</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.673318</td>\n",
       "      <td>1.440644</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>-1.025311</td>\n",
       "      <td>0.145561</td>\n",
       "      <td>-0.137611</td>\n",
       "      <td>-0.612576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.863527</td>\n",
       "      <td>0.151054</td>\n",
       "      <td>-0.621895</td>\n",
       "      <td>1.102764</td>\n",
       "      <td>0.127329</td>\n",
       "      <td>-0.637058</td>\n",
       "      <td>-0.923254</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>-2.615026</td>\n",
       "      <td>-1.113191</td>\n",
       "      <td>-0.353638</td>\n",
       "      <td>-0.942371</td>\n",
       "      <td>1.263226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.250864</td>\n",
       "      <td>-1.539722</td>\n",
       "      <td>-0.320317</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>1.494396</td>\n",
       "      <td>1.996060</td>\n",
       "      <td>-0.855019</td>\n",
       "      <td>-0.153564</td>\n",
       "      <td>-0.572640</td>\n",
       "      <td>-0.513297</td>\n",
       "      <td>-0.060177</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>0.233746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.845037</td>\n",
       "      <td>2.016857</td>\n",
       "      <td>0.079042</td>\n",
       "      <td>0.082106</td>\n",
       "      <td>-0.680868</td>\n",
       "      <td>-0.186099</td>\n",
       "      <td>-0.529998</td>\n",
       "      <td>-0.301536</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>-0.029481</td>\n",
       "      <td>-1.333357</td>\n",
       "      <td>-0.259586</td>\n",
       "      <td>-1.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.330616</td>\n",
       "      <td>-1.041621</td>\n",
       "      <td>-0.163635</td>\n",
       "      <td>0.216016</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>-0.562350</td>\n",
       "      <td>-0.604425</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>0.441959</td>\n",
       "      <td>1.107620</td>\n",
       "      <td>-0.197033</td>\n",
       "      <td>-1.626711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.038869</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>-1.058361</td>\n",
       "      <td>0.544799</td>\n",
       "      <td>-0.519040</td>\n",
       "      <td>-0.246005</td>\n",
       "      <td>1.843414</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>-1.608033</td>\n",
       "      <td>1.175863</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>-0.930218</td>\n",
       "      <td>-1.208786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.802686</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>2.691830</td>\n",
       "      <td>2.205935</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.910832</td>\n",
       "      <td>0.617372</td>\n",
       "      <td>0.393352</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>-0.563892</td>\n",
       "      <td>-0.681889</td>\n",
       "      <td>-0.061548</td>\n",
       "      <td>-0.110975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.248989</td>\n",
       "      <td>-1.540390</td>\n",
       "      <td>-0.259678</td>\n",
       "      <td>0.338137</td>\n",
       "      <td>1.419395</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>0.247133</td>\n",
       "      <td>-0.372901</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>-0.375925</td>\n",
       "      <td>-1.600665</td>\n",
       "      <td>-0.439351</td>\n",
       "      <td>0.211505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.509456</td>\n",
       "      <td>0.064296</td>\n",
       "      <td>2.700187</td>\n",
       "      <td>1.597607</td>\n",
       "      <td>-0.144598</td>\n",
       "      <td>0.310441</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>0.585163</td>\n",
       "      <td>3.476441</td>\n",
       "      <td>1.317026</td>\n",
       "      <td>0.872823</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>1.922435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.231409</td>\n",
       "      <td>-1.538950</td>\n",
       "      <td>0.688780</td>\n",
       "      <td>-0.936760</td>\n",
       "      <td>-0.398978</td>\n",
       "      <td>-0.730870</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>-0.940533</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>0.675256</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>-0.217405</td>\n",
       "      <td>-1.520989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.534067</td>\n",
       "      <td>-0.182972</td>\n",
       "      <td>2.735200</td>\n",
       "      <td>1.545595</td>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.187525</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>-0.256181</td>\n",
       "      <td>-0.892626</td>\n",
       "      <td>1.122224</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>-0.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-0.188002</td>\n",
       "      <td>-0.354648</td>\n",
       "      <td>1.814985</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>-0.423748</td>\n",
       "      <td>-0.521735</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.755776</td>\n",
       "      <td>-1.094067</td>\n",
       "      <td>0.626996</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>-0.217247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.069057</td>\n",
       "      <td>-0.099665</td>\n",
       "      <td>-1.132815</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>-0.730913</td>\n",
       "      <td>-1.100634</td>\n",
       "      <td>2.043489</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-1.495209</td>\n",
       "      <td>0.700378</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>-1.033186</td>\n",
       "      <td>3.565111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-1.086996</td>\n",
       "      <td>0.369113</td>\n",
       "      <td>0.343296</td>\n",
       "      <td>-0.357972</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>1.026568</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>-0.774167</td>\n",
       "      <td>0.254745</td>\n",
       "      <td>-1.067171</td>\n",
       "      <td>0.603821</td>\n",
       "      <td>-0.176953</td>\n",
       "      <td>-0.166501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.190903</td>\n",
       "      <td>-0.402475</td>\n",
       "      <td>1.511917</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>-0.407703</td>\n",
       "      <td>-0.352837</td>\n",
       "      <td>-0.155576</td>\n",
       "      <td>1.782732</td>\n",
       "      <td>-1.411651</td>\n",
       "      <td>-1.642066</td>\n",
       "      <td>0.222688</td>\n",
       "      <td>-0.066098</td>\n",
       "      <td>-1.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.918492</td>\n",
       "      <td>2.448586</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.520436</td>\n",
       "      <td>-0.741136</td>\n",
       "      <td>-0.175211</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>-0.164630</td>\n",
       "      <td>-1.124253</td>\n",
       "      <td>-0.171095</td>\n",
       "      <td>0.864909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-1.036607</td>\n",
       "      <td>0.232198</td>\n",
       "      <td>-0.630966</td>\n",
       "      <td>-0.585621</td>\n",
       "      <td>0.471721</td>\n",
       "      <td>1.047169</td>\n",
       "      <td>-0.671226</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>1.669281</td>\n",
       "      <td>0.383386</td>\n",
       "      <td>-0.356056</td>\n",
       "      <td>-0.501093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.593573</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>-1.209316</td>\n",
       "      <td>1.399069</td>\n",
       "      <td>0.283667</td>\n",
       "      <td>2.809910</td>\n",
       "      <td>-1.617712</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>-1.553295</td>\n",
       "      <td>2.757605</td>\n",
       "      <td>-0.812138</td>\n",
       "      <td>-0.679586</td>\n",
       "      <td>-0.578312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.793258</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>-1.138782</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>0.694742</td>\n",
       "      <td>-1.275697</td>\n",
       "      <td>-0.662284</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>-0.241130</td>\n",
       "      <td>-0.972592</td>\n",
       "      <td>-0.584089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.858731</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>-0.984352</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>0.148730</td>\n",
       "      <td>-0.576002</td>\n",
       "      <td>-1.127209</td>\n",
       "      <td>0.135239</td>\n",
       "      <td>-2.526001</td>\n",
       "      <td>-0.874003</td>\n",
       "      <td>-0.672065</td>\n",
       "      <td>-1.024450</td>\n",
       "      <td>1.060107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.246741</td>\n",
       "      <td>-1.540688</td>\n",
       "      <td>-0.173736</td>\n",
       "      <td>0.186121</td>\n",
       "      <td>0.273360</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>-0.735751</td>\n",
       "      <td>-0.534623</td>\n",
       "      <td>-0.272326</td>\n",
       "      <td>-0.240316</td>\n",
       "      <td>0.196462</td>\n",
       "      <td>-0.218107</td>\n",
       "      <td>1.164912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.181469</td>\n",
       "      <td>1.443857</td>\n",
       "      <td>-0.453647</td>\n",
       "      <td>-0.179776</td>\n",
       "      <td>-0.862378</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>1.993915</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>-1.710368</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>-0.781257</td>\n",
       "      <td>-1.071121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.819563</td>\n",
       "      <td>0.096842</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>-1.586421</td>\n",
       "      <td>0.071846</td>\n",
       "      <td>-1.046755</td>\n",
       "      <td>-0.297640</td>\n",
       "      <td>1.274354</td>\n",
       "      <td>-0.194642</td>\n",
       "      <td>-1.549125</td>\n",
       "      <td>-1.857324</td>\n",
       "      <td>-0.234793</td>\n",
       "      <td>0.067342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.849991</td>\n",
       "      <td>0.205352</td>\n",
       "      <td>-0.888543</td>\n",
       "      <td>1.466501</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>-1.092184</td>\n",
       "      <td>-0.933734</td>\n",
       "      <td>0.064675</td>\n",
       "      <td>-2.440991</td>\n",
       "      <td>-1.015456</td>\n",
       "      <td>-0.059666</td>\n",
       "      <td>-0.988334</td>\n",
       "      <td>1.042627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.229282</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>-1.121209</td>\n",
       "      <td>0.570964</td>\n",
       "      <td>-0.437700</td>\n",
       "      <td>-0.485966</td>\n",
       "      <td>-0.532777</td>\n",
       "      <td>1.497981</td>\n",
       "      <td>1.544072</td>\n",
       "      <td>-1.200528</td>\n",
       "      <td>-0.152799</td>\n",
       "      <td>-0.081302</td>\n",
       "      <td>-0.440124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.569485</td>\n",
       "      <td>-0.151394</td>\n",
       "      <td>2.260648</td>\n",
       "      <td>2.176295</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>-0.292190</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>1.312312</td>\n",
       "      <td>-1.773981</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>-0.416606</td>\n",
       "      <td>-0.314958</td>\n",
       "      <td>-0.636563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.257425</td>\n",
       "      <td>-1.486130</td>\n",
       "      <td>-0.288594</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>-0.495139</td>\n",
       "      <td>-0.636809</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>-0.162717</td>\n",
       "      <td>-0.565589</td>\n",
       "      <td>-0.377851</td>\n",
       "      <td>0.389921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.786884</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>-0.801586</td>\n",
       "      <td>-0.232461</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>1.257130</td>\n",
       "      <td>-0.209978</td>\n",
       "      <td>-0.291861</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.478781</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.409151</td>\n",
       "      <td>-0.691410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0    0.080348 -0.394817 -0.890183  0.371012 -0.729959  0.941728  2.038580   \n",
       "1   -1.115092  0.278251  1.081599 -1.335076  0.450709  0.342844  0.530724   \n",
       "2   -0.678670  0.109902  0.841250  0.052771  0.031168 -0.192856 -0.352267   \n",
       "3    1.957708  2.691383  0.204966 -0.059570 -0.575203  0.883537 -0.790650   \n",
       "4   -1.009087  0.196193  1.046665 -1.122527  0.320851 -0.093841  0.184398   \n",
       "5   -0.611866  0.137828 -0.531281 -0.444828  0.115007 -0.188192 -1.068207   \n",
       "6   -0.338056 -0.323253  1.205601  1.744052 -0.362501 -0.347251 -0.274208   \n",
       "7    1.249902 -1.540512 -0.316446  0.389658  1.098720  0.224061 -0.371540   \n",
       "8    1.960374  2.726205  0.573851 -0.488915  2.904541 -1.689157  1.238750   \n",
       "9   -0.657942 -0.054441 -0.837061 -0.077872 -0.043811 -0.086200  0.009856   \n",
       "10  -0.636011 -0.072869 -1.239630  0.456554  0.231618  0.878649 -0.860661   \n",
       "11  -1.009365  0.191193  2.148391  2.001960  0.143939 -0.012545  0.671094   \n",
       "12  -0.175675 -0.277053  1.865595  0.199379 -0.430563 -0.528763  0.068854   \n",
       "13   1.985661  2.895293  0.544915 -0.480189 -1.177606 -0.463066 -0.338959   \n",
       "14  -0.080628 -0.155687 -1.017810  0.497181 -0.715356 -1.729263  2.308184   \n",
       "15  -0.943787  0.191897  2.283650  3.452496  0.053454 -0.170607 -0.112187   \n",
       "16  -0.535033 -0.084668  0.958809 -0.641210  0.074573  0.202774 -0.423037   \n",
       "17   1.404678 -0.613735 -0.231168  0.308832 -0.178946  1.354895 -1.057672   \n",
       "18  -0.196783 -0.414817  1.490226 -2.874329 -0.251195  0.331195  1.518385   \n",
       "19   1.898128  2.359720  0.329719 -0.233685 -1.512660 -0.211246 -0.626046   \n",
       "20   1.351897 -0.876389  0.301938 -0.427105  0.437554  2.323010 -0.937386   \n",
       "21  -0.843534  0.090307 -0.500667 -0.592639  0.019766 -1.092255 -0.577864   \n",
       "22   0.050379 -0.584889 -1.041110  0.572919 -0.818853  0.079107  2.221296   \n",
       "23  -0.779425  0.097954  1.043213 -0.670624  0.244888 -0.056817 -0.533982   \n",
       "24  -0.176788 -0.304556  3.399690  2.066358 -0.485542  0.191075  0.487928   \n",
       "25   1.545173  0.222524 -0.127907  0.237873  0.282217  0.656231 -0.648339   \n",
       "26  -0.984151  0.225336 -0.140532  0.457158  0.209959 -0.100670 -0.462245   \n",
       "27  -0.808280  0.055035 -0.837358 -0.115261 -0.093117 -1.640965 -0.719455   \n",
       "28  -0.994640  0.314741  2.200903  2.732752  0.037579 -0.152012  0.626242   \n",
       "29   1.275527 -1.331517  0.176396 -0.262578 -0.404761  0.388403 -0.596450   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324  0.448404  3.017727 -0.447951 -0.095226 -0.986589  0.186189  1.900239   \n",
       "325 -0.637666  0.119517  0.803028 -2.211732  0.133059 -0.773462 -0.165652   \n",
       "326 -0.742337  0.495750 -0.303305 -0.809501 -0.052632 -0.898387 -0.673318   \n",
       "327 -0.863527  0.151054 -0.621895  1.102764  0.127329 -0.637058 -0.923254   \n",
       "328  1.250864 -1.539722 -0.320317  0.369770  1.494396  1.996060 -0.855019   \n",
       "329  1.845037  2.016857  0.079042  0.082106 -0.680868 -0.186099 -0.529998   \n",
       "330  1.330616 -1.041621 -0.163635  0.216016 -0.180344 -0.059550 -0.562350   \n",
       "331 -0.038869  0.083404 -1.058361  0.544799 -0.519040 -0.246005  1.843414   \n",
       "332 -0.802686  0.054897  2.691830  2.205935  0.040140  0.910832  0.617372   \n",
       "333  1.248989 -1.540390 -0.259678  0.338137  1.419395 -1.254890  0.247133   \n",
       "334 -0.509456  0.064296  2.700187  1.597607 -0.144598  0.310441 -0.006960   \n",
       "335  1.231409 -1.538950  0.688780 -0.936760 -0.398978 -0.730870  0.026377   \n",
       "336 -0.534067 -0.182972  2.735200  1.545595 -0.155897  0.187525  0.503330   \n",
       "337 -0.188002 -0.354648  1.814985  0.266498 -0.423748 -0.521735  0.005338   \n",
       "338 -0.069057 -0.099665 -1.132815  0.642774 -0.730913 -1.100634  2.043489   \n",
       "339 -1.086996  0.369113  0.343296 -0.357972  0.485442  1.026568 -0.074474   \n",
       "340 -0.190903 -0.402475  1.511917  0.657549 -0.407703 -0.352837 -0.155576   \n",
       "341  1.918492  2.448586  0.081510  0.095092 -0.600437  0.520436 -0.741136   \n",
       "342 -1.036607  0.232198 -0.630966 -0.585621  0.471721  1.047169 -0.671226   \n",
       "343 -0.593573  0.027279 -1.209316  1.399069  0.283667  2.809910 -1.617712   \n",
       "344 -0.793258  0.099612 -1.138782  0.220145 -0.077865 -0.385340  0.694742   \n",
       "345 -0.858731  0.142945 -0.984352  1.583382  0.148730 -0.576002 -1.127209   \n",
       "346  1.246741 -1.540688 -0.173736  0.186121  0.273360  0.841098 -0.735751   \n",
       "347  0.181469  1.443857 -0.453647 -0.179776 -0.862378 -0.038269  1.993915   \n",
       "348 -0.819563  0.096842  0.264932 -1.586421  0.071846 -1.046755 -0.297640   \n",
       "349 -0.849991  0.205352 -0.888543  1.466501  0.024785 -1.092184 -0.933734   \n",
       "350 -0.229282 -0.369674 -1.121209  0.570964 -0.437700 -0.485966 -0.532777   \n",
       "351 -0.569485 -0.151394  2.260648  2.176295 -0.257481 -0.292190  0.280509   \n",
       "352  1.257425 -1.486130 -0.288594  0.357705 -0.014140 -0.290924 -0.495139   \n",
       "353 -0.786884  0.135389 -0.801586 -0.232461  0.242451  1.257130 -0.209978   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.344230  1.603922 -0.748164 -0.248955 -0.280126  0.092254  \n",
       "1   -0.992543  0.171785 -1.591981  0.471225 -0.110589  0.393893  \n",
       "2   -0.167803 -0.456787  0.755681 -0.028307 -0.310263 -0.552134  \n",
       "3   -0.139723 -0.029203 -0.473747 -1.924215 -0.190591 -0.187401  \n",
       "4   -0.654900 -0.433389  1.050608 -0.023740 -0.310646  0.314520  \n",
       "5   -0.249310 -0.612161 -0.099950  0.827616 -0.404626 -0.524731  \n",
       "6    1.125857  0.471972 -0.353582  0.172697  0.022303  0.391402  \n",
       "7   -0.349467 -0.161251 -0.315329 -1.166842 -0.349731  0.014179  \n",
       "8    0.475148  0.423293 -0.043176  0.395698  0.118429  0.235490  \n",
       "9    0.189647  0.306190  0.377249  1.069730 -0.342973  0.129854  \n",
       "10   0.708222  1.563122 -0.154623 -0.569178 -0.148434  0.493215  \n",
       "11  -1.530055  1.489968 -2.731570  0.459341  0.036337 -0.264038  \n",
       "12   1.725652 -1.356036 -1.158937  0.687860  0.026640 -0.771315  \n",
       "13  -0.379896  0.370657  0.345026  0.494635 -0.022322  0.673355  \n",
       "14  -0.125476 -1.382472  0.852165 -1.760670 -1.251921 -0.786614  \n",
       "15  -1.098166 -0.018907  0.608938  0.653165 -0.266726 -0.091649  \n",
       "16  -0.009278  0.833602  2.085996  0.073895  0.009437  0.349866  \n",
       "17  -0.458506 -0.332231 -0.585559 -0.053712 -0.211421 -1.758293  \n",
       "18   0.603767 -0.317663 -0.738418 -0.211338  0.043863 -0.686020  \n",
       "19  -0.492962  0.273988  0.065852 -0.662386 -0.185006  0.625654  \n",
       "20  -0.412936 -0.766805 -1.074004 -1.122226 -0.137080  0.442295  \n",
       "21   1.215063 -0.036064 -0.900039 -0.542748 -0.305855  0.150305  \n",
       "22   0.277487  1.849282 -0.427553 -0.648227 -0.398190  0.193268  \n",
       "23  -1.080526  1.165125  1.450427  0.390579 -0.020257  0.948641  \n",
       "24   1.877667  0.472362 -0.851668 -0.475440  0.433045  0.416610  \n",
       "25  -0.269487 -0.078472 -0.102407 -0.167001 -0.170500  0.992560  \n",
       "26  -0.424416 -0.047900  2.007666  0.541705 -0.460942 -0.511064  \n",
       "27   1.428069  0.283175 -0.634228 -2.059973 -0.474163 -0.548719  \n",
       "28  -1.081080  0.102347 -1.146830 -0.437390 -0.314694 -0.672085  \n",
       "29  -0.757497 -0.202598 -0.207741 -0.193679 -0.247489  0.767546  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324  0.300365 -1.736481  0.142566  0.208303  3.278740  3.117442  \n",
       "325 -0.569493 -0.943414 -1.386104  0.410985 -0.254111  0.349224  \n",
       "326  1.440644  0.015810 -1.025311  0.145561 -0.137611 -0.612576  \n",
       "327  0.052150 -2.615026 -1.113191 -0.353638 -0.942371  1.263226  \n",
       "328 -0.153564 -0.572640 -0.513297 -0.060177 -0.138515  0.233746  \n",
       "329 -0.301536  0.243190 -0.029481 -1.333357 -0.259586 -1.784060  \n",
       "330 -0.604425  0.084291  0.441959  1.107620 -0.197033 -1.626711  \n",
       "331  0.062016 -1.608033  1.175863  0.911292 -0.930218 -1.208786  \n",
       "332  0.393352 -0.427835 -0.563892 -0.681889 -0.061548 -0.110975  \n",
       "333 -0.372901  0.121113 -0.375925 -1.600665 -0.439351  0.211505  \n",
       "334  0.585163  3.476441  1.317026  0.872823  0.785367  1.922435  \n",
       "335 -0.940533  0.054370  0.675256  0.089150 -0.217405 -1.520989  \n",
       "336  0.394356 -0.256181 -0.892626  1.122224  0.152020 -0.519524  \n",
       "337  1.755776 -1.094067  0.626996  0.061140 -0.036445 -0.217247  \n",
       "338 -0.061708 -1.495209  0.700378  0.447174 -1.033186  3.565111  \n",
       "339 -0.774167  0.254745 -1.067171  0.603821 -0.176953 -0.166501  \n",
       "340  1.782732 -1.411651 -1.642066  0.222688 -0.066098 -1.138598  \n",
       "341 -0.175211  0.105444 -0.164630 -1.124253 -0.171095  0.864909  \n",
       "342 -0.113630 -0.024870  1.669281  0.383386 -0.356056 -0.501093  \n",
       "343  0.692484 -1.553295  2.757605 -0.812138 -0.679586 -0.578312  \n",
       "344 -1.275697 -0.662284  0.814229 -0.241130 -0.972592 -0.584089  \n",
       "345  0.135239 -2.526001 -0.874003 -0.672065 -1.024450  1.060107  \n",
       "346 -0.534623 -0.272326 -0.240316  0.196462 -0.218107  1.164912  \n",
       "347  0.082282 -1.710368  0.748365  0.861978 -0.781257 -1.071121  \n",
       "348  1.274354 -0.194642 -1.549125 -1.857324 -0.234793  0.067342  \n",
       "349  0.064675 -2.440991 -1.015456 -0.059666 -0.988334  1.042627  \n",
       "350  1.497981  1.544072 -1.200528 -0.152799 -0.081302 -0.440124  \n",
       "351  1.312312 -1.773981  0.703413 -0.416606 -0.314958 -0.636563  \n",
       "352 -0.636809  0.011451 -0.162717 -0.565589 -0.377851  0.389921  \n",
       "353 -0.291861  0.157986  0.478781  0.014941 -0.409151 -0.691410  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 734us/step - loss: 14680.1065\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 2836.4735\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 594.3208\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 250.7337\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 177.8791\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 143.6774\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 119.7154\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 101.4944\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 88.3701\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 78.5823\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 72.2640\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 69.3628\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 67.3200\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 66.2800\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 65.2054\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 64.4346\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 63.8169\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 63.6550\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 63.0776\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 62.8515\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 62.2456\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 61.3262\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 60.8466\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 60.8798\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 59.6763\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 60.3130\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 59.5641\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 58.4680\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 57.8651\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 58.4029\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 57.4578\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 57.5914\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 56.6029\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 56.0821\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 56.1305\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 55.6526\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 55.1952\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 54.7676\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 54.2011\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 53.7750\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 53.6563\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 53.2544\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 52.6136\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 52.2329\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 52.2609\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 51.6274\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 50.9611\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 51.4037\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 52.2845\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 50.3425\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 49.0873\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 48.8447\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 48.8591\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 47.8671\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 47.2432\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.9648\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 46.4299\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 46.0651\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.8773\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.3448\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 44.6632\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.3336\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.0170\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.4004\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.6023\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.6927\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.3663\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.4692\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.4468\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.0627\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.1544\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.0997\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 38.8803\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.3871\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.3411\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.4963\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.2576\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.1226\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2875\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.8219\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.0141\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.1131\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.1043\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.4793\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.0764\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.7218\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.2217\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8839\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.5008\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.8706\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 35.2802\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.3834\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.6655\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.2681\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.1545\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 34.7108\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.6484\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.3567\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.4755\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.7598\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.5588\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.7669\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.7805\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.7015\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9806\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9335\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9575\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.3726\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.7051\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.3644\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.6668\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5678\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7518\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.9738\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3973\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.0811\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 33.9264\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 33.0801\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 34.2947\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0777\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9678\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6270\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2996\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0412\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6952\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.8891\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2630\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.9493\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6504\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.3615\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8117\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2613\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.4986\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9082\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.2606\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6514\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5998\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5193\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0954\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.1824\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5198\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 32.3753\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.4675\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1407\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6517\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6364\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5586\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2937\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5097\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.5929\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.4168\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5279\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2428\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.4164\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2542\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.2313\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2536\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3924\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5829\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9760\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8373\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.3537\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9704\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1287\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.0141\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6651\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8637\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.0856\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2035\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8029\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.8163\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2073\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2673\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.7799\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1181\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3420\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.2507\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1350\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9621\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8213\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1973\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9504\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5626\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.2598\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.3086\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9781\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.7670\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.0260\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.2285\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 28.6045\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 28.8574\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8679\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3592\n",
      "Epoch 194/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.7644\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4651\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8834\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.9221\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 27.0587\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3942\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 27.9488\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 29.8658\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6601\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6361\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9953\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.2388\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8966\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4063\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 29.2547\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0995\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8054\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.3807\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4404\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.2650\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.6559\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.5267\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9332\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7338\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4124\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0498\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.2680\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.4557\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7735\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.1299\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7939\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4692\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 25.7264\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0147\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1466\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3741\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3320\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8460\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8018\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.5891\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.6976\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7002\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5043\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1988\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6939\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4793\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.6428\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5062\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2864\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.3661\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8218\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0350\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1614\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.3257\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8786\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8515\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 26.0302\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1712\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6307\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7992\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9849\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1397\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.6483\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3096\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9104\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0379\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9708\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3052\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6745\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7425\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3414\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6514\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.2336\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 85us/step - loss: 24.2763\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3947\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9412\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9366\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.1975\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.4439\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1361\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9566\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.5414\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.6604\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2422\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4962\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.7865\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7693\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.7873\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9415\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3317\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 85us/step - loss: 24.0564\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.2296\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.7227\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.6944\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.6443\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.0999\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5310\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.2961\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9838\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 23.5121\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.0765\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.0328\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 23.4111\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.4089\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.8785\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.3783\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.0388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1773fcf8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26., 13., 39., 21., 22., 24., 26., 14., 17., 12., 22., 17., 19.,\n",
       "        17., 23., 12., 35., 19., 28., 43., 30., 12., 33., 26., 25., 26.,\n",
       "        28., 23., 21., 13., 22., 20., 39., 32., 28., 14., 25., 36., 20.,\n",
       "        16., 27., 26., 19., 13., 20., 19., 17., 27., 17., 14., 19., 33.,\n",
       "        21., 32., 22., 29., 20., 28., 11., 17., 23., 15., 16., 20., 33.,\n",
       "        32., 14., 17., 18., 27., 21., 32., 20., 20., 17., 16., 29., 38.,\n",
       "        28.,  8., 14., 41., 14., 14., 17., 27., 13., 28., 16., 21., 14.,\n",
       "        19., 40., 21., 16., 17., 23., 19., 11., 17., 26., 10., 21., 18.,\n",
       "        29., 23., 16., 26., 21., 22., 28., 23., 21., 41., 27., 22., 24.,\n",
       "        28., 27., 38., 29., 20., 31., 12., 38., 28., 42., 28., 16., 20.,\n",
       "        14., 26., 32., 33., 26., 22., 33., 19., 20., 21., 20., 24., 27.,\n",
       "        13., 14., 17., 23., 16., 32., 30., 27., 22.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 921us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.240611678675602"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\", kernel_initializer='Zeros'))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 650us/step - loss: 10.2955\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 6.6151\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 5.8601\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.5552\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 5.4446\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.3405\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.2588\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 5.3175\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 5.2154\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.4380\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.3101\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.1315\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 5.1283\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 5.1318\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.0955\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.1415\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.1001\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.0458\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.9710\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.9809\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.8990\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.9717\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.8866\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.8483\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.8292\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.8240\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.8528\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.8823\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.6604\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.7464\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.6930\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.7092\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.6744\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.6098\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.6196\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.5373\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.5873\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.5486\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.5227\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.4558\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.7414\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.5458\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.4588\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.4110\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.4996\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.4066\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.7122\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.3645\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.3259\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.3983\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.5015\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.3011\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.4458\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2677\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.3612\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2739\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2267\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2443\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2901\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.2729\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.3097\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.3022\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.1502\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2714\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.2279\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.1561\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.2309\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.1071\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0669\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0295\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.1645\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0681\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.0416\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.2018\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0954\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0541\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0499\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0319\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9551\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0391\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9508\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9680\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0138\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8707\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 3.9156\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8878\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9581\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.0669\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9868\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8511\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9045\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8813\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8868\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9227\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 3.8535\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9432\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 3.9351\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 88us/step - loss: 3.8552\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 116us/step - loss: 3.9025\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 133us/step - loss: 3.9282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1632f9e8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23., 12., 31., 23., 24., 25., 24., 13., 16., 11., 21., 19., 17.,\n",
       "        15., 23.,  8., 29., 23., 26., 31., 28., 13., 31., 27., 21., 25.,\n",
       "        25., 26., 19., 13., 25., 20., 30., 27., 26., 12., 25., 30., 21.,\n",
       "        17., 27., 25., 14., 11., 18., 18., 17., 22., 18., 12., 18., 24.,\n",
       "        22., 27., 23., 31., 22., 29.,  9., 16., 23., 14., 15., 15., 29.,\n",
       "        27., 15., 19., 21., 25., 21., 28., 20., 18., 21., 19., 28., 29.,\n",
       "        26., 10., 10., 31., 14., 14., 15., 26.,  8., 25., 14., 22., 13.,\n",
       "        17., 36., 19., 14., 20., 20., 20.,  7., 20., 24.,  8., 17., 19.,\n",
       "        26., 20., 17., 25., 18., 22., 26., 25., 21., 31., 27., 23., 22.,\n",
       "        26., 25., 33., 29., 19., 30., 13., 30., 26., 37., 27., 15., 19.,\n",
       "        20., 25., 33., 30., 25., 18., 29., 17., 21., 18., 22., 21., 25.,\n",
       "        10., 12., 20., 18., 16., 33., 27., 26., 23.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\", kernel_initializer='Zeros'))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 593us/step - loss: 73.6679\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.0527\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.6927\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.3327\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 20.9727\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 20.6127\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 20.2527\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 19.8927\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 19.5327\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 19.1727\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 18.8127\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 18.4527\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 18.0926\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 17.7326\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 17.3726\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 17.0126\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 16.6526\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 16.2931\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 15.9372\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 15.5812\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 15.2323\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 14.8962\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 14.5639\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 14.2349\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 13.9153\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 13.6042\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 13.2947\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 12.9871\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 12.6871\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 12.3904\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 12.1037\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 11.8267\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 11.5567\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 11.2904\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 11.0335\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 10.7877\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 10.5438\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 10.3085\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 7.524 - 0s 141us/step - loss: 10.0833\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 9.8738\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 9.6811\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 9.5042\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.3421\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 9.1900\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 9.0397\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 8.8938\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 8.7503\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 8.6144\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 8.4871\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 8.3659\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 8.2503\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 8.1342\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 8.0250\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.9231\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.8224\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.7297\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.6422\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.5553\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.4768\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 7.4035\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 7.3354\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.2701\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 7.2104\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.1536\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 7.1000\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 7.0499\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 7.0012\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 6.9588\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.9163\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.8777\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.8416\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.8084\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.7794\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.7529\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.7317\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.7114\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6936\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6765\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6608\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6462\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6324\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6199\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.6085\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5982\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5894\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 6.5822\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5752\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5680\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 6.5620\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5569\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5518\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5464\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5424\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5384\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5349\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 6.5316\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5291\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 6.5276\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 6.5263\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 6.5248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17defcc0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"elu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 650us/step - loss: 10.3829\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 6.8659\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 5.8235\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 5.7181\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.5751\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.4261\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.3646\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.2442\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 5.3122\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.1820\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.1791\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.1201\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 5.1181\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.1009\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.9845\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.0279\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 5.0124\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.8979\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.9667\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.9020\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.8371\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.7783\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.8750\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.7798\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.7154\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.7473\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.7120\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.6588\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.5968\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.6849\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.6726\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.5861\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.6035\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.5675\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.5129\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.5437\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.4512\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.5011\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.4031\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.4537\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.4243\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.3967\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.3440\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.2554\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.3282\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.3078\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.2248\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.2929\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 4.1670\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.2199\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.2229\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.2651\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 4.2148\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.1930\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.1310\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.1050\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.1370\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.1371\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.1306\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0713\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.1109\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0824\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0217\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0491\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0316\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0295\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0485\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0391\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0062\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9789\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9472\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 4.0303\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 3.9818\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9555\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0171\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9265\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9849\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9753\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8740\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 4.0118\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9476\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9360\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9558\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8720\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9463\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8481\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8763\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 3.8436\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 3.9351\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 3.8865\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8924\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.7867\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8581\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.9070\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8680\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8735\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 3.7943\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.8328\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 3.6568\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 3.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17934f60>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 763us/step - loss: 6.5556\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.4918\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1524\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.1183\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1049\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1037\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1042\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1064\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0993\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0995\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0993\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0967\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0937\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0953\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0917\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0992\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1015\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1039\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0926\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0948\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0929\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0884\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1058\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0968\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0934\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0942\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0990\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0970\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0931\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0900\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0903\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0990\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0979\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0925\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0954\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0947\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0866\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0973\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0975\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0978\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0926\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0927\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0945\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0961\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0888\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0996\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0887\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0909\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0885\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0938\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0897\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0907\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0934\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0810\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0843\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0859\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0887\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0917\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0985\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0831\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0890\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0832\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0938\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0832\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0830\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0927\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0910\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0836\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0825\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0898\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0874\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0853\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0865\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0842\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0841\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0837\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0837\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0811\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0973\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0784\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0851\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0788\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0902\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0867\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0875\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0859\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0823\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0875\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0758\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0996\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0815\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0806\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0806\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0769\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0806\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0934\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 0.0882\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0987\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0788\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1909e2b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 876us/step - loss: 6.9748\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 3.5177\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 1.8233\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.4979\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.2609\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2531\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.2208\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.2184\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2515\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.2006\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1870\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1822\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.1780\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1767\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1741\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1563\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1737\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1682\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.2535\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1372\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1484\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.1378\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1331\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1318\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2198\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1295\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1167\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1191\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1208\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.1204\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.2955\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1545\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1243\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0955\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1590\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1262\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0945\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0856\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0861\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0913\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0768\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0713\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0703\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0671\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0682\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0688\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0714\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0713\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0673\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0717\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0729\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0656\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0669\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0725\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0705\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0655\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0704\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0640\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0623\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0648\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0612\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0614\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0597\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0612\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0620\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0755\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0940\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0641\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0654\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0622\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0576\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0593\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0599\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0579\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0702\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0553\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0698\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0605\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0645\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0560\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0593\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0606\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0662\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0568\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0549\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0568\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0559\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0569\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0567\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0618\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0595\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0568\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0586\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0574\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0544\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0556\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 0.0535\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0541\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0625\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1927d898>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 1ms/step - loss: 7.5053\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8412\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1477\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1148\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1070\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1159\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1134\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1114\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1181\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1175\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1155\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1055\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1098\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1092\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1133\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1113\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1088\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1149\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1064\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1076\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1081\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1061\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1081\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0962\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1042\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0983\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1119\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1030\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1093\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1090\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0996\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1035\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1093\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 271us/step - loss: 0.0994\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 237us/step - loss: 0.0986\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0985\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1067\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0942\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1019\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0969\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 232us/step - loss: 0.0976\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1028\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0941\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0944\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1001\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0866\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0984\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0970\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1063\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0953\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0951\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1057\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0939\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0959\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0939\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0943\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0842\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0952\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0904\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1021\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0923\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0908\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1024\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0949\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0886\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0814\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1097\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0875\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0966\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0968\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0910\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0964\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0842\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0886\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0952\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0833\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0876\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0938\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0834\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0944\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0826\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1027\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0890\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0883\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0861\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0808\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0840\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0935\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0929\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0884\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0869\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0920\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0878\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0882\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0847\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0875\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 254us/step - loss: 0.0885\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0858\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0834\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.0881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cbbca90>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.,  9., 20., 28., 25., 29., 29., 17., 15., 16., 25., 21., 16.,\n",
       "        17., 26., 13., 30., 26., 31., 30., 30., 14., 28., 32., 19., 27.,\n",
       "        20., 26., 23., 22., 28., 23., 30., 26., 29., 16., 28., 28., 23.,\n",
       "        21., 27., 25., 13., 15., 29., 25., 20., 25., 21., 19., 25., 21.,\n",
       "        23., 26., 25., 32., 24., 34., 14., 16., 26., 20., 21., 16., 31.,\n",
       "        25., 20., 22., 24., 26., 23., 28., 24., 17., 24., 22., 29., 29.,\n",
       "        29., 15., 17., 29., 12., 12., 17., 29., 11., 26., 20., 26., 16.,\n",
       "        17., 37., 22., 16., 22., 18., 24., 10., 22., 24., 12., 24., 23.,\n",
       "        26., 17., 21., 32., 19., 26., 28., 26., 25., 30., 27., 27., 27.,\n",
       "        28., 29., 31., 31., 23., 32., 10., 19., 29., 37., 27., 17., 19.,\n",
       "        27., 27., 35., 28., 25., 17., 30., 18., 27., 18., 24., 24., 28.,\n",
       "        14., 18., 24., 18., 15., 34., 29., 26., 26.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.662978473462557"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 1ms/step - loss: 7.7185\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 7.6619\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 7.5804\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.9881\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 1.5786\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.9907\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.5170\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.4333\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.3655\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.3287\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2900\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2737\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2599\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2615\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2478\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2400\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2360\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2322\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2348\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2431\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2110\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.2035\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1957\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1952\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1968\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1900\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1878\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1815\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1789\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1802\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2802\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1796\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1696\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.3081\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1720\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1361\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1308\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1767\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1208\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1569\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0933\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0997\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0903\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0842\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0841\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0812\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0835\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0760\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0754\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0739\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0756\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0725\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 274us/step - loss: 0.0824\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 350us/step - loss: 0.0761\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0764\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0698\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0720\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0699\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0704\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0706\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0688\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0675\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0720\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0651\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0669\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0655\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0678\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0663\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0667\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0711\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0656\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0649\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0645\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0677\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0636\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0608\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0635\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0681\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0674\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0652\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0741\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0724\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0635\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 280us/step - loss: 0.0686\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0648\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0637\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0624\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0638\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0599\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0610\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0681\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0676\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0622\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0608\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0622\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0607\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 226us/step - loss: 0.0611\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0590\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0666\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c36b860>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -2., -1., -0., -0., -1., -1., -1., -2., -0., -1., -0., -1.,\n",
       "        -1., -0., -1., -1., -1., -1., -1., -1., -2., -1., -1., -1., -1.,\n",
       "        -1., -1., -0., -1., -0., -0., -1., -0., -0., -1., -1., -1., -1.,\n",
       "        -0., -1., -1., -1., -1., -1., -0., -1., -1., -0., -0., -1., -1.,\n",
       "        -0., -0., -1., -0., -0., -1., -1., -1., -0., -0., -1., -1., -1.,\n",
       "        -0., -0., -0., -1., -1., -0., -1., -0., -1., -0., -1., -0., -1.,\n",
       "        -1., -1., -1., -1., -1., -2., -1., -0., -1., -1., -0., -0., -1.,\n",
       "        -1., -1., -0., -1., -0., -1., -0., -2., -0., -0., -1., -0., -0.,\n",
       "        -0., -1., -0., -1., -1., -1., -0., -1., -1., -1., -0., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -0., -0., -1., -1., -1., -1., -1., -0., -1., -0.,\n",
       "        -1., -0., -1., -1., -2., -1., -1., -1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.662978473462557"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080348</td>\n",
       "      <td>-0.394817</td>\n",
       "      <td>-0.890183</td>\n",
       "      <td>0.371012</td>\n",
       "      <td>-0.729959</td>\n",
       "      <td>0.941728</td>\n",
       "      <td>2.038580</td>\n",
       "      <td>0.344230</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>-0.748164</td>\n",
       "      <td>-0.248955</td>\n",
       "      <td>-0.280126</td>\n",
       "      <td>0.092254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.115092</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>1.081599</td>\n",
       "      <td>-1.335076</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>-1.591981</td>\n",
       "      <td>0.471225</td>\n",
       "      <td>-0.110589</td>\n",
       "      <td>0.393893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.678670</td>\n",
       "      <td>0.109902</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>-0.192856</td>\n",
       "      <td>-0.352267</td>\n",
       "      <td>-0.167803</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>0.755681</td>\n",
       "      <td>-0.028307</td>\n",
       "      <td>-0.310263</td>\n",
       "      <td>-0.552134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.957708</td>\n",
       "      <td>2.691383</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.575203</td>\n",
       "      <td>0.883537</td>\n",
       "      <td>-0.790650</td>\n",
       "      <td>-0.139723</td>\n",
       "      <td>-0.029203</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>-1.924215</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>-0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.009087</td>\n",
       "      <td>0.196193</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>-1.122527</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.184398</td>\n",
       "      <td>-0.654900</td>\n",
       "      <td>-0.433389</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>-0.310646</td>\n",
       "      <td>0.314520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.611866</td>\n",
       "      <td>0.137828</td>\n",
       "      <td>-0.531281</td>\n",
       "      <td>-0.444828</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>-0.188192</td>\n",
       "      <td>-1.068207</td>\n",
       "      <td>-0.249310</td>\n",
       "      <td>-0.612161</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>-0.404626</td>\n",
       "      <td>-0.524731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.338056</td>\n",
       "      <td>-0.323253</td>\n",
       "      <td>1.205601</td>\n",
       "      <td>1.744052</td>\n",
       "      <td>-0.362501</td>\n",
       "      <td>-0.347251</td>\n",
       "      <td>-0.274208</td>\n",
       "      <td>1.125857</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>-0.353582</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.391402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.249902</td>\n",
       "      <td>-1.540512</td>\n",
       "      <td>-0.316446</td>\n",
       "      <td>0.389658</td>\n",
       "      <td>1.098720</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>-0.371540</td>\n",
       "      <td>-0.349467</td>\n",
       "      <td>-0.161251</td>\n",
       "      <td>-0.315329</td>\n",
       "      <td>-1.166842</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>0.014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.960374</td>\n",
       "      <td>2.726205</td>\n",
       "      <td>0.573851</td>\n",
       "      <td>-0.488915</td>\n",
       "      <td>2.904541</td>\n",
       "      <td>-1.689157</td>\n",
       "      <td>1.238750</td>\n",
       "      <td>0.475148</td>\n",
       "      <td>0.423293</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.657942</td>\n",
       "      <td>-0.054441</td>\n",
       "      <td>-0.837061</td>\n",
       "      <td>-0.077872</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.086200</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>0.306190</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>1.069730</td>\n",
       "      <td>-0.342973</td>\n",
       "      <td>0.129854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.636011</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-1.239630</td>\n",
       "      <td>0.456554</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>-0.860661</td>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.563122</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>-0.569178</td>\n",
       "      <td>-0.148434</td>\n",
       "      <td>0.493215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.009365</td>\n",
       "      <td>0.191193</td>\n",
       "      <td>2.148391</td>\n",
       "      <td>2.001960</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>-1.530055</td>\n",
       "      <td>1.489968</td>\n",
       "      <td>-2.731570</td>\n",
       "      <td>0.459341</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>-0.264038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.277053</td>\n",
       "      <td>1.865595</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>-0.430563</td>\n",
       "      <td>-0.528763</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>1.725652</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-1.158937</td>\n",
       "      <td>0.687860</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>-0.771315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.985661</td>\n",
       "      <td>2.895293</td>\n",
       "      <td>0.544915</td>\n",
       "      <td>-0.480189</td>\n",
       "      <td>-1.177606</td>\n",
       "      <td>-0.463066</td>\n",
       "      <td>-0.338959</td>\n",
       "      <td>-0.379896</td>\n",
       "      <td>0.370657</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>-0.022322</td>\n",
       "      <td>0.673355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.155687</td>\n",
       "      <td>-1.017810</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>-0.715356</td>\n",
       "      <td>-1.729263</td>\n",
       "      <td>2.308184</td>\n",
       "      <td>-0.125476</td>\n",
       "      <td>-1.382472</td>\n",
       "      <td>0.852165</td>\n",
       "      <td>-1.760670</td>\n",
       "      <td>-1.251921</td>\n",
       "      <td>-0.786614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.943787</td>\n",
       "      <td>0.191897</td>\n",
       "      <td>2.283650</td>\n",
       "      <td>3.452496</td>\n",
       "      <td>0.053454</td>\n",
       "      <td>-0.170607</td>\n",
       "      <td>-0.112187</td>\n",
       "      <td>-1.098166</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>0.608938</td>\n",
       "      <td>0.653165</td>\n",
       "      <td>-0.266726</td>\n",
       "      <td>-0.091649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.535033</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>-0.641210</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>0.202774</td>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>0.833602</td>\n",
       "      <td>2.085996</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.404678</td>\n",
       "      <td>-0.613735</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.308832</td>\n",
       "      <td>-0.178946</td>\n",
       "      <td>1.354895</td>\n",
       "      <td>-1.057672</td>\n",
       "      <td>-0.458506</td>\n",
       "      <td>-0.332231</td>\n",
       "      <td>-0.585559</td>\n",
       "      <td>-0.053712</td>\n",
       "      <td>-0.211421</td>\n",
       "      <td>-1.758293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.196783</td>\n",
       "      <td>-0.414817</td>\n",
       "      <td>1.490226</td>\n",
       "      <td>-2.874329</td>\n",
       "      <td>-0.251195</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.518385</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-0.317663</td>\n",
       "      <td>-0.738418</td>\n",
       "      <td>-0.211338</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>-0.686020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.898128</td>\n",
       "      <td>2.359720</td>\n",
       "      <td>0.329719</td>\n",
       "      <td>-0.233685</td>\n",
       "      <td>-1.512660</td>\n",
       "      <td>-0.211246</td>\n",
       "      <td>-0.626046</td>\n",
       "      <td>-0.492962</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.065852</td>\n",
       "      <td>-0.662386</td>\n",
       "      <td>-0.185006</td>\n",
       "      <td>0.625654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.351897</td>\n",
       "      <td>-0.876389</td>\n",
       "      <td>0.301938</td>\n",
       "      <td>-0.427105</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>2.323010</td>\n",
       "      <td>-0.937386</td>\n",
       "      <td>-0.412936</td>\n",
       "      <td>-0.766805</td>\n",
       "      <td>-1.074004</td>\n",
       "      <td>-1.122226</td>\n",
       "      <td>-0.137080</td>\n",
       "      <td>0.442295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.843534</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.592639</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>-1.092255</td>\n",
       "      <td>-0.577864</td>\n",
       "      <td>1.215063</td>\n",
       "      <td>-0.036064</td>\n",
       "      <td>-0.900039</td>\n",
       "      <td>-0.542748</td>\n",
       "      <td>-0.305855</td>\n",
       "      <td>0.150305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050379</td>\n",
       "      <td>-0.584889</td>\n",
       "      <td>-1.041110</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>-0.818853</td>\n",
       "      <td>0.079107</td>\n",
       "      <td>2.221296</td>\n",
       "      <td>0.277487</td>\n",
       "      <td>1.849282</td>\n",
       "      <td>-0.427553</td>\n",
       "      <td>-0.648227</td>\n",
       "      <td>-0.398190</td>\n",
       "      <td>0.193268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.779425</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>1.043213</td>\n",
       "      <td>-0.670624</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.533982</td>\n",
       "      <td>-1.080526</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>1.450427</td>\n",
       "      <td>0.390579</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>0.948641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.304556</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.066358</td>\n",
       "      <td>-0.485542</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>1.877667</td>\n",
       "      <td>0.472362</td>\n",
       "      <td>-0.851668</td>\n",
       "      <td>-0.475440</td>\n",
       "      <td>0.433045</td>\n",
       "      <td>0.416610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.545173</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>-0.127907</td>\n",
       "      <td>0.237873</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>-0.648339</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>-0.167001</td>\n",
       "      <td>-0.170500</td>\n",
       "      <td>0.992560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.225336</td>\n",
       "      <td>-0.140532</td>\n",
       "      <td>0.457158</td>\n",
       "      <td>0.209959</td>\n",
       "      <td>-0.100670</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>2.007666</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>-0.460942</td>\n",
       "      <td>-0.511064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.808280</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>-0.837358</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.093117</td>\n",
       "      <td>-1.640965</td>\n",
       "      <td>-0.719455</td>\n",
       "      <td>1.428069</td>\n",
       "      <td>0.283175</td>\n",
       "      <td>-0.634228</td>\n",
       "      <td>-2.059973</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.548719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.994640</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>2.200903</td>\n",
       "      <td>2.732752</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>-0.152012</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>-1.081080</td>\n",
       "      <td>0.102347</td>\n",
       "      <td>-1.146830</td>\n",
       "      <td>-0.437390</td>\n",
       "      <td>-0.314694</td>\n",
       "      <td>-0.672085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.275527</td>\n",
       "      <td>-1.331517</td>\n",
       "      <td>0.176396</td>\n",
       "      <td>-0.262578</td>\n",
       "      <td>-0.404761</td>\n",
       "      <td>0.388403</td>\n",
       "      <td>-0.596450</td>\n",
       "      <td>-0.757497</td>\n",
       "      <td>-0.202598</td>\n",
       "      <td>-0.207741</td>\n",
       "      <td>-0.193679</td>\n",
       "      <td>-0.247489</td>\n",
       "      <td>0.767546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.448404</td>\n",
       "      <td>3.017727</td>\n",
       "      <td>-0.447951</td>\n",
       "      <td>-0.095226</td>\n",
       "      <td>-0.986589</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>1.900239</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>-1.736481</td>\n",
       "      <td>0.142566</td>\n",
       "      <td>0.208303</td>\n",
       "      <td>3.278740</td>\n",
       "      <td>3.117442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.637666</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.803028</td>\n",
       "      <td>-2.211732</td>\n",
       "      <td>0.133059</td>\n",
       "      <td>-0.773462</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>-0.569493</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-1.386104</td>\n",
       "      <td>0.410985</td>\n",
       "      <td>-0.254111</td>\n",
       "      <td>0.349224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.742337</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>-0.303305</td>\n",
       "      <td>-0.809501</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.673318</td>\n",
       "      <td>1.440644</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>-1.025311</td>\n",
       "      <td>0.145561</td>\n",
       "      <td>-0.137611</td>\n",
       "      <td>-0.612576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.863527</td>\n",
       "      <td>0.151054</td>\n",
       "      <td>-0.621895</td>\n",
       "      <td>1.102764</td>\n",
       "      <td>0.127329</td>\n",
       "      <td>-0.637058</td>\n",
       "      <td>-0.923254</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>-2.615026</td>\n",
       "      <td>-1.113191</td>\n",
       "      <td>-0.353638</td>\n",
       "      <td>-0.942371</td>\n",
       "      <td>1.263226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.250864</td>\n",
       "      <td>-1.539722</td>\n",
       "      <td>-0.320317</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>1.494396</td>\n",
       "      <td>1.996060</td>\n",
       "      <td>-0.855019</td>\n",
       "      <td>-0.153564</td>\n",
       "      <td>-0.572640</td>\n",
       "      <td>-0.513297</td>\n",
       "      <td>-0.060177</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>0.233746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.845037</td>\n",
       "      <td>2.016857</td>\n",
       "      <td>0.079042</td>\n",
       "      <td>0.082106</td>\n",
       "      <td>-0.680868</td>\n",
       "      <td>-0.186099</td>\n",
       "      <td>-0.529998</td>\n",
       "      <td>-0.301536</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>-0.029481</td>\n",
       "      <td>-1.333357</td>\n",
       "      <td>-0.259586</td>\n",
       "      <td>-1.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.330616</td>\n",
       "      <td>-1.041621</td>\n",
       "      <td>-0.163635</td>\n",
       "      <td>0.216016</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>-0.562350</td>\n",
       "      <td>-0.604425</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>0.441959</td>\n",
       "      <td>1.107620</td>\n",
       "      <td>-0.197033</td>\n",
       "      <td>-1.626711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.038869</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>-1.058361</td>\n",
       "      <td>0.544799</td>\n",
       "      <td>-0.519040</td>\n",
       "      <td>-0.246005</td>\n",
       "      <td>1.843414</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>-1.608033</td>\n",
       "      <td>1.175863</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>-0.930218</td>\n",
       "      <td>-1.208786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.802686</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>2.691830</td>\n",
       "      <td>2.205935</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.910832</td>\n",
       "      <td>0.617372</td>\n",
       "      <td>0.393352</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>-0.563892</td>\n",
       "      <td>-0.681889</td>\n",
       "      <td>-0.061548</td>\n",
       "      <td>-0.110975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.248989</td>\n",
       "      <td>-1.540390</td>\n",
       "      <td>-0.259678</td>\n",
       "      <td>0.338137</td>\n",
       "      <td>1.419395</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>0.247133</td>\n",
       "      <td>-0.372901</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>-0.375925</td>\n",
       "      <td>-1.600665</td>\n",
       "      <td>-0.439351</td>\n",
       "      <td>0.211505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.509456</td>\n",
       "      <td>0.064296</td>\n",
       "      <td>2.700187</td>\n",
       "      <td>1.597607</td>\n",
       "      <td>-0.144598</td>\n",
       "      <td>0.310441</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>0.585163</td>\n",
       "      <td>3.476441</td>\n",
       "      <td>1.317026</td>\n",
       "      <td>0.872823</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>1.922435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.231409</td>\n",
       "      <td>-1.538950</td>\n",
       "      <td>0.688780</td>\n",
       "      <td>-0.936760</td>\n",
       "      <td>-0.398978</td>\n",
       "      <td>-0.730870</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>-0.940533</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>0.675256</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>-0.217405</td>\n",
       "      <td>-1.520989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.534067</td>\n",
       "      <td>-0.182972</td>\n",
       "      <td>2.735200</td>\n",
       "      <td>1.545595</td>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.187525</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>-0.256181</td>\n",
       "      <td>-0.892626</td>\n",
       "      <td>1.122224</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>-0.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-0.188002</td>\n",
       "      <td>-0.354648</td>\n",
       "      <td>1.814985</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>-0.423748</td>\n",
       "      <td>-0.521735</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.755776</td>\n",
       "      <td>-1.094067</td>\n",
       "      <td>0.626996</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>-0.217247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.069057</td>\n",
       "      <td>-0.099665</td>\n",
       "      <td>-1.132815</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>-0.730913</td>\n",
       "      <td>-1.100634</td>\n",
       "      <td>2.043489</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-1.495209</td>\n",
       "      <td>0.700378</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>-1.033186</td>\n",
       "      <td>3.565111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-1.086996</td>\n",
       "      <td>0.369113</td>\n",
       "      <td>0.343296</td>\n",
       "      <td>-0.357972</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>1.026568</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>-0.774167</td>\n",
       "      <td>0.254745</td>\n",
       "      <td>-1.067171</td>\n",
       "      <td>0.603821</td>\n",
       "      <td>-0.176953</td>\n",
       "      <td>-0.166501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.190903</td>\n",
       "      <td>-0.402475</td>\n",
       "      <td>1.511917</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>-0.407703</td>\n",
       "      <td>-0.352837</td>\n",
       "      <td>-0.155576</td>\n",
       "      <td>1.782732</td>\n",
       "      <td>-1.411651</td>\n",
       "      <td>-1.642066</td>\n",
       "      <td>0.222688</td>\n",
       "      <td>-0.066098</td>\n",
       "      <td>-1.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.918492</td>\n",
       "      <td>2.448586</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.520436</td>\n",
       "      <td>-0.741136</td>\n",
       "      <td>-0.175211</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>-0.164630</td>\n",
       "      <td>-1.124253</td>\n",
       "      <td>-0.171095</td>\n",
       "      <td>0.864909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-1.036607</td>\n",
       "      <td>0.232198</td>\n",
       "      <td>-0.630966</td>\n",
       "      <td>-0.585621</td>\n",
       "      <td>0.471721</td>\n",
       "      <td>1.047169</td>\n",
       "      <td>-0.671226</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>1.669281</td>\n",
       "      <td>0.383386</td>\n",
       "      <td>-0.356056</td>\n",
       "      <td>-0.501093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.593573</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>-1.209316</td>\n",
       "      <td>1.399069</td>\n",
       "      <td>0.283667</td>\n",
       "      <td>2.809910</td>\n",
       "      <td>-1.617712</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>-1.553295</td>\n",
       "      <td>2.757605</td>\n",
       "      <td>-0.812138</td>\n",
       "      <td>-0.679586</td>\n",
       "      <td>-0.578312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.793258</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>-1.138782</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>0.694742</td>\n",
       "      <td>-1.275697</td>\n",
       "      <td>-0.662284</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>-0.241130</td>\n",
       "      <td>-0.972592</td>\n",
       "      <td>-0.584089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.858731</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>-0.984352</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>0.148730</td>\n",
       "      <td>-0.576002</td>\n",
       "      <td>-1.127209</td>\n",
       "      <td>0.135239</td>\n",
       "      <td>-2.526001</td>\n",
       "      <td>-0.874003</td>\n",
       "      <td>-0.672065</td>\n",
       "      <td>-1.024450</td>\n",
       "      <td>1.060107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.246741</td>\n",
       "      <td>-1.540688</td>\n",
       "      <td>-0.173736</td>\n",
       "      <td>0.186121</td>\n",
       "      <td>0.273360</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>-0.735751</td>\n",
       "      <td>-0.534623</td>\n",
       "      <td>-0.272326</td>\n",
       "      <td>-0.240316</td>\n",
       "      <td>0.196462</td>\n",
       "      <td>-0.218107</td>\n",
       "      <td>1.164912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.181469</td>\n",
       "      <td>1.443857</td>\n",
       "      <td>-0.453647</td>\n",
       "      <td>-0.179776</td>\n",
       "      <td>-0.862378</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>1.993915</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>-1.710368</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>-0.781257</td>\n",
       "      <td>-1.071121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.819563</td>\n",
       "      <td>0.096842</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>-1.586421</td>\n",
       "      <td>0.071846</td>\n",
       "      <td>-1.046755</td>\n",
       "      <td>-0.297640</td>\n",
       "      <td>1.274354</td>\n",
       "      <td>-0.194642</td>\n",
       "      <td>-1.549125</td>\n",
       "      <td>-1.857324</td>\n",
       "      <td>-0.234793</td>\n",
       "      <td>0.067342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.849991</td>\n",
       "      <td>0.205352</td>\n",
       "      <td>-0.888543</td>\n",
       "      <td>1.466501</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>-1.092184</td>\n",
       "      <td>-0.933734</td>\n",
       "      <td>0.064675</td>\n",
       "      <td>-2.440991</td>\n",
       "      <td>-1.015456</td>\n",
       "      <td>-0.059666</td>\n",
       "      <td>-0.988334</td>\n",
       "      <td>1.042627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.229282</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>-1.121209</td>\n",
       "      <td>0.570964</td>\n",
       "      <td>-0.437700</td>\n",
       "      <td>-0.485966</td>\n",
       "      <td>-0.532777</td>\n",
       "      <td>1.497981</td>\n",
       "      <td>1.544072</td>\n",
       "      <td>-1.200528</td>\n",
       "      <td>-0.152799</td>\n",
       "      <td>-0.081302</td>\n",
       "      <td>-0.440124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.569485</td>\n",
       "      <td>-0.151394</td>\n",
       "      <td>2.260648</td>\n",
       "      <td>2.176295</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>-0.292190</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>1.312312</td>\n",
       "      <td>-1.773981</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>-0.416606</td>\n",
       "      <td>-0.314958</td>\n",
       "      <td>-0.636563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.257425</td>\n",
       "      <td>-1.486130</td>\n",
       "      <td>-0.288594</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>-0.495139</td>\n",
       "      <td>-0.636809</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>-0.162717</td>\n",
       "      <td>-0.565589</td>\n",
       "      <td>-0.377851</td>\n",
       "      <td>0.389921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.786884</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>-0.801586</td>\n",
       "      <td>-0.232461</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>1.257130</td>\n",
       "      <td>-0.209978</td>\n",
       "      <td>-0.291861</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.478781</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.409151</td>\n",
       "      <td>-0.691410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0    0.080348 -0.394817 -0.890183  0.371012 -0.729959  0.941728  2.038580   \n",
       "1   -1.115092  0.278251  1.081599 -1.335076  0.450709  0.342844  0.530724   \n",
       "2   -0.678670  0.109902  0.841250  0.052771  0.031168 -0.192856 -0.352267   \n",
       "3    1.957708  2.691383  0.204966 -0.059570 -0.575203  0.883537 -0.790650   \n",
       "4   -1.009087  0.196193  1.046665 -1.122527  0.320851 -0.093841  0.184398   \n",
       "5   -0.611866  0.137828 -0.531281 -0.444828  0.115007 -0.188192 -1.068207   \n",
       "6   -0.338056 -0.323253  1.205601  1.744052 -0.362501 -0.347251 -0.274208   \n",
       "7    1.249902 -1.540512 -0.316446  0.389658  1.098720  0.224061 -0.371540   \n",
       "8    1.960374  2.726205  0.573851 -0.488915  2.904541 -1.689157  1.238750   \n",
       "9   -0.657942 -0.054441 -0.837061 -0.077872 -0.043811 -0.086200  0.009856   \n",
       "10  -0.636011 -0.072869 -1.239630  0.456554  0.231618  0.878649 -0.860661   \n",
       "11  -1.009365  0.191193  2.148391  2.001960  0.143939 -0.012545  0.671094   \n",
       "12  -0.175675 -0.277053  1.865595  0.199379 -0.430563 -0.528763  0.068854   \n",
       "13   1.985661  2.895293  0.544915 -0.480189 -1.177606 -0.463066 -0.338959   \n",
       "14  -0.080628 -0.155687 -1.017810  0.497181 -0.715356 -1.729263  2.308184   \n",
       "15  -0.943787  0.191897  2.283650  3.452496  0.053454 -0.170607 -0.112187   \n",
       "16  -0.535033 -0.084668  0.958809 -0.641210  0.074573  0.202774 -0.423037   \n",
       "17   1.404678 -0.613735 -0.231168  0.308832 -0.178946  1.354895 -1.057672   \n",
       "18  -0.196783 -0.414817  1.490226 -2.874329 -0.251195  0.331195  1.518385   \n",
       "19   1.898128  2.359720  0.329719 -0.233685 -1.512660 -0.211246 -0.626046   \n",
       "20   1.351897 -0.876389  0.301938 -0.427105  0.437554  2.323010 -0.937386   \n",
       "21  -0.843534  0.090307 -0.500667 -0.592639  0.019766 -1.092255 -0.577864   \n",
       "22   0.050379 -0.584889 -1.041110  0.572919 -0.818853  0.079107  2.221296   \n",
       "23  -0.779425  0.097954  1.043213 -0.670624  0.244888 -0.056817 -0.533982   \n",
       "24  -0.176788 -0.304556  3.399690  2.066358 -0.485542  0.191075  0.487928   \n",
       "25   1.545173  0.222524 -0.127907  0.237873  0.282217  0.656231 -0.648339   \n",
       "26  -0.984151  0.225336 -0.140532  0.457158  0.209959 -0.100670 -0.462245   \n",
       "27  -0.808280  0.055035 -0.837358 -0.115261 -0.093117 -1.640965 -0.719455   \n",
       "28  -0.994640  0.314741  2.200903  2.732752  0.037579 -0.152012  0.626242   \n",
       "29   1.275527 -1.331517  0.176396 -0.262578 -0.404761  0.388403 -0.596450   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324  0.448404  3.017727 -0.447951 -0.095226 -0.986589  0.186189  1.900239   \n",
       "325 -0.637666  0.119517  0.803028 -2.211732  0.133059 -0.773462 -0.165652   \n",
       "326 -0.742337  0.495750 -0.303305 -0.809501 -0.052632 -0.898387 -0.673318   \n",
       "327 -0.863527  0.151054 -0.621895  1.102764  0.127329 -0.637058 -0.923254   \n",
       "328  1.250864 -1.539722 -0.320317  0.369770  1.494396  1.996060 -0.855019   \n",
       "329  1.845037  2.016857  0.079042  0.082106 -0.680868 -0.186099 -0.529998   \n",
       "330  1.330616 -1.041621 -0.163635  0.216016 -0.180344 -0.059550 -0.562350   \n",
       "331 -0.038869  0.083404 -1.058361  0.544799 -0.519040 -0.246005  1.843414   \n",
       "332 -0.802686  0.054897  2.691830  2.205935  0.040140  0.910832  0.617372   \n",
       "333  1.248989 -1.540390 -0.259678  0.338137  1.419395 -1.254890  0.247133   \n",
       "334 -0.509456  0.064296  2.700187  1.597607 -0.144598  0.310441 -0.006960   \n",
       "335  1.231409 -1.538950  0.688780 -0.936760 -0.398978 -0.730870  0.026377   \n",
       "336 -0.534067 -0.182972  2.735200  1.545595 -0.155897  0.187525  0.503330   \n",
       "337 -0.188002 -0.354648  1.814985  0.266498 -0.423748 -0.521735  0.005338   \n",
       "338 -0.069057 -0.099665 -1.132815  0.642774 -0.730913 -1.100634  2.043489   \n",
       "339 -1.086996  0.369113  0.343296 -0.357972  0.485442  1.026568 -0.074474   \n",
       "340 -0.190903 -0.402475  1.511917  0.657549 -0.407703 -0.352837 -0.155576   \n",
       "341  1.918492  2.448586  0.081510  0.095092 -0.600437  0.520436 -0.741136   \n",
       "342 -1.036607  0.232198 -0.630966 -0.585621  0.471721  1.047169 -0.671226   \n",
       "343 -0.593573  0.027279 -1.209316  1.399069  0.283667  2.809910 -1.617712   \n",
       "344 -0.793258  0.099612 -1.138782  0.220145 -0.077865 -0.385340  0.694742   \n",
       "345 -0.858731  0.142945 -0.984352  1.583382  0.148730 -0.576002 -1.127209   \n",
       "346  1.246741 -1.540688 -0.173736  0.186121  0.273360  0.841098 -0.735751   \n",
       "347  0.181469  1.443857 -0.453647 -0.179776 -0.862378 -0.038269  1.993915   \n",
       "348 -0.819563  0.096842  0.264932 -1.586421  0.071846 -1.046755 -0.297640   \n",
       "349 -0.849991  0.205352 -0.888543  1.466501  0.024785 -1.092184 -0.933734   \n",
       "350 -0.229282 -0.369674 -1.121209  0.570964 -0.437700 -0.485966 -0.532777   \n",
       "351 -0.569485 -0.151394  2.260648  2.176295 -0.257481 -0.292190  0.280509   \n",
       "352  1.257425 -1.486130 -0.288594  0.357705 -0.014140 -0.290924 -0.495139   \n",
       "353 -0.786884  0.135389 -0.801586 -0.232461  0.242451  1.257130 -0.209978   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.344230  1.603922 -0.748164 -0.248955 -0.280126  0.092254  \n",
       "1   -0.992543  0.171785 -1.591981  0.471225 -0.110589  0.393893  \n",
       "2   -0.167803 -0.456787  0.755681 -0.028307 -0.310263 -0.552134  \n",
       "3   -0.139723 -0.029203 -0.473747 -1.924215 -0.190591 -0.187401  \n",
       "4   -0.654900 -0.433389  1.050608 -0.023740 -0.310646  0.314520  \n",
       "5   -0.249310 -0.612161 -0.099950  0.827616 -0.404626 -0.524731  \n",
       "6    1.125857  0.471972 -0.353582  0.172697  0.022303  0.391402  \n",
       "7   -0.349467 -0.161251 -0.315329 -1.166842 -0.349731  0.014179  \n",
       "8    0.475148  0.423293 -0.043176  0.395698  0.118429  0.235490  \n",
       "9    0.189647  0.306190  0.377249  1.069730 -0.342973  0.129854  \n",
       "10   0.708222  1.563122 -0.154623 -0.569178 -0.148434  0.493215  \n",
       "11  -1.530055  1.489968 -2.731570  0.459341  0.036337 -0.264038  \n",
       "12   1.725652 -1.356036 -1.158937  0.687860  0.026640 -0.771315  \n",
       "13  -0.379896  0.370657  0.345026  0.494635 -0.022322  0.673355  \n",
       "14  -0.125476 -1.382472  0.852165 -1.760670 -1.251921 -0.786614  \n",
       "15  -1.098166 -0.018907  0.608938  0.653165 -0.266726 -0.091649  \n",
       "16  -0.009278  0.833602  2.085996  0.073895  0.009437  0.349866  \n",
       "17  -0.458506 -0.332231 -0.585559 -0.053712 -0.211421 -1.758293  \n",
       "18   0.603767 -0.317663 -0.738418 -0.211338  0.043863 -0.686020  \n",
       "19  -0.492962  0.273988  0.065852 -0.662386 -0.185006  0.625654  \n",
       "20  -0.412936 -0.766805 -1.074004 -1.122226 -0.137080  0.442295  \n",
       "21   1.215063 -0.036064 -0.900039 -0.542748 -0.305855  0.150305  \n",
       "22   0.277487  1.849282 -0.427553 -0.648227 -0.398190  0.193268  \n",
       "23  -1.080526  1.165125  1.450427  0.390579 -0.020257  0.948641  \n",
       "24   1.877667  0.472362 -0.851668 -0.475440  0.433045  0.416610  \n",
       "25  -0.269487 -0.078472 -0.102407 -0.167001 -0.170500  0.992560  \n",
       "26  -0.424416 -0.047900  2.007666  0.541705 -0.460942 -0.511064  \n",
       "27   1.428069  0.283175 -0.634228 -2.059973 -0.474163 -0.548719  \n",
       "28  -1.081080  0.102347 -1.146830 -0.437390 -0.314694 -0.672085  \n",
       "29  -0.757497 -0.202598 -0.207741 -0.193679 -0.247489  0.767546  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324  0.300365 -1.736481  0.142566  0.208303  3.278740  3.117442  \n",
       "325 -0.569493 -0.943414 -1.386104  0.410985 -0.254111  0.349224  \n",
       "326  1.440644  0.015810 -1.025311  0.145561 -0.137611 -0.612576  \n",
       "327  0.052150 -2.615026 -1.113191 -0.353638 -0.942371  1.263226  \n",
       "328 -0.153564 -0.572640 -0.513297 -0.060177 -0.138515  0.233746  \n",
       "329 -0.301536  0.243190 -0.029481 -1.333357 -0.259586 -1.784060  \n",
       "330 -0.604425  0.084291  0.441959  1.107620 -0.197033 -1.626711  \n",
       "331  0.062016 -1.608033  1.175863  0.911292 -0.930218 -1.208786  \n",
       "332  0.393352 -0.427835 -0.563892 -0.681889 -0.061548 -0.110975  \n",
       "333 -0.372901  0.121113 -0.375925 -1.600665 -0.439351  0.211505  \n",
       "334  0.585163  3.476441  1.317026  0.872823  0.785367  1.922435  \n",
       "335 -0.940533  0.054370  0.675256  0.089150 -0.217405 -1.520989  \n",
       "336  0.394356 -0.256181 -0.892626  1.122224  0.152020 -0.519524  \n",
       "337  1.755776 -1.094067  0.626996  0.061140 -0.036445 -0.217247  \n",
       "338 -0.061708 -1.495209  0.700378  0.447174 -1.033186  3.565111  \n",
       "339 -0.774167  0.254745 -1.067171  0.603821 -0.176953 -0.166501  \n",
       "340  1.782732 -1.411651 -1.642066  0.222688 -0.066098 -1.138598  \n",
       "341 -0.175211  0.105444 -0.164630 -1.124253 -0.171095  0.864909  \n",
       "342 -0.113630 -0.024870  1.669281  0.383386 -0.356056 -0.501093  \n",
       "343  0.692484 -1.553295  2.757605 -0.812138 -0.679586 -0.578312  \n",
       "344 -1.275697 -0.662284  0.814229 -0.241130 -0.972592 -0.584089  \n",
       "345  0.135239 -2.526001 -0.874003 -0.672065 -1.024450  1.060107  \n",
       "346 -0.534623 -0.272326 -0.240316  0.196462 -0.218107  1.164912  \n",
       "347  0.082282 -1.710368  0.748365  0.861978 -0.781257 -1.071121  \n",
       "348  1.274354 -0.194642 -1.549125 -1.857324 -0.234793  0.067342  \n",
       "349  0.064675 -2.440991 -1.015456 -0.059666 -0.988334  1.042627  \n",
       "350  1.497981  1.544072 -1.200528 -0.152799 -0.081302 -0.440124  \n",
       "351  1.312312 -1.773981  0.703413 -0.416606 -0.314958 -0.636563  \n",
       "352 -0.636809  0.011451 -0.162717 -0.565589 -0.377851  0.389921  \n",
       "353 -0.291861  0.157986  0.478781  0.014941 -0.409151 -0.691410  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 1ms/step - loss: 1.3192\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 1.1226\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.9954\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.9631\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.9469\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.9199\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8993\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.8872\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8746\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.8612\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8536\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.8431\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8413\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8302\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.8247\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8142\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.8110\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.8054\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8047\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7933\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7915\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7872\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7817\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7786\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7772\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7729\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7674\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7709\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7665\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7651\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7634\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.7559\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7540\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7566\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7541\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7502\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7486\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7462\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7452\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7415\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7398\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7469\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7383\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7367\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.7363\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7380\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7351\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7312\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7304\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7299\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7280\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7267\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.7246\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7231\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.7238\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.7224\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7218\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.7186\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7169\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7173\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 285us/step - loss: 0.7211\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6758\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.4420\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2735\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1399\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.1174\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1065\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1272\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1976\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0984\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.0903\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0847\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0800\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0883\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0825\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0805\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0793\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.0782\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 480us/step - loss: 0.0773\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0816\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0780\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0768\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0818\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0785\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 599us/step - loss: 0.0785\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 508us/step - loss: 0.0726\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 260us/step - loss: 0.0707\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0744\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0748\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0822\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0736\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 480us/step - loss: 0.0725\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 452us/step - loss: 0.0750\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0714\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0761\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0711\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 226us/step - loss: 0.0722\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0703\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0756\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c5231d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18., 14., 18., 20., 20., 20., 20., 20., 18., 20., 20., 20., 18.,\n",
       "        18., 20., 18., 20., 20., 20., 20., 20., 17., 20., 20., 18., 20.,\n",
       "        18., 20., 20., 20., 20., 20., 20., 20., 20., 18., 20., 20., 20.,\n",
       "        20., 20., 20., 20., 18., 20., 20., 18., 20., 20., 20., 20., 20.,\n",
       "        20., 20., 20., 20., 20., 20., 18., 18., 20., 20., 20., 18., 20.,\n",
       "        20., 20., 20., 20., 20., 20., 20., 20., 18., 20., 20., 20., 20.,\n",
       "        20., 18., 20., 20., 14., 14., 18., 20., 20., 20., 20., 20., 18.,\n",
       "        18., 20., 18., 18., 20., 18., 20., 14., 20., 20., 18., 20., 20.,\n",
       "        20., 18., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.,\n",
       "        20., 20., 20., 20., 20., 20., 14., 18., 20., 16., 20., 18., 18.,\n",
       "        20., 20., 20., 20., 20., 18., 20., 18., 20., 18., 20., 20., 20.,\n",
       "        18., 20., 20., 20., 18., 20., 20., 20., 20.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15172351347772697"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-ad13f78e1055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = m.fit(x_train, y_train, epochs=100, batch_size=10)\n",
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 9.6721\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 9.6721\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 9.6721\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 9.6721\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 9.6721\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 9.6721\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 9.6721\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 9.6721\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 9.6721\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 429us/step - loss: 9.6721\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 9.6721\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 9.6721\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 339us/step - loss: 9.6721\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20be7be0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 1ms/step - loss: 9.6721\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 201us/step - loss: 9.6721\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.6721\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 254us/step - loss: 9.6721\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 9.6721\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 9.6721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2054f208>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32., 15., 35., 36., 31., 33., 34., 21., 23., 21., 31., 29., 27.,\n",
       "        29., 31., 19., 35., 35., 37., 34., 34., 21., 33., 37., 33., 32.,\n",
       "        34., 32., 30., 26., 34., 30., 35., 32., 34., 26., 33., 33., 29.,\n",
       "        29., 31., 31., 18., 24., 31., 31., 31., 32., 29., 26., 29., 29.,\n",
       "        30., 32., 31., 41., 30., 38., 21., 26., 31., 24., 25., 25., 35.,\n",
       "        32., 28., 30., 30., 32., 30., 34., 30., 30., 30., 29., 37., 34.,\n",
       "        34., 19., 24., 35., 20., 21., 29., 34., 13., 32., 27., 31., 26.,\n",
       "        30., 40., 28., 26., 29., 32., 31., 16., 29., 32., 18., 30., 30.,\n",
       "        33., 29., 25., 37., 26., 31., 33., 32., 30., 34., 34., 32., 33.,\n",
       "        32., 35., 36., 35., 29., 36., 18., 34., 35., 39., 33., 28., 32.,\n",
       "        35., 32., 39., 36., 32., 29., 35., 30., 31., 31., 30., 31., 34.,\n",
       "        24., 25., 29., 25., 25., 38., 35., 31., 32.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([21.7, 18.6, 50. , 18.6, 19.4, 33. , 30.3, 14.8, 16.4, 20.2, 24.4,\n",
       "       19.3, 14.2, 14.6, 23.1,  8.8, 35.4, 24.1, 19.4, 50. , 28.4, 16.3,\n",
       "       39.8, 21.9, 19.6, 22.2, 23.7, 11.9, 24.5, 14.4, 22.9, 21.8, 45.4,\n",
       "       30.1, 29.6, 10.5, 22.9, 50. , 20. , 14.3, 36.2, 22.6, 25. ,  5.6,\n",
       "       20.1, 17.4, 20.1, 27.1, 18.1, 11.8, 15. , 24.3, 20.1, 29.4, 22.4,\n",
       "       34.9, 18.4, 24.7,  5. , 14.9, 24.2, 12.7, 17.3,  7. , 28.2, 29.9,\n",
       "       19.7, 18.3, 20.3, 23.8, 16.5, 24. , 21.7, 15.2, 19.6, 18.7, 29. ,\n",
       "       43.1, 24.4,  5. , 14.4, 43.5, 14.9, 14.5, 15.4, 24.4, 13.8, 25. ,\n",
       "       15.6, 19.4,  8.3, 12.6, 48.5, 19.8, 19.1, 19.5, 17.7, 21. ,  8.4,\n",
       "       20.4, 26.5,  8.5, 21.7, 21.7, 22.1, 16.8, 13.1, 20.9, 19.6, 21.2,\n",
       "       24.8, 18.7, 22.5, 48.8, 37. , 20.7, 22. , 26.6, 22.9, 32.4, 29.1,\n",
       "       22.4, 31.1, 10.2, 50. , 22.2, 50. , 28.7, 12.1, 20. , 18.9, 23. ,\n",
       "       27.9, 36.4, 23.8, 19.9, 36.1, 15.1, 16. , 18.4, 18.2, 23.3, 22. ,\n",
       "       10.5, 14.6, 20.5, 22.3, 20.8, 30.8, 32.7, 22. , 19.5],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21195011311455778"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080348</td>\n",
       "      <td>-0.394817</td>\n",
       "      <td>-0.890183</td>\n",
       "      <td>0.371012</td>\n",
       "      <td>-0.729959</td>\n",
       "      <td>0.941728</td>\n",
       "      <td>2.038580</td>\n",
       "      <td>0.344230</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>-0.748164</td>\n",
       "      <td>-0.248955</td>\n",
       "      <td>-0.280126</td>\n",
       "      <td>0.092254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.115092</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>1.081599</td>\n",
       "      <td>-1.335076</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>0.530724</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.171785</td>\n",
       "      <td>-1.591981</td>\n",
       "      <td>0.471225</td>\n",
       "      <td>-0.110589</td>\n",
       "      <td>0.393893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.678670</td>\n",
       "      <td>0.109902</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>-0.192856</td>\n",
       "      <td>-0.352267</td>\n",
       "      <td>-0.167803</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>0.755681</td>\n",
       "      <td>-0.028307</td>\n",
       "      <td>-0.310263</td>\n",
       "      <td>-0.552134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.957708</td>\n",
       "      <td>2.691383</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.575203</td>\n",
       "      <td>0.883537</td>\n",
       "      <td>-0.790650</td>\n",
       "      <td>-0.139723</td>\n",
       "      <td>-0.029203</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>-1.924215</td>\n",
       "      <td>-0.190591</td>\n",
       "      <td>-0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.009087</td>\n",
       "      <td>0.196193</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>-1.122527</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.184398</td>\n",
       "      <td>-0.654900</td>\n",
       "      <td>-0.433389</td>\n",
       "      <td>1.050608</td>\n",
       "      <td>-0.023740</td>\n",
       "      <td>-0.310646</td>\n",
       "      <td>0.314520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.611866</td>\n",
       "      <td>0.137828</td>\n",
       "      <td>-0.531281</td>\n",
       "      <td>-0.444828</td>\n",
       "      <td>0.115007</td>\n",
       "      <td>-0.188192</td>\n",
       "      <td>-1.068207</td>\n",
       "      <td>-0.249310</td>\n",
       "      <td>-0.612161</td>\n",
       "      <td>-0.099950</td>\n",
       "      <td>0.827616</td>\n",
       "      <td>-0.404626</td>\n",
       "      <td>-0.524731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.338056</td>\n",
       "      <td>-0.323253</td>\n",
       "      <td>1.205601</td>\n",
       "      <td>1.744052</td>\n",
       "      <td>-0.362501</td>\n",
       "      <td>-0.347251</td>\n",
       "      <td>-0.274208</td>\n",
       "      <td>1.125857</td>\n",
       "      <td>0.471972</td>\n",
       "      <td>-0.353582</td>\n",
       "      <td>0.172697</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>0.391402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.249902</td>\n",
       "      <td>-1.540512</td>\n",
       "      <td>-0.316446</td>\n",
       "      <td>0.389658</td>\n",
       "      <td>1.098720</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>-0.371540</td>\n",
       "      <td>-0.349467</td>\n",
       "      <td>-0.161251</td>\n",
       "      <td>-0.315329</td>\n",
       "      <td>-1.166842</td>\n",
       "      <td>-0.349731</td>\n",
       "      <td>0.014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.960374</td>\n",
       "      <td>2.726205</td>\n",
       "      <td>0.573851</td>\n",
       "      <td>-0.488915</td>\n",
       "      <td>2.904541</td>\n",
       "      <td>-1.689157</td>\n",
       "      <td>1.238750</td>\n",
       "      <td>0.475148</td>\n",
       "      <td>0.423293</td>\n",
       "      <td>-0.043176</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>0.118429</td>\n",
       "      <td>0.235490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.657942</td>\n",
       "      <td>-0.054441</td>\n",
       "      <td>-0.837061</td>\n",
       "      <td>-0.077872</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.086200</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.189647</td>\n",
       "      <td>0.306190</td>\n",
       "      <td>0.377249</td>\n",
       "      <td>1.069730</td>\n",
       "      <td>-0.342973</td>\n",
       "      <td>0.129854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.636011</td>\n",
       "      <td>-0.072869</td>\n",
       "      <td>-1.239630</td>\n",
       "      <td>0.456554</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.878649</td>\n",
       "      <td>-0.860661</td>\n",
       "      <td>0.708222</td>\n",
       "      <td>1.563122</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>-0.569178</td>\n",
       "      <td>-0.148434</td>\n",
       "      <td>0.493215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.009365</td>\n",
       "      <td>0.191193</td>\n",
       "      <td>2.148391</td>\n",
       "      <td>2.001960</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>-1.530055</td>\n",
       "      <td>1.489968</td>\n",
       "      <td>-2.731570</td>\n",
       "      <td>0.459341</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>-0.264038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.175675</td>\n",
       "      <td>-0.277053</td>\n",
       "      <td>1.865595</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>-0.430563</td>\n",
       "      <td>-0.528763</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>1.725652</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-1.158937</td>\n",
       "      <td>0.687860</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>-0.771315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.985661</td>\n",
       "      <td>2.895293</td>\n",
       "      <td>0.544915</td>\n",
       "      <td>-0.480189</td>\n",
       "      <td>-1.177606</td>\n",
       "      <td>-0.463066</td>\n",
       "      <td>-0.338959</td>\n",
       "      <td>-0.379896</td>\n",
       "      <td>0.370657</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>-0.022322</td>\n",
       "      <td>0.673355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.080628</td>\n",
       "      <td>-0.155687</td>\n",
       "      <td>-1.017810</td>\n",
       "      <td>0.497181</td>\n",
       "      <td>-0.715356</td>\n",
       "      <td>-1.729263</td>\n",
       "      <td>2.308184</td>\n",
       "      <td>-0.125476</td>\n",
       "      <td>-1.382472</td>\n",
       "      <td>0.852165</td>\n",
       "      <td>-1.760670</td>\n",
       "      <td>-1.251921</td>\n",
       "      <td>-0.786614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.943787</td>\n",
       "      <td>0.191897</td>\n",
       "      <td>2.283650</td>\n",
       "      <td>3.452496</td>\n",
       "      <td>0.053454</td>\n",
       "      <td>-0.170607</td>\n",
       "      <td>-0.112187</td>\n",
       "      <td>-1.098166</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>0.608938</td>\n",
       "      <td>0.653165</td>\n",
       "      <td>-0.266726</td>\n",
       "      <td>-0.091649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.535033</td>\n",
       "      <td>-0.084668</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>-0.641210</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>0.202774</td>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>0.833602</td>\n",
       "      <td>2.085996</td>\n",
       "      <td>0.073895</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.349866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.404678</td>\n",
       "      <td>-0.613735</td>\n",
       "      <td>-0.231168</td>\n",
       "      <td>0.308832</td>\n",
       "      <td>-0.178946</td>\n",
       "      <td>1.354895</td>\n",
       "      <td>-1.057672</td>\n",
       "      <td>-0.458506</td>\n",
       "      <td>-0.332231</td>\n",
       "      <td>-0.585559</td>\n",
       "      <td>-0.053712</td>\n",
       "      <td>-0.211421</td>\n",
       "      <td>-1.758293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.196783</td>\n",
       "      <td>-0.414817</td>\n",
       "      <td>1.490226</td>\n",
       "      <td>-2.874329</td>\n",
       "      <td>-0.251195</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>1.518385</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-0.317663</td>\n",
       "      <td>-0.738418</td>\n",
       "      <td>-0.211338</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>-0.686020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.898128</td>\n",
       "      <td>2.359720</td>\n",
       "      <td>0.329719</td>\n",
       "      <td>-0.233685</td>\n",
       "      <td>-1.512660</td>\n",
       "      <td>-0.211246</td>\n",
       "      <td>-0.626046</td>\n",
       "      <td>-0.492962</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.065852</td>\n",
       "      <td>-0.662386</td>\n",
       "      <td>-0.185006</td>\n",
       "      <td>0.625654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.351897</td>\n",
       "      <td>-0.876389</td>\n",
       "      <td>0.301938</td>\n",
       "      <td>-0.427105</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>2.323010</td>\n",
       "      <td>-0.937386</td>\n",
       "      <td>-0.412936</td>\n",
       "      <td>-0.766805</td>\n",
       "      <td>-1.074004</td>\n",
       "      <td>-1.122226</td>\n",
       "      <td>-0.137080</td>\n",
       "      <td>0.442295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.843534</td>\n",
       "      <td>0.090307</td>\n",
       "      <td>-0.500667</td>\n",
       "      <td>-0.592639</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>-1.092255</td>\n",
       "      <td>-0.577864</td>\n",
       "      <td>1.215063</td>\n",
       "      <td>-0.036064</td>\n",
       "      <td>-0.900039</td>\n",
       "      <td>-0.542748</td>\n",
       "      <td>-0.305855</td>\n",
       "      <td>0.150305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050379</td>\n",
       "      <td>-0.584889</td>\n",
       "      <td>-1.041110</td>\n",
       "      <td>0.572919</td>\n",
       "      <td>-0.818853</td>\n",
       "      <td>0.079107</td>\n",
       "      <td>2.221296</td>\n",
       "      <td>0.277487</td>\n",
       "      <td>1.849282</td>\n",
       "      <td>-0.427553</td>\n",
       "      <td>-0.648227</td>\n",
       "      <td>-0.398190</td>\n",
       "      <td>0.193268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.779425</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>1.043213</td>\n",
       "      <td>-0.670624</td>\n",
       "      <td>0.244888</td>\n",
       "      <td>-0.056817</td>\n",
       "      <td>-0.533982</td>\n",
       "      <td>-1.080526</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>1.450427</td>\n",
       "      <td>0.390579</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>0.948641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.304556</td>\n",
       "      <td>3.399690</td>\n",
       "      <td>2.066358</td>\n",
       "      <td>-0.485542</td>\n",
       "      <td>0.191075</td>\n",
       "      <td>0.487928</td>\n",
       "      <td>1.877667</td>\n",
       "      <td>0.472362</td>\n",
       "      <td>-0.851668</td>\n",
       "      <td>-0.475440</td>\n",
       "      <td>0.433045</td>\n",
       "      <td>0.416610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.545173</td>\n",
       "      <td>0.222524</td>\n",
       "      <td>-0.127907</td>\n",
       "      <td>0.237873</td>\n",
       "      <td>0.282217</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>-0.648339</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>-0.102407</td>\n",
       "      <td>-0.167001</td>\n",
       "      <td>-0.170500</td>\n",
       "      <td>0.992560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.984151</td>\n",
       "      <td>0.225336</td>\n",
       "      <td>-0.140532</td>\n",
       "      <td>0.457158</td>\n",
       "      <td>0.209959</td>\n",
       "      <td>-0.100670</td>\n",
       "      <td>-0.462245</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>2.007666</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>-0.460942</td>\n",
       "      <td>-0.511064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.808280</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>-0.837358</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.093117</td>\n",
       "      <td>-1.640965</td>\n",
       "      <td>-0.719455</td>\n",
       "      <td>1.428069</td>\n",
       "      <td>0.283175</td>\n",
       "      <td>-0.634228</td>\n",
       "      <td>-2.059973</td>\n",
       "      <td>-0.474163</td>\n",
       "      <td>-0.548719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.994640</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>2.200903</td>\n",
       "      <td>2.732752</td>\n",
       "      <td>0.037579</td>\n",
       "      <td>-0.152012</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>-1.081080</td>\n",
       "      <td>0.102347</td>\n",
       "      <td>-1.146830</td>\n",
       "      <td>-0.437390</td>\n",
       "      <td>-0.314694</td>\n",
       "      <td>-0.672085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.275527</td>\n",
       "      <td>-1.331517</td>\n",
       "      <td>0.176396</td>\n",
       "      <td>-0.262578</td>\n",
       "      <td>-0.404761</td>\n",
       "      <td>0.388403</td>\n",
       "      <td>-0.596450</td>\n",
       "      <td>-0.757497</td>\n",
       "      <td>-0.202598</td>\n",
       "      <td>-0.207741</td>\n",
       "      <td>-0.193679</td>\n",
       "      <td>-0.247489</td>\n",
       "      <td>0.767546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.448404</td>\n",
       "      <td>3.017727</td>\n",
       "      <td>-0.447951</td>\n",
       "      <td>-0.095226</td>\n",
       "      <td>-0.986589</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>1.900239</td>\n",
       "      <td>0.300365</td>\n",
       "      <td>-1.736481</td>\n",
       "      <td>0.142566</td>\n",
       "      <td>0.208303</td>\n",
       "      <td>3.278740</td>\n",
       "      <td>3.117442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.637666</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>0.803028</td>\n",
       "      <td>-2.211732</td>\n",
       "      <td>0.133059</td>\n",
       "      <td>-0.773462</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>-0.569493</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-1.386104</td>\n",
       "      <td>0.410985</td>\n",
       "      <td>-0.254111</td>\n",
       "      <td>0.349224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.742337</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>-0.303305</td>\n",
       "      <td>-0.809501</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.898387</td>\n",
       "      <td>-0.673318</td>\n",
       "      <td>1.440644</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>-1.025311</td>\n",
       "      <td>0.145561</td>\n",
       "      <td>-0.137611</td>\n",
       "      <td>-0.612576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.863527</td>\n",
       "      <td>0.151054</td>\n",
       "      <td>-0.621895</td>\n",
       "      <td>1.102764</td>\n",
       "      <td>0.127329</td>\n",
       "      <td>-0.637058</td>\n",
       "      <td>-0.923254</td>\n",
       "      <td>0.052150</td>\n",
       "      <td>-2.615026</td>\n",
       "      <td>-1.113191</td>\n",
       "      <td>-0.353638</td>\n",
       "      <td>-0.942371</td>\n",
       "      <td>1.263226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.250864</td>\n",
       "      <td>-1.539722</td>\n",
       "      <td>-0.320317</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>1.494396</td>\n",
       "      <td>1.996060</td>\n",
       "      <td>-0.855019</td>\n",
       "      <td>-0.153564</td>\n",
       "      <td>-0.572640</td>\n",
       "      <td>-0.513297</td>\n",
       "      <td>-0.060177</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>0.233746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.845037</td>\n",
       "      <td>2.016857</td>\n",
       "      <td>0.079042</td>\n",
       "      <td>0.082106</td>\n",
       "      <td>-0.680868</td>\n",
       "      <td>-0.186099</td>\n",
       "      <td>-0.529998</td>\n",
       "      <td>-0.301536</td>\n",
       "      <td>0.243190</td>\n",
       "      <td>-0.029481</td>\n",
       "      <td>-1.333357</td>\n",
       "      <td>-0.259586</td>\n",
       "      <td>-1.784060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.330616</td>\n",
       "      <td>-1.041621</td>\n",
       "      <td>-0.163635</td>\n",
       "      <td>0.216016</td>\n",
       "      <td>-0.180344</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>-0.562350</td>\n",
       "      <td>-0.604425</td>\n",
       "      <td>0.084291</td>\n",
       "      <td>0.441959</td>\n",
       "      <td>1.107620</td>\n",
       "      <td>-0.197033</td>\n",
       "      <td>-1.626711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.038869</td>\n",
       "      <td>0.083404</td>\n",
       "      <td>-1.058361</td>\n",
       "      <td>0.544799</td>\n",
       "      <td>-0.519040</td>\n",
       "      <td>-0.246005</td>\n",
       "      <td>1.843414</td>\n",
       "      <td>0.062016</td>\n",
       "      <td>-1.608033</td>\n",
       "      <td>1.175863</td>\n",
       "      <td>0.911292</td>\n",
       "      <td>-0.930218</td>\n",
       "      <td>-1.208786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.802686</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>2.691830</td>\n",
       "      <td>2.205935</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.910832</td>\n",
       "      <td>0.617372</td>\n",
       "      <td>0.393352</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>-0.563892</td>\n",
       "      <td>-0.681889</td>\n",
       "      <td>-0.061548</td>\n",
       "      <td>-0.110975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.248989</td>\n",
       "      <td>-1.540390</td>\n",
       "      <td>-0.259678</td>\n",
       "      <td>0.338137</td>\n",
       "      <td>1.419395</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>0.247133</td>\n",
       "      <td>-0.372901</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>-0.375925</td>\n",
       "      <td>-1.600665</td>\n",
       "      <td>-0.439351</td>\n",
       "      <td>0.211505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.509456</td>\n",
       "      <td>0.064296</td>\n",
       "      <td>2.700187</td>\n",
       "      <td>1.597607</td>\n",
       "      <td>-0.144598</td>\n",
       "      <td>0.310441</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>0.585163</td>\n",
       "      <td>3.476441</td>\n",
       "      <td>1.317026</td>\n",
       "      <td>0.872823</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>1.922435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1.231409</td>\n",
       "      <td>-1.538950</td>\n",
       "      <td>0.688780</td>\n",
       "      <td>-0.936760</td>\n",
       "      <td>-0.398978</td>\n",
       "      <td>-0.730870</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>-0.940533</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>0.675256</td>\n",
       "      <td>0.089150</td>\n",
       "      <td>-0.217405</td>\n",
       "      <td>-1.520989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.534067</td>\n",
       "      <td>-0.182972</td>\n",
       "      <td>2.735200</td>\n",
       "      <td>1.545595</td>\n",
       "      <td>-0.155897</td>\n",
       "      <td>0.187525</td>\n",
       "      <td>0.503330</td>\n",
       "      <td>0.394356</td>\n",
       "      <td>-0.256181</td>\n",
       "      <td>-0.892626</td>\n",
       "      <td>1.122224</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>-0.519524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-0.188002</td>\n",
       "      <td>-0.354648</td>\n",
       "      <td>1.814985</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>-0.423748</td>\n",
       "      <td>-0.521735</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.755776</td>\n",
       "      <td>-1.094067</td>\n",
       "      <td>0.626996</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>-0.036445</td>\n",
       "      <td>-0.217247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.069057</td>\n",
       "      <td>-0.099665</td>\n",
       "      <td>-1.132815</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>-0.730913</td>\n",
       "      <td>-1.100634</td>\n",
       "      <td>2.043489</td>\n",
       "      <td>-0.061708</td>\n",
       "      <td>-1.495209</td>\n",
       "      <td>0.700378</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>-1.033186</td>\n",
       "      <td>3.565111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-1.086996</td>\n",
       "      <td>0.369113</td>\n",
       "      <td>0.343296</td>\n",
       "      <td>-0.357972</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>1.026568</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>-0.774167</td>\n",
       "      <td>0.254745</td>\n",
       "      <td>-1.067171</td>\n",
       "      <td>0.603821</td>\n",
       "      <td>-0.176953</td>\n",
       "      <td>-0.166501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.190903</td>\n",
       "      <td>-0.402475</td>\n",
       "      <td>1.511917</td>\n",
       "      <td>0.657549</td>\n",
       "      <td>-0.407703</td>\n",
       "      <td>-0.352837</td>\n",
       "      <td>-0.155576</td>\n",
       "      <td>1.782732</td>\n",
       "      <td>-1.411651</td>\n",
       "      <td>-1.642066</td>\n",
       "      <td>0.222688</td>\n",
       "      <td>-0.066098</td>\n",
       "      <td>-1.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.918492</td>\n",
       "      <td>2.448586</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>-0.600437</td>\n",
       "      <td>0.520436</td>\n",
       "      <td>-0.741136</td>\n",
       "      <td>-0.175211</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>-0.164630</td>\n",
       "      <td>-1.124253</td>\n",
       "      <td>-0.171095</td>\n",
       "      <td>0.864909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-1.036607</td>\n",
       "      <td>0.232198</td>\n",
       "      <td>-0.630966</td>\n",
       "      <td>-0.585621</td>\n",
       "      <td>0.471721</td>\n",
       "      <td>1.047169</td>\n",
       "      <td>-0.671226</td>\n",
       "      <td>-0.113630</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>1.669281</td>\n",
       "      <td>0.383386</td>\n",
       "      <td>-0.356056</td>\n",
       "      <td>-0.501093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.593573</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>-1.209316</td>\n",
       "      <td>1.399069</td>\n",
       "      <td>0.283667</td>\n",
       "      <td>2.809910</td>\n",
       "      <td>-1.617712</td>\n",
       "      <td>0.692484</td>\n",
       "      <td>-1.553295</td>\n",
       "      <td>2.757605</td>\n",
       "      <td>-0.812138</td>\n",
       "      <td>-0.679586</td>\n",
       "      <td>-0.578312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.793258</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>-1.138782</td>\n",
       "      <td>0.220145</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>0.694742</td>\n",
       "      <td>-1.275697</td>\n",
       "      <td>-0.662284</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>-0.241130</td>\n",
       "      <td>-0.972592</td>\n",
       "      <td>-0.584089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.858731</td>\n",
       "      <td>0.142945</td>\n",
       "      <td>-0.984352</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>0.148730</td>\n",
       "      <td>-0.576002</td>\n",
       "      <td>-1.127209</td>\n",
       "      <td>0.135239</td>\n",
       "      <td>-2.526001</td>\n",
       "      <td>-0.874003</td>\n",
       "      <td>-0.672065</td>\n",
       "      <td>-1.024450</td>\n",
       "      <td>1.060107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.246741</td>\n",
       "      <td>-1.540688</td>\n",
       "      <td>-0.173736</td>\n",
       "      <td>0.186121</td>\n",
       "      <td>0.273360</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>-0.735751</td>\n",
       "      <td>-0.534623</td>\n",
       "      <td>-0.272326</td>\n",
       "      <td>-0.240316</td>\n",
       "      <td>0.196462</td>\n",
       "      <td>-0.218107</td>\n",
       "      <td>1.164912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.181469</td>\n",
       "      <td>1.443857</td>\n",
       "      <td>-0.453647</td>\n",
       "      <td>-0.179776</td>\n",
       "      <td>-0.862378</td>\n",
       "      <td>-0.038269</td>\n",
       "      <td>1.993915</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>-1.710368</td>\n",
       "      <td>0.748365</td>\n",
       "      <td>0.861978</td>\n",
       "      <td>-0.781257</td>\n",
       "      <td>-1.071121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.819563</td>\n",
       "      <td>0.096842</td>\n",
       "      <td>0.264932</td>\n",
       "      <td>-1.586421</td>\n",
       "      <td>0.071846</td>\n",
       "      <td>-1.046755</td>\n",
       "      <td>-0.297640</td>\n",
       "      <td>1.274354</td>\n",
       "      <td>-0.194642</td>\n",
       "      <td>-1.549125</td>\n",
       "      <td>-1.857324</td>\n",
       "      <td>-0.234793</td>\n",
       "      <td>0.067342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.849991</td>\n",
       "      <td>0.205352</td>\n",
       "      <td>-0.888543</td>\n",
       "      <td>1.466501</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>-1.092184</td>\n",
       "      <td>-0.933734</td>\n",
       "      <td>0.064675</td>\n",
       "      <td>-2.440991</td>\n",
       "      <td>-1.015456</td>\n",
       "      <td>-0.059666</td>\n",
       "      <td>-0.988334</td>\n",
       "      <td>1.042627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.229282</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>-1.121209</td>\n",
       "      <td>0.570964</td>\n",
       "      <td>-0.437700</td>\n",
       "      <td>-0.485966</td>\n",
       "      <td>-0.532777</td>\n",
       "      <td>1.497981</td>\n",
       "      <td>1.544072</td>\n",
       "      <td>-1.200528</td>\n",
       "      <td>-0.152799</td>\n",
       "      <td>-0.081302</td>\n",
       "      <td>-0.440124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.569485</td>\n",
       "      <td>-0.151394</td>\n",
       "      <td>2.260648</td>\n",
       "      <td>2.176295</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>-0.292190</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>1.312312</td>\n",
       "      <td>-1.773981</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>-0.416606</td>\n",
       "      <td>-0.314958</td>\n",
       "      <td>-0.636563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1.257425</td>\n",
       "      <td>-1.486130</td>\n",
       "      <td>-0.288594</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>-0.495139</td>\n",
       "      <td>-0.636809</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>-0.162717</td>\n",
       "      <td>-0.565589</td>\n",
       "      <td>-0.377851</td>\n",
       "      <td>0.389921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.786884</td>\n",
       "      <td>0.135389</td>\n",
       "      <td>-0.801586</td>\n",
       "      <td>-0.232461</td>\n",
       "      <td>0.242451</td>\n",
       "      <td>1.257130</td>\n",
       "      <td>-0.209978</td>\n",
       "      <td>-0.291861</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.478781</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.409151</td>\n",
       "      <td>-0.691410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0    0.080348 -0.394817 -0.890183  0.371012 -0.729959  0.941728  2.038580   \n",
       "1   -1.115092  0.278251  1.081599 -1.335076  0.450709  0.342844  0.530724   \n",
       "2   -0.678670  0.109902  0.841250  0.052771  0.031168 -0.192856 -0.352267   \n",
       "3    1.957708  2.691383  0.204966 -0.059570 -0.575203  0.883537 -0.790650   \n",
       "4   -1.009087  0.196193  1.046665 -1.122527  0.320851 -0.093841  0.184398   \n",
       "5   -0.611866  0.137828 -0.531281 -0.444828  0.115007 -0.188192 -1.068207   \n",
       "6   -0.338056 -0.323253  1.205601  1.744052 -0.362501 -0.347251 -0.274208   \n",
       "7    1.249902 -1.540512 -0.316446  0.389658  1.098720  0.224061 -0.371540   \n",
       "8    1.960374  2.726205  0.573851 -0.488915  2.904541 -1.689157  1.238750   \n",
       "9   -0.657942 -0.054441 -0.837061 -0.077872 -0.043811 -0.086200  0.009856   \n",
       "10  -0.636011 -0.072869 -1.239630  0.456554  0.231618  0.878649 -0.860661   \n",
       "11  -1.009365  0.191193  2.148391  2.001960  0.143939 -0.012545  0.671094   \n",
       "12  -0.175675 -0.277053  1.865595  0.199379 -0.430563 -0.528763  0.068854   \n",
       "13   1.985661  2.895293  0.544915 -0.480189 -1.177606 -0.463066 -0.338959   \n",
       "14  -0.080628 -0.155687 -1.017810  0.497181 -0.715356 -1.729263  2.308184   \n",
       "15  -0.943787  0.191897  2.283650  3.452496  0.053454 -0.170607 -0.112187   \n",
       "16  -0.535033 -0.084668  0.958809 -0.641210  0.074573  0.202774 -0.423037   \n",
       "17   1.404678 -0.613735 -0.231168  0.308832 -0.178946  1.354895 -1.057672   \n",
       "18  -0.196783 -0.414817  1.490226 -2.874329 -0.251195  0.331195  1.518385   \n",
       "19   1.898128  2.359720  0.329719 -0.233685 -1.512660 -0.211246 -0.626046   \n",
       "20   1.351897 -0.876389  0.301938 -0.427105  0.437554  2.323010 -0.937386   \n",
       "21  -0.843534  0.090307 -0.500667 -0.592639  0.019766 -1.092255 -0.577864   \n",
       "22   0.050379 -0.584889 -1.041110  0.572919 -0.818853  0.079107  2.221296   \n",
       "23  -0.779425  0.097954  1.043213 -0.670624  0.244888 -0.056817 -0.533982   \n",
       "24  -0.176788 -0.304556  3.399690  2.066358 -0.485542  0.191075  0.487928   \n",
       "25   1.545173  0.222524 -0.127907  0.237873  0.282217  0.656231 -0.648339   \n",
       "26  -0.984151  0.225336 -0.140532  0.457158  0.209959 -0.100670 -0.462245   \n",
       "27  -0.808280  0.055035 -0.837358 -0.115261 -0.093117 -1.640965 -0.719455   \n",
       "28  -0.994640  0.314741  2.200903  2.732752  0.037579 -0.152012  0.626242   \n",
       "29   1.275527 -1.331517  0.176396 -0.262578 -0.404761  0.388403 -0.596450   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324  0.448404  3.017727 -0.447951 -0.095226 -0.986589  0.186189  1.900239   \n",
       "325 -0.637666  0.119517  0.803028 -2.211732  0.133059 -0.773462 -0.165652   \n",
       "326 -0.742337  0.495750 -0.303305 -0.809501 -0.052632 -0.898387 -0.673318   \n",
       "327 -0.863527  0.151054 -0.621895  1.102764  0.127329 -0.637058 -0.923254   \n",
       "328  1.250864 -1.539722 -0.320317  0.369770  1.494396  1.996060 -0.855019   \n",
       "329  1.845037  2.016857  0.079042  0.082106 -0.680868 -0.186099 -0.529998   \n",
       "330  1.330616 -1.041621 -0.163635  0.216016 -0.180344 -0.059550 -0.562350   \n",
       "331 -0.038869  0.083404 -1.058361  0.544799 -0.519040 -0.246005  1.843414   \n",
       "332 -0.802686  0.054897  2.691830  2.205935  0.040140  0.910832  0.617372   \n",
       "333  1.248989 -1.540390 -0.259678  0.338137  1.419395 -1.254890  0.247133   \n",
       "334 -0.509456  0.064296  2.700187  1.597607 -0.144598  0.310441 -0.006960   \n",
       "335  1.231409 -1.538950  0.688780 -0.936760 -0.398978 -0.730870  0.026377   \n",
       "336 -0.534067 -0.182972  2.735200  1.545595 -0.155897  0.187525  0.503330   \n",
       "337 -0.188002 -0.354648  1.814985  0.266498 -0.423748 -0.521735  0.005338   \n",
       "338 -0.069057 -0.099665 -1.132815  0.642774 -0.730913 -1.100634  2.043489   \n",
       "339 -1.086996  0.369113  0.343296 -0.357972  0.485442  1.026568 -0.074474   \n",
       "340 -0.190903 -0.402475  1.511917  0.657549 -0.407703 -0.352837 -0.155576   \n",
       "341  1.918492  2.448586  0.081510  0.095092 -0.600437  0.520436 -0.741136   \n",
       "342 -1.036607  0.232198 -0.630966 -0.585621  0.471721  1.047169 -0.671226   \n",
       "343 -0.593573  0.027279 -1.209316  1.399069  0.283667  2.809910 -1.617712   \n",
       "344 -0.793258  0.099612 -1.138782  0.220145 -0.077865 -0.385340  0.694742   \n",
       "345 -0.858731  0.142945 -0.984352  1.583382  0.148730 -0.576002 -1.127209   \n",
       "346  1.246741 -1.540688 -0.173736  0.186121  0.273360  0.841098 -0.735751   \n",
       "347  0.181469  1.443857 -0.453647 -0.179776 -0.862378 -0.038269  1.993915   \n",
       "348 -0.819563  0.096842  0.264932 -1.586421  0.071846 -1.046755 -0.297640   \n",
       "349 -0.849991  0.205352 -0.888543  1.466501  0.024785 -1.092184 -0.933734   \n",
       "350 -0.229282 -0.369674 -1.121209  0.570964 -0.437700 -0.485966 -0.532777   \n",
       "351 -0.569485 -0.151394  2.260648  2.176295 -0.257481 -0.292190  0.280509   \n",
       "352  1.257425 -1.486130 -0.288594  0.357705 -0.014140 -0.290924 -0.495139   \n",
       "353 -0.786884  0.135389 -0.801586 -0.232461  0.242451  1.257130 -0.209978   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.344230  1.603922 -0.748164 -0.248955 -0.280126  0.092254  \n",
       "1   -0.992543  0.171785 -1.591981  0.471225 -0.110589  0.393893  \n",
       "2   -0.167803 -0.456787  0.755681 -0.028307 -0.310263 -0.552134  \n",
       "3   -0.139723 -0.029203 -0.473747 -1.924215 -0.190591 -0.187401  \n",
       "4   -0.654900 -0.433389  1.050608 -0.023740 -0.310646  0.314520  \n",
       "5   -0.249310 -0.612161 -0.099950  0.827616 -0.404626 -0.524731  \n",
       "6    1.125857  0.471972 -0.353582  0.172697  0.022303  0.391402  \n",
       "7   -0.349467 -0.161251 -0.315329 -1.166842 -0.349731  0.014179  \n",
       "8    0.475148  0.423293 -0.043176  0.395698  0.118429  0.235490  \n",
       "9    0.189647  0.306190  0.377249  1.069730 -0.342973  0.129854  \n",
       "10   0.708222  1.563122 -0.154623 -0.569178 -0.148434  0.493215  \n",
       "11  -1.530055  1.489968 -2.731570  0.459341  0.036337 -0.264038  \n",
       "12   1.725652 -1.356036 -1.158937  0.687860  0.026640 -0.771315  \n",
       "13  -0.379896  0.370657  0.345026  0.494635 -0.022322  0.673355  \n",
       "14  -0.125476 -1.382472  0.852165 -1.760670 -1.251921 -0.786614  \n",
       "15  -1.098166 -0.018907  0.608938  0.653165 -0.266726 -0.091649  \n",
       "16  -0.009278  0.833602  2.085996  0.073895  0.009437  0.349866  \n",
       "17  -0.458506 -0.332231 -0.585559 -0.053712 -0.211421 -1.758293  \n",
       "18   0.603767 -0.317663 -0.738418 -0.211338  0.043863 -0.686020  \n",
       "19  -0.492962  0.273988  0.065852 -0.662386 -0.185006  0.625654  \n",
       "20  -0.412936 -0.766805 -1.074004 -1.122226 -0.137080  0.442295  \n",
       "21   1.215063 -0.036064 -0.900039 -0.542748 -0.305855  0.150305  \n",
       "22   0.277487  1.849282 -0.427553 -0.648227 -0.398190  0.193268  \n",
       "23  -1.080526  1.165125  1.450427  0.390579 -0.020257  0.948641  \n",
       "24   1.877667  0.472362 -0.851668 -0.475440  0.433045  0.416610  \n",
       "25  -0.269487 -0.078472 -0.102407 -0.167001 -0.170500  0.992560  \n",
       "26  -0.424416 -0.047900  2.007666  0.541705 -0.460942 -0.511064  \n",
       "27   1.428069  0.283175 -0.634228 -2.059973 -0.474163 -0.548719  \n",
       "28  -1.081080  0.102347 -1.146830 -0.437390 -0.314694 -0.672085  \n",
       "29  -0.757497 -0.202598 -0.207741 -0.193679 -0.247489  0.767546  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324  0.300365 -1.736481  0.142566  0.208303  3.278740  3.117442  \n",
       "325 -0.569493 -0.943414 -1.386104  0.410985 -0.254111  0.349224  \n",
       "326  1.440644  0.015810 -1.025311  0.145561 -0.137611 -0.612576  \n",
       "327  0.052150 -2.615026 -1.113191 -0.353638 -0.942371  1.263226  \n",
       "328 -0.153564 -0.572640 -0.513297 -0.060177 -0.138515  0.233746  \n",
       "329 -0.301536  0.243190 -0.029481 -1.333357 -0.259586 -1.784060  \n",
       "330 -0.604425  0.084291  0.441959  1.107620 -0.197033 -1.626711  \n",
       "331  0.062016 -1.608033  1.175863  0.911292 -0.930218 -1.208786  \n",
       "332  0.393352 -0.427835 -0.563892 -0.681889 -0.061548 -0.110975  \n",
       "333 -0.372901  0.121113 -0.375925 -1.600665 -0.439351  0.211505  \n",
       "334  0.585163  3.476441  1.317026  0.872823  0.785367  1.922435  \n",
       "335 -0.940533  0.054370  0.675256  0.089150 -0.217405 -1.520989  \n",
       "336  0.394356 -0.256181 -0.892626  1.122224  0.152020 -0.519524  \n",
       "337  1.755776 -1.094067  0.626996  0.061140 -0.036445 -0.217247  \n",
       "338 -0.061708 -1.495209  0.700378  0.447174 -1.033186  3.565111  \n",
       "339 -0.774167  0.254745 -1.067171  0.603821 -0.176953 -0.166501  \n",
       "340  1.782732 -1.411651 -1.642066  0.222688 -0.066098 -1.138598  \n",
       "341 -0.175211  0.105444 -0.164630 -1.124253 -0.171095  0.864909  \n",
       "342 -0.113630 -0.024870  1.669281  0.383386 -0.356056 -0.501093  \n",
       "343  0.692484 -1.553295  2.757605 -0.812138 -0.679586 -0.578312  \n",
       "344 -1.275697 -0.662284  0.814229 -0.241130 -0.972592 -0.584089  \n",
       "345  0.135239 -2.526001 -0.874003 -0.672065 -1.024450  1.060107  \n",
       "346 -0.534623 -0.272326 -0.240316  0.196462 -0.218107  1.164912  \n",
       "347  0.082282 -1.710368  0.748365  0.861978 -0.781257 -1.071121  \n",
       "348  1.274354 -0.194642 -1.549125 -1.857324 -0.234793  0.067342  \n",
       "349  0.064675 -2.440991 -1.015456 -0.059666 -0.988334  1.042627  \n",
       "350  1.497981  1.544072 -1.200528 -0.152799 -0.081302 -0.440124  \n",
       "351  1.312312 -1.773981  0.703413 -0.416606 -0.314958 -0.636563  \n",
       "352 -0.636809  0.011451 -0.162717 -0.565589 -0.377851  0.389921  \n",
       "353 -0.291861  0.157986  0.478781  0.014941 -0.409151 -0.691410  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 1ms/step - loss: 4.0109\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 3.1676\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.8138\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.6734\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.4503\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 1.3934\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 1.0855\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.8615\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7993\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7878\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7613\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7569\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7515\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.7522\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7488\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7494\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.7602\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7491\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7072\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7021\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.7114\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7072\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.7006\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.6975\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6963\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6949\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6943\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6993\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6941\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6882\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.6950\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6895\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6869\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6869\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6853\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6841\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6840\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6880\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.6821\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6801\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6845\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6880\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6805\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6788\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6803\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.6830\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6864\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6810\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6789\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6791\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6772\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6766\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6766\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.6794\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.6786\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.6748\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.6789\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.6782\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.6855\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.6266\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.4748\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.4604\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.4758\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2968\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.1317\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0811\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0942\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0911\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0726\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0865\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0689\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0701\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0939\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0738\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0767\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0800\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0679\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0628\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0653\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0634\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0768\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0921\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0787\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0679\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0636\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0657\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0637\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0612\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0607\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0695\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0650\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0651\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0641\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0615\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0749\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 0.0614\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 198us/step - loss: 0.0671\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0614\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 0.0613\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 0.0609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x204d36d8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
