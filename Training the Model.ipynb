{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For neural networks.\n",
    "import keras as kr\n",
    "# For data frames.\n",
    "import pandas as pd\n",
    "# For numerical arrays.\n",
    "import numpy as np\n",
    "# For preprocessing data.\n",
    "import sklearn.preprocessing as pre\n",
    "# For splitting data sets.\n",
    "import sklearn.model_selection as mod\n",
    "# For whitening.\n",
    "import sklearn.decomposition as dec\n",
    "from sklearn.datasets import load_boston #load the boston house proce index from the sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset = load_boston()\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston['MEDV'] = boston_dataset.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>392.53</td>\n",
       "      <td>13.83</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.54</td>\n",
       "      <td>19.88</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.33</td>\n",
       "      <td>16.30</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.88</td>\n",
       "      <td>14.81</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.047</td>\n",
       "      <td>88.8</td>\n",
       "      <td>4.4534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>306.38</td>\n",
       "      <td>17.28</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.77299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.495</td>\n",
       "      <td>94.4</td>\n",
       "      <td>4.4547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>387.94</td>\n",
       "      <td>12.80</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.23</td>\n",
       "      <td>11.98</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.21</td>\n",
       "      <td>18.68</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>379.70</td>\n",
       "      <td>18.03</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>14.33370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.229</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>383.32</td>\n",
       "      <td>13.11</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.82401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.7</td>\n",
       "      <td>3.4242</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.74</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.70818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.750</td>\n",
       "      <td>74.9</td>\n",
       "      <td>3.3317</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.07</td>\n",
       "      <td>7.74</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.73116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>7.061</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.28</td>\n",
       "      <td>7.01</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.92</td>\n",
       "      <td>10.42</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>370.73</td>\n",
       "      <td>13.34</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.62</td>\n",
       "      <td>10.58</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.69175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.114</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3.5459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.68</td>\n",
       "      <td>14.98</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.22</td>\n",
       "      <td>11.45</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.15086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.454</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.8209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>395.09</td>\n",
       "      <td>18.06</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.18337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.414</td>\n",
       "      <td>98.3</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>344.05</td>\n",
       "      <td>23.97</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>318.43</td>\n",
       "      <td>29.68</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.11132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>83.5</td>\n",
       "      <td>2.1099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.35</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.59</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.17899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.670</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>393.29</td>\n",
       "      <td>17.60</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.28960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.390</td>\n",
       "      <td>72.9</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.14</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.10</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.92</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
       "1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
       "2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
       "3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
       "4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
       "5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
       "6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
       "7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
       "8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
       "10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
       "11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
       "12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
       "13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
       "14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
       "15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
       "16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
       "17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
       "19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
       "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
       "22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
       "24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
       "26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
       "28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
       "29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       "476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
       "477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
       "478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
       "479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
       "480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
       "481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
       "482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
       "483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
       "486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
       "487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
       "488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
       "489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
       "490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
       "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       "492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
       "493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
       "495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
       "496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
       "497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
       "498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
       "499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
       "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
       "501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
       "502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
       "503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
       "504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
       "505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "5       18.7  394.12   5.21  28.7  \n",
       "6       15.2  395.60  12.43  22.9  \n",
       "7       15.2  396.90  19.15  27.1  \n",
       "8       15.2  386.63  29.93  16.5  \n",
       "9       15.2  386.71  17.10  18.9  \n",
       "10      15.2  392.52  20.45  15.0  \n",
       "11      15.2  396.90  13.27  18.9  \n",
       "12      15.2  390.50  15.71  21.7  \n",
       "13      21.0  396.90   8.26  20.4  \n",
       "14      21.0  380.02  10.26  18.2  \n",
       "15      21.0  395.62   8.47  19.9  \n",
       "16      21.0  386.85   6.58  23.1  \n",
       "17      21.0  386.75  14.67  17.5  \n",
       "18      21.0  288.99  11.69  20.2  \n",
       "19      21.0  390.95  11.28  18.2  \n",
       "20      21.0  376.57  21.02  13.6  \n",
       "21      21.0  392.53  13.83  19.6  \n",
       "22      21.0  396.90  18.72  15.2  \n",
       "23      21.0  394.54  19.88  14.5  \n",
       "24      21.0  394.33  16.30  15.6  \n",
       "25      21.0  303.42  16.51  13.9  \n",
       "26      21.0  376.88  14.81  16.6  \n",
       "27      21.0  306.38  17.28  14.8  \n",
       "28      21.0  387.94  12.80  18.4  \n",
       "29      21.0  380.23  11.98  21.0  \n",
       "..       ...     ...    ...   ...  \n",
       "476     20.2  396.21  18.68  16.7  \n",
       "477     20.2  349.48  24.91  12.0  \n",
       "478     20.2  379.70  18.03  14.6  \n",
       "479     20.2  383.32  13.11  21.4  \n",
       "480     20.2  396.90  10.74  23.0  \n",
       "481     20.2  393.07   7.74  23.7  \n",
       "482     20.2  395.28   7.01  25.0  \n",
       "483     20.2  392.92  10.42  21.8  \n",
       "484     20.2  370.73  13.34  20.6  \n",
       "485     20.2  388.62  10.58  21.2  \n",
       "486     20.2  392.68  14.98  19.1  \n",
       "487     20.2  388.22  11.45  20.6  \n",
       "488     20.1  395.09  18.06  15.2  \n",
       "489     20.1  344.05  23.97   7.0  \n",
       "490     20.1  318.43  29.68   8.1  \n",
       "491     20.1  390.11  18.07  13.6  \n",
       "492     20.1  396.90  13.35  20.1  \n",
       "493     19.2  396.90  12.01  21.8  \n",
       "494     19.2  396.90  13.59  24.5  \n",
       "495     19.2  393.29  17.60  23.1  \n",
       "496     19.2  396.90  21.14  19.7  \n",
       "497     19.2  396.90  14.10  18.3  \n",
       "498     19.2  396.90  12.92  21.2  \n",
       "499     19.2  395.77  15.10  17.5  \n",
       "500     19.2  396.90  14.33  16.8  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.iloc[:,0:13]\n",
    "y = boston.iloc[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = mod.train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 650us/step - loss: 2502.2045\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 167.9174\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 116.8635\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 100.8420\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 91.3929\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 87.0228\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 82.8010\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 80.5694\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 77.7305\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 76.5624\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 74.3577\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 71.8194\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 71.9270\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 70.5578\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 67.7593\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 66.6066\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 65.4261\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.2704\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 62.5482\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 61.5775\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 61.0241\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.9053\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.1644\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 57.8648\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 55.9479\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.1175\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.3852\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 52.6480\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 266us/step - loss: 54.1392\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 562us/step - loss: 52.0172\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 401us/step - loss: 49.7165\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 291us/step - loss: 50.5294\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 438us/step - loss: 48.7328\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 47.6938\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 47.0385\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 46.9882\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 45.8703\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 463us/step - loss: 45.6088\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 47.1310\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 44.5413\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 45.1136\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 42.9278\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 42.8571\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 42.1043\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 41.4426\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 40.1350\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.2596\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 40.2246\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 39.1191\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 39.4221\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.8953\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.4694\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.3987\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.6966\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.4895\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.0301\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.8144\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.8276\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.6441\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.7876\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.4305\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.7611\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.8712\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.9034\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.5609\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5882\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.1453\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.2686\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.5255\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.7180\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 263us/step - loss: 32.3655\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 381us/step - loss: 32.3557\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 32.6379\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 32.4172\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 31.9740\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 33.3456\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.0282\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 31.2551\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.1562\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 31.4450\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.0347\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.1022\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.3544\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 30.7706\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 30.0668\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 29.7948\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 31.9116\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 30.5452\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 328us/step - loss: 31.3749\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 285us/step - loss: 30.0794\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 31.8016\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.4376\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 198us/step - loss: 32.1209\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.7269\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5104\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5280\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.9314\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.4473\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1968\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.4906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xfb6fd68>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25., 35., 40., 12., 24., 35., 17., 16., 25., 20., 21.,  9., 38.,\n",
       "        19., 17., 28., 34., 28., 25., 22., 25., 23., 39., 27., 26.,  6.,\n",
       "        18., 16., 14., 14., 30., 24., 26., 20., 30., 41., 19., 27., 20.,\n",
       "        33., 23., 11., 28., 28., 24., 25., 18., 20., 28., 17., 23.,  8.,\n",
       "        28., 27., 26., 27.,  7., 34., 10., 26., 28., 26., 19., 47., 30.,\n",
       "        29., 28., 27., 31., 24., 24., 31., 14., 39., 41., 21., 18., 29.,\n",
       "        29., 34., 24., 23., 26., 21., 19., 17., 25., 25., 24., 15.,  2.,\n",
       "        24., 24., 23., 31., 26., 18., 24., 24., 26., 25., 10., 18., 16.,\n",
       "        23., 24., 31.,  6., 35., 26., 38., 24., 15., 14., 30., 26., 21.,\n",
       "        29., 29., 20., 24., 23., 18., 26., 28., 23., 15., 13.,  8., 26.,\n",
       "        19., 19., 24., 16., 41., 23., 27., 41., 28., 24., 24., 16., 36.,\n",
       "        11., 31., 28., 15., 17., 37., 13., 15., 30.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 329us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.461715597855417"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 392.4264\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 148.6321\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 85.9988\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 74.7026\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 68.9543\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 64.5362\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 61.5061\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 58.5681\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 57.4766\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 55.6983\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 53.3653\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 17.25 - 0s 113us/step - loss: 50.4466\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.7711\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 48.2368\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.1327\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 46.9988\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 46.0610\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.4775\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.1408\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 43.0047\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 42.1860\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 42.4082\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 41.3631\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.4264\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.0320\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.3190\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.2171\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 39.1082\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.9670\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 37.9418\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 39.6050\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.6340\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 38.4489\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.9993\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.9337\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.0594\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.9051\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.9974\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.8104\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.5778\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.4765\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.1283\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.4843\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.5378\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.2192\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.7207\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.9348\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.0434\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.7406\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.4332\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.7963\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.7012\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.0107\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.8784\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.9748\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9096\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 34.3998\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.7275\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 31.8029\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.7838\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.9393\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7289\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.3897\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.6072\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 33.5037\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 31.3954\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.8181\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.4383\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1528\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.1972\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6888\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5519\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5002\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.7178\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9431\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.5377\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1266\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2366\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6933\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.9876\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0256\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.6021\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6248\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6229\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.0376\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.1482\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.4991\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.7138\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.4104\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.3109\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9459\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6984\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7788\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2967\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.3407\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 85us/step - loss: 29.6812\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.9978\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 30.6592\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.9623\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x11d84780>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22., 33., 37., 10., 21., 32., 16., 14., 23., 21., 18.,  4., 34.,\n",
       "        19., 14., 25., 31., 25., 21., 21., 22., 21., 37., 24., 23., -0.,\n",
       "        19., 14., 12., 14., 27., 22., 25., 20., 28., 37., 16., 25., 18.,\n",
       "        32., 19.,  6., 27., 26., 23., 23., 15., 17., 25., 15., 22.,  2.,\n",
       "        25., 25., 23., 25.,  6., 31., 10., 23., 26., 23., 18., 45., 28.,\n",
       "        27., 27., 26., 29., 20., 20., 28., 15., 36., 38., 18., 20., 29.,\n",
       "        28., 31., 21., 21., 23., 18., 18., 16., 23., 23., 24., 12., -1.,\n",
       "        22., 21., 19., 31., 23., 17., 21., 22., 23., 21.,  8., 20., 14.,\n",
       "        20., 21., 29.,  4., 32., 22., 34., 21., 13.,  9., 28., 23., 18.,\n",
       "        27., 26., 18., 20., 22., 16., 23., 25., 23., 11., 10.,  4., 24.,\n",
       "        21., 17., 21., 15., 38., 24., 25., 37., 27., 23., 23., 15., 32.,\n",
       "         8., 29., 24., 11., 13., 36., 12., 11., 28.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 395us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.93973139712685"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.218296</td>\n",
       "      <td>0.336704</td>\n",
       "      <td>-0.426186</td>\n",
       "      <td>-0.886752</td>\n",
       "      <td>0.380047</td>\n",
       "      <td>-1.187510</td>\n",
       "      <td>-0.391259</td>\n",
       "      <td>0.125752</td>\n",
       "      <td>-0.172811</td>\n",
       "      <td>-1.267331</td>\n",
       "      <td>-1.771462</td>\n",
       "      <td>-0.501306</td>\n",
       "      <td>0.296134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410900</td>\n",
       "      <td>-1.292493</td>\n",
       "      <td>1.055464</td>\n",
       "      <td>-1.463581</td>\n",
       "      <td>-0.607597</td>\n",
       "      <td>-0.256340</td>\n",
       "      <td>0.067925</td>\n",
       "      <td>1.176856</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>-0.220818</td>\n",
       "      <td>-0.498881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.551091</td>\n",
       "      <td>0.086810</td>\n",
       "      <td>-1.064214</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>-0.056779</td>\n",
       "      <td>-0.404564</td>\n",
       "      <td>-0.352776</td>\n",
       "      <td>-0.668523</td>\n",
       "      <td>1.635779</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>-0.914374</td>\n",
       "      <td>-0.289210</td>\n",
       "      <td>0.679937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>1.007146</td>\n",
       "      <td>-2.389351</td>\n",
       "      <td>0.140114</td>\n",
       "      <td>-0.508026</td>\n",
       "      <td>0.103962</td>\n",
       "      <td>0.610198</td>\n",
       "      <td>-0.978994</td>\n",
       "      <td>-1.487230</td>\n",
       "      <td>-1.857298</td>\n",
       "      <td>-0.362586</td>\n",
       "      <td>0.584306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115420</td>\n",
       "      <td>-0.424497</td>\n",
       "      <td>-0.599070</td>\n",
       "      <td>-0.126995</td>\n",
       "      <td>-0.378454</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>-0.435759</td>\n",
       "      <td>-0.986912</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>-1.001963</td>\n",
       "      <td>0.307408</td>\n",
       "      <td>-0.171837</td>\n",
       "      <td>0.416459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.568687</td>\n",
       "      <td>-0.017722</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-0.158364</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.930286</td>\n",
       "      <td>-0.793835</td>\n",
       "      <td>0.195159</td>\n",
       "      <td>-0.394252</td>\n",
       "      <td>0.754895</td>\n",
       "      <td>-0.054449</td>\n",
       "      <td>3.939962</td>\n",
       "      <td>-0.256343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.447170</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>2.683609</td>\n",
       "      <td>1.917981</td>\n",
       "      <td>-0.119569</td>\n",
       "      <td>0.329389</td>\n",
       "      <td>-0.053554</td>\n",
       "      <td>-0.408277</td>\n",
       "      <td>3.289767</td>\n",
       "      <td>0.921860</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.310273</td>\n",
       "      <td>1.934371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.967308</td>\n",
       "      <td>0.106104</td>\n",
       "      <td>1.077655</td>\n",
       "      <td>-1.022205</td>\n",
       "      <td>0.391836</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>-0.112093</td>\n",
       "      <td>0.631071</td>\n",
       "      <td>-0.554251</td>\n",
       "      <td>1.049112</td>\n",
       "      <td>0.595754</td>\n",
       "      <td>-0.264482</td>\n",
       "      <td>0.098367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.446440</td>\n",
       "      <td>-1.186458</td>\n",
       "      <td>-0.223272</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>-0.011630</td>\n",
       "      <td>-0.288014</td>\n",
       "      <td>-0.546646</td>\n",
       "      <td>0.685738</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>-0.260171</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.977767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.743204</td>\n",
       "      <td>-0.016091</td>\n",
       "      <td>-1.406325</td>\n",
       "      <td>0.539970</td>\n",
       "      <td>0.063506</td>\n",
       "      <td>0.855115</td>\n",
       "      <td>-0.100882</td>\n",
       "      <td>1.019661</td>\n",
       "      <td>-1.045355</td>\n",
       "      <td>0.728018</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>3.768397</td>\n",
       "      <td>-0.865074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>-1.128775</td>\n",
       "      <td>0.598142</td>\n",
       "      <td>-0.700726</td>\n",
       "      <td>-0.792189</td>\n",
       "      <td>2.491377</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>-1.475142</td>\n",
       "      <td>0.964716</td>\n",
       "      <td>0.580170</td>\n",
       "      <td>-0.526890</td>\n",
       "      <td>3.695478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.109496</td>\n",
       "      <td>-0.463290</td>\n",
       "      <td>3.319455</td>\n",
       "      <td>2.483666</td>\n",
       "      <td>-0.436228</td>\n",
       "      <td>0.296471</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>-1.359378</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>-1.069896</td>\n",
       "      <td>-0.435476</td>\n",
       "      <td>0.335398</td>\n",
       "      <td>0.233901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.563461</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.916949</td>\n",
       "      <td>0.047773</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.193161</td>\n",
       "      <td>-0.672598</td>\n",
       "      <td>-0.635800</td>\n",
       "      <td>1.411689</td>\n",
       "      <td>-0.034218</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.644681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.227955</td>\n",
       "      <td>0.397238</td>\n",
       "      <td>-1.018147</td>\n",
       "      <td>-0.282160</td>\n",
       "      <td>0.326452</td>\n",
       "      <td>2.019800</td>\n",
       "      <td>2.784529</td>\n",
       "      <td>3.627855</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>-0.305158</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>-0.827660</td>\n",
       "      <td>-0.294085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.184482</td>\n",
       "      <td>0.636922</td>\n",
       "      <td>-1.831814</td>\n",
       "      <td>0.768341</td>\n",
       "      <td>0.404875</td>\n",
       "      <td>3.168186</td>\n",
       "      <td>1.429387</td>\n",
       "      <td>3.382434</td>\n",
       "      <td>0.488574</td>\n",
       "      <td>-0.065362</td>\n",
       "      <td>-0.991493</td>\n",
       "      <td>-0.928332</td>\n",
       "      <td>-0.957187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.770244</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.887590</td>\n",
       "      <td>-0.119189</td>\n",
       "      <td>-0.104687</td>\n",
       "      <td>-0.106483</td>\n",
       "      <td>0.990349</td>\n",
       "      <td>-0.165131</td>\n",
       "      <td>1.597335</td>\n",
       "      <td>-1.654309</td>\n",
       "      <td>0.477349</td>\n",
       "      <td>-0.238305</td>\n",
       "      <td>0.806332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.049209</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>-0.191747</td>\n",
       "      <td>0.451898</td>\n",
       "      <td>0.354904</td>\n",
       "      <td>0.686849</td>\n",
       "      <td>-0.510539</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>0.264772</td>\n",
       "      <td>-0.954217</td>\n",
       "      <td>0.657336</td>\n",
       "      <td>4.091099</td>\n",
       "      <td>-0.468007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.686215</td>\n",
       "      <td>-0.075888</td>\n",
       "      <td>1.192591</td>\n",
       "      <td>1.485459</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>-0.011337</td>\n",
       "      <td>-0.086963</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>1.270550</td>\n",
       "      <td>0.603574</td>\n",
       "      <td>-0.282384</td>\n",
       "      <td>-0.934310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.784367</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>-0.780065</td>\n",
       "      <td>-0.207366</td>\n",
       "      <td>-0.016780</td>\n",
       "      <td>-0.963678</td>\n",
       "      <td>-0.534382</td>\n",
       "      <td>-1.264696</td>\n",
       "      <td>-0.251943</td>\n",
       "      <td>-0.784355</td>\n",
       "      <td>0.594379</td>\n",
       "      <td>-0.225215</td>\n",
       "      <td>-0.516801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.717640</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.989287</td>\n",
       "      <td>-2.451317</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.077713</td>\n",
       "      <td>0.384208</td>\n",
       "      <td>0.270853</td>\n",
       "      <td>0.533549</td>\n",
       "      <td>-0.278017</td>\n",
       "      <td>-0.256943</td>\n",
       "      <td>-0.159516</td>\n",
       "      <td>1.272878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.624073</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.160763</td>\n",
       "      <td>0.031376</td>\n",
       "      <td>-0.234554</td>\n",
       "      <td>-0.241636</td>\n",
       "      <td>0.243423</td>\n",
       "      <td>-0.493480</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.280933</td>\n",
       "      <td>-0.702675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.715731</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.572144</td>\n",
       "      <td>-1.919670</td>\n",
       "      <td>0.174060</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>0.208287</td>\n",
       "      <td>0.176057</td>\n",
       "      <td>0.658007</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>-0.017581</td>\n",
       "      <td>-0.200698</td>\n",
       "      <td>0.979237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.421298</td>\n",
       "      <td>-1.406029</td>\n",
       "      <td>-0.310320</td>\n",
       "      <td>0.269410</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.218211</td>\n",
       "      <td>-0.958624</td>\n",
       "      <td>0.714248</td>\n",
       "      <td>-0.279995</td>\n",
       "      <td>-0.538967</td>\n",
       "      <td>-1.754797</td>\n",
       "      <td>-0.429055</td>\n",
       "      <td>-0.052801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.115556</td>\n",
       "      <td>-0.540635</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>-0.074706</td>\n",
       "      <td>-0.683186</td>\n",
       "      <td>-0.629395</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>-1.539723</td>\n",
       "      <td>-0.511106</td>\n",
       "      <td>-0.225811</td>\n",
       "      <td>0.887479</td>\n",
       "      <td>-0.116359</td>\n",
       "      <td>-0.620534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.810639</td>\n",
       "      <td>0.069947</td>\n",
       "      <td>-0.996857</td>\n",
       "      <td>1.638662</td>\n",
       "      <td>0.107503</td>\n",
       "      <td>-0.951199</td>\n",
       "      <td>-0.879962</td>\n",
       "      <td>-0.084254</td>\n",
       "      <td>-2.660340</td>\n",
       "      <td>-0.417255</td>\n",
       "      <td>-0.456178</td>\n",
       "      <td>-0.660758</td>\n",
       "      <td>0.809331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.105027</td>\n",
       "      <td>-0.365970</td>\n",
       "      <td>1.965839</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>-0.438936</td>\n",
       "      <td>-0.648371</td>\n",
       "      <td>0.423267</td>\n",
       "      <td>-1.329676</td>\n",
       "      <td>-1.265713</td>\n",
       "      <td>0.452782</td>\n",
       "      <td>-0.624106</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>-0.248861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.572685</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>2.236526</td>\n",
       "      <td>2.417969</td>\n",
       "      <td>-0.146365</td>\n",
       "      <td>0.462122</td>\n",
       "      <td>0.541046</td>\n",
       "      <td>-0.676499</td>\n",
       "      <td>0.307313</td>\n",
       "      <td>1.529051</td>\n",
       "      <td>0.819056</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>-0.124282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.492915</td>\n",
       "      <td>-0.203387</td>\n",
       "      <td>1.777558</td>\n",
       "      <td>-1.572743</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>-0.118156</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.826970</td>\n",
       "      <td>2.020085</td>\n",
       "      <td>-3.937981</td>\n",
       "      <td>-0.269015</td>\n",
       "      <td>1.479730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.452100</td>\n",
       "      <td>-1.043974</td>\n",
       "      <td>0.526998</td>\n",
       "      <td>-0.762193</td>\n",
       "      <td>0.790775</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>-0.189807</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>-0.103903</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>-0.112098</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>-0.970029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.751558</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>0.426210</td>\n",
       "      <td>-1.772618</td>\n",
       "      <td>0.183135</td>\n",
       "      <td>0.663843</td>\n",
       "      <td>0.573432</td>\n",
       "      <td>0.576692</td>\n",
       "      <td>-0.106322</td>\n",
       "      <td>-0.719618</td>\n",
       "      <td>-0.340360</td>\n",
       "      <td>-0.287602</td>\n",
       "      <td>0.048091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.341859</td>\n",
       "      <td>1.772573</td>\n",
       "      <td>-1.265405</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>-0.069995</td>\n",
       "      <td>0.509438</td>\n",
       "      <td>-1.132676</td>\n",
       "      <td>-0.942075</td>\n",
       "      <td>1.348960</td>\n",
       "      <td>-0.156008</td>\n",
       "      <td>-0.450447</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>0.098929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.826799</td>\n",
       "      <td>0.112487</td>\n",
       "      <td>0.247452</td>\n",
       "      <td>0.055284</td>\n",
       "      <td>0.105849</td>\n",
       "      <td>-1.312153</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>0.206861</td>\n",
       "      <td>-2.599742</td>\n",
       "      <td>-0.679201</td>\n",
       "      <td>-0.256533</td>\n",
       "      <td>-0.516969</td>\n",
       "      <td>0.534755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.641654</td>\n",
       "      <td>-0.038538</td>\n",
       "      <td>-0.551487</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.734961</td>\n",
       "      <td>-0.838139</td>\n",
       "      <td>-0.706664</td>\n",
       "      <td>-1.151996</td>\n",
       "      <td>-0.788001</td>\n",
       "      <td>1.688322</td>\n",
       "      <td>-0.269644</td>\n",
       "      <td>-0.713522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.079148</td>\n",
       "      <td>-1.116960</td>\n",
       "      <td>0.596164</td>\n",
       "      <td>-0.749896</td>\n",
       "      <td>-0.961395</td>\n",
       "      <td>2.613610</td>\n",
       "      <td>0.045463</td>\n",
       "      <td>-1.388278</td>\n",
       "      <td>1.004437</td>\n",
       "      <td>1.593126</td>\n",
       "      <td>-0.459578</td>\n",
       "      <td>-1.373151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-0.813866</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>1.064336</td>\n",
       "      <td>-0.424341</td>\n",
       "      <td>0.102291</td>\n",
       "      <td>0.844122</td>\n",
       "      <td>1.986576</td>\n",
       "      <td>1.953437</td>\n",
       "      <td>0.265062</td>\n",
       "      <td>-1.395970</td>\n",
       "      <td>0.522529</td>\n",
       "      <td>-0.342571</td>\n",
       "      <td>-0.815108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-0.921492</td>\n",
       "      <td>0.112342</td>\n",
       "      <td>-0.365070</td>\n",
       "      <td>-0.821385</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>-0.452206</td>\n",
       "      <td>-0.469554</td>\n",
       "      <td>-0.391193</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>-0.702808</td>\n",
       "      <td>0.813267</td>\n",
       "      <td>-0.251879</td>\n",
       "      <td>-0.768778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.991131</td>\n",
       "      <td>3.384534</td>\n",
       "      <td>0.421641</td>\n",
       "      <td>-0.237522</td>\n",
       "      <td>-1.409536</td>\n",
       "      <td>-0.691933</td>\n",
       "      <td>-0.216972</td>\n",
       "      <td>0.564823</td>\n",
       "      <td>0.417845</td>\n",
       "      <td>0.566093</td>\n",
       "      <td>0.646313</td>\n",
       "      <td>-0.044244</td>\n",
       "      <td>-0.164187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.569081</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>-1.287219</td>\n",
       "      <td>0.513402</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>0.189279</td>\n",
       "      <td>-0.924604</td>\n",
       "      <td>-0.714949</td>\n",
       "      <td>1.490871</td>\n",
       "      <td>0.395190</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.270665</td>\n",
       "      <td>0.437375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.423465</td>\n",
       "      <td>-1.404566</td>\n",
       "      <td>-0.327444</td>\n",
       "      <td>0.281870</td>\n",
       "      <td>1.136365</td>\n",
       "      <td>1.723241</td>\n",
       "      <td>-1.725096</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>-0.753861</td>\n",
       "      <td>-0.512377</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>-0.252973</td>\n",
       "      <td>0.189492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.356470</td>\n",
       "      <td>1.123745</td>\n",
       "      <td>-0.933219</td>\n",
       "      <td>0.525810</td>\n",
       "      <td>-0.889419</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.884598</td>\n",
       "      <td>-0.494448</td>\n",
       "      <td>1.574206</td>\n",
       "      <td>-0.295988</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>-0.094441</td>\n",
       "      <td>0.154127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.824148</td>\n",
       "      <td>0.085650</td>\n",
       "      <td>-0.076755</td>\n",
       "      <td>0.455379</td>\n",
       "      <td>0.246723</td>\n",
       "      <td>-0.323226</td>\n",
       "      <td>-0.679215</td>\n",
       "      <td>0.111718</td>\n",
       "      <td>-2.984972</td>\n",
       "      <td>-1.232753</td>\n",
       "      <td>2.838079</td>\n",
       "      <td>-0.386188</td>\n",
       "      <td>1.017576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-0.127880</td>\n",
       "      <td>-0.422532</td>\n",
       "      <td>0.152169</td>\n",
       "      <td>-1.090901</td>\n",
       "      <td>-0.301478</td>\n",
       "      <td>0.352250</td>\n",
       "      <td>-0.072848</td>\n",
       "      <td>-0.811853</td>\n",
       "      <td>-0.211932</td>\n",
       "      <td>-1.731636</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>-0.048400</td>\n",
       "      <td>0.811001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.146226</td>\n",
       "      <td>-0.384283</td>\n",
       "      <td>-0.986603</td>\n",
       "      <td>0.347412</td>\n",
       "      <td>-0.335649</td>\n",
       "      <td>0.549421</td>\n",
       "      <td>-1.125597</td>\n",
       "      <td>-1.430948</td>\n",
       "      <td>0.742985</td>\n",
       "      <td>-1.589639</td>\n",
       "      <td>0.149407</td>\n",
       "      <td>-0.093774</td>\n",
       "      <td>-0.686834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.472153</td>\n",
       "      <td>-0.972228</td>\n",
       "      <td>-0.133663</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>0.740923</td>\n",
       "      <td>0.531293</td>\n",
       "      <td>-0.840607</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>-0.384282</td>\n",
       "      <td>-0.656741</td>\n",
       "      <td>-1.713876</td>\n",
       "      <td>-0.325242</td>\n",
       "      <td>-0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.456135</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>2.599987</td>\n",
       "      <td>2.013634</td>\n",
       "      <td>-0.074048</td>\n",
       "      <td>0.699033</td>\n",
       "      <td>-0.367732</td>\n",
       "      <td>-0.427186</td>\n",
       "      <td>3.169238</td>\n",
       "      <td>0.951461</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>1.829259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.199952</td>\n",
       "      <td>1.533377</td>\n",
       "      <td>-0.834032</td>\n",
       "      <td>0.360015</td>\n",
       "      <td>-0.631507</td>\n",
       "      <td>-0.470706</td>\n",
       "      <td>2.482422</td>\n",
       "      <td>-0.134929</td>\n",
       "      <td>-1.467272</td>\n",
       "      <td>1.261561</td>\n",
       "      <td>1.124268</td>\n",
       "      <td>-0.344816</td>\n",
       "      <td>-1.194008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.133477</td>\n",
       "      <td>-0.373511</td>\n",
       "      <td>0.864971</td>\n",
       "      <td>-2.012486</td>\n",
       "      <td>-0.053010</td>\n",
       "      <td>1.852188</td>\n",
       "      <td>-0.642114</td>\n",
       "      <td>-0.699432</td>\n",
       "      <td>-0.825240</td>\n",
       "      <td>-2.137400</td>\n",
       "      <td>0.036622</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>1.373298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>-0.674742</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>-0.674479</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>-0.423200</td>\n",
       "      <td>-1.656176</td>\n",
       "      <td>-0.758245</td>\n",
       "      <td>-0.422877</td>\n",
       "      <td>0.556423</td>\n",
       "      <td>-0.095854</td>\n",
       "      <td>-0.889029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.035970</td>\n",
       "      <td>-0.467859</td>\n",
       "      <td>-1.224252</td>\n",
       "      <td>0.653701</td>\n",
       "      <td>0.116760</td>\n",
       "      <td>2.371741</td>\n",
       "      <td>0.350227</td>\n",
       "      <td>-0.105625</td>\n",
       "      <td>-2.684684</td>\n",
       "      <td>0.362394</td>\n",
       "      <td>0.224631</td>\n",
       "      <td>-0.483569</td>\n",
       "      <td>3.346229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>-0.231514</td>\n",
       "      <td>-0.408073</td>\n",
       "      <td>-0.620177</td>\n",
       "      <td>0.326987</td>\n",
       "      <td>-0.316636</td>\n",
       "      <td>-1.566828</td>\n",
       "      <td>-0.924376</td>\n",
       "      <td>-0.802616</td>\n",
       "      <td>0.570587</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>-0.615597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.734757</td>\n",
       "      <td>-0.019290</td>\n",
       "      <td>-1.589464</td>\n",
       "      <td>0.786915</td>\n",
       "      <td>0.188284</td>\n",
       "      <td>1.379813</td>\n",
       "      <td>-1.282396</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>-0.042861</td>\n",
       "      <td>0.826787</td>\n",
       "      <td>0.598042</td>\n",
       "      <td>3.973727</td>\n",
       "      <td>-1.264901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-1.062561</td>\n",
       "      <td>0.175754</td>\n",
       "      <td>-0.150195</td>\n",
       "      <td>1.450560</td>\n",
       "      <td>0.300127</td>\n",
       "      <td>-0.997197</td>\n",
       "      <td>-1.044866</td>\n",
       "      <td>1.169793</td>\n",
       "      <td>0.471431</td>\n",
       "      <td>-1.895855</td>\n",
       "      <td>0.366942</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.593682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.077830</td>\n",
       "      <td>-0.320047</td>\n",
       "      <td>0.419044</td>\n",
       "      <td>-1.408831</td>\n",
       "      <td>-0.406938</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>-0.651299</td>\n",
       "      <td>-0.127834</td>\n",
       "      <td>-0.059416</td>\n",
       "      <td>-0.119636</td>\n",
       "      <td>-0.087696</td>\n",
       "      <td>-1.513201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.424047</td>\n",
       "      <td>-1.335482</td>\n",
       "      <td>-0.047273</td>\n",
       "      <td>-0.052808</td>\n",
       "      <td>-0.885869</td>\n",
       "      <td>-0.821740</td>\n",
       "      <td>-0.321385</td>\n",
       "      <td>0.994797</td>\n",
       "      <td>0.244490</td>\n",
       "      <td>0.392686</td>\n",
       "      <td>-0.244980</td>\n",
       "      <td>4.024945</td>\n",
       "      <td>2.431384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1.426656</td>\n",
       "      <td>-1.357723</td>\n",
       "      <td>-0.304057</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>-0.286396</td>\n",
       "      <td>0.040887</td>\n",
       "      <td>-0.919443</td>\n",
       "      <td>0.784602</td>\n",
       "      <td>-0.134163</td>\n",
       "      <td>-0.228937</td>\n",
       "      <td>0.448984</td>\n",
       "      <td>-0.348608</td>\n",
       "      <td>0.212757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.421858</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>-0.205606</td>\n",
       "      <td>0.990012</td>\n",
       "      <td>-0.147521</td>\n",
       "      <td>-0.228645</td>\n",
       "      <td>-1.006426</td>\n",
       "      <td>-0.215783</td>\n",
       "      <td>1.153468</td>\n",
       "      <td>2.968010</td>\n",
       "      <td>1.083063</td>\n",
       "      <td>-0.241957</td>\n",
       "      <td>-0.681613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.791279</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.351439</td>\n",
       "      <td>1.390501</td>\n",
       "      <td>-0.051356</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>1.300206</td>\n",
       "      <td>1.631244</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>-0.233673</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>-0.520131</td>\n",
       "      <td>-1.751054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1.525218</td>\n",
       "      <td>-0.541349</td>\n",
       "      <td>0.094171</td>\n",
       "      <td>-0.153951</td>\n",
       "      <td>4.182298</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>-0.510013</td>\n",
       "      <td>-0.382875</td>\n",
       "      <td>-0.328020</td>\n",
       "      <td>-0.053195</td>\n",
       "      <td>0.050772</td>\n",
       "      <td>0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.400854</td>\n",
       "      <td>-0.247820</td>\n",
       "      <td>1.234477</td>\n",
       "      <td>-1.592875</td>\n",
       "      <td>-0.061667</td>\n",
       "      <td>0.427942</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>-0.932233</td>\n",
       "      <td>0.208401</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0.460779</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>-0.304442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.944012</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>-0.494481</td>\n",
       "      <td>-0.667725</td>\n",
       "      <td>0.048722</td>\n",
       "      <td>-1.041966</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>-0.188151</td>\n",
       "      <td>0.285467</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>-0.951077</td>\n",
       "      <td>-0.418927</td>\n",
       "      <td>-0.168896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -1.218296  0.336704 -0.426186 -0.886752  0.380047 -1.187510 -0.391259   \n",
       "1    1.410900 -1.292493  1.055464 -1.463581 -0.607597 -0.256340  0.067925   \n",
       "2   -0.551091  0.086810 -1.064214  0.249742 -0.056779 -0.404564 -0.352776   \n",
       "3   -0.580706  0.126584  1.007146 -2.389351  0.140114 -0.508026  0.103962   \n",
       "4   -0.115420 -0.424497 -0.599070 -0.126995 -0.378454  0.132858 -0.435759   \n",
       "5   -0.568687 -0.017722 -0.741355 -0.158364  0.000028 -0.930286 -0.793835   \n",
       "6   -0.447170  0.045592  2.683609  1.917981 -0.119569  0.329389 -0.053554   \n",
       "7   -0.967308  0.106104  1.077655 -1.022205  0.391836  0.588200 -0.112093   \n",
       "8    1.446440 -1.186458 -0.223272  0.184505 -0.011630 -0.288014 -0.546646   \n",
       "9   -0.743204 -0.016091 -1.406325  0.539970  0.063506  0.855115 -0.100882   \n",
       "10   0.011236 -0.053868 -1.128775  0.598142 -0.700726 -0.792189  2.491377   \n",
       "11  -0.109496 -0.463290  3.319455  2.483666 -0.436228  0.296471  0.442018   \n",
       "12  -0.563461  0.004313 -0.916949  0.047773  0.015107  0.193161 -0.672598   \n",
       "13  -1.227955  0.397238 -1.018147 -0.282160  0.326452  2.019800  2.784529   \n",
       "14  -1.184482  0.636922 -1.831814  0.768341  0.404875  3.168186  1.429387   \n",
       "15  -0.770244 -0.004625 -0.887590 -0.119189 -0.104687 -0.106483  0.990349   \n",
       "16  -1.049209  0.245458 -0.191747  0.451898  0.354904  0.686849 -0.510539   \n",
       "17  -0.686215 -0.075888  1.192591  1.485459  0.039956 -0.011337 -0.086963   \n",
       "18  -0.784367  0.049567 -0.780065 -0.207366 -0.016780 -0.963678 -0.534382   \n",
       "19  -0.717640 -0.008363  0.989287 -2.451317  0.204783  0.077713  0.384208   \n",
       "20  -0.624073  0.068307  0.862734  0.160763  0.031376 -0.234554 -0.241636   \n",
       "21  -0.715731 -0.050616  0.572144 -1.919670  0.174060 -0.069824  0.208287   \n",
       "22   1.421298 -1.406029 -0.310320  0.269410  0.025199  0.218211 -0.958624   \n",
       "23   0.115556 -0.540635 -0.533333 -0.074706 -0.683186 -0.629395  0.157352   \n",
       "24  -0.810639  0.069947 -0.996857  1.638662  0.107503 -0.951199 -0.879962   \n",
       "25  -0.105027 -0.365970  1.965839  0.244274 -0.438936 -0.648371  0.423267   \n",
       "26  -0.572685 -0.102770  2.236526  2.417969 -0.146365  0.462122  0.541046   \n",
       "27  -0.492915 -0.203387  1.777558 -1.572743  0.071259 -0.118156  0.251742   \n",
       "28   1.452100 -1.043974  0.526998 -0.762193  0.790775  0.227564 -0.189807   \n",
       "29  -0.751558  0.126659  0.426210 -1.772618  0.183135  0.663843  0.573432   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324 -0.341859  1.772573 -1.265405  0.645878 -0.069995  0.509438 -1.132676   \n",
       "325 -0.826799  0.112487  0.247452  0.055284  0.105849 -1.312153  0.193734   \n",
       "326 -0.641654 -0.038538 -0.551487 -0.429577 -0.006266 -0.734961 -0.838139   \n",
       "327  0.027163  0.079148 -1.116960  0.596164 -0.749896 -0.961395  2.613610   \n",
       "328 -0.813866  0.015304  1.064336 -0.424341  0.102291  0.844122  1.986576   \n",
       "329 -0.921492  0.112342 -0.365070 -0.821385  0.201869 -0.452206 -0.469554   \n",
       "330  1.991131  3.384534  0.421641 -0.237522 -1.409536 -0.691933 -0.216972   \n",
       "331 -0.569081 -0.093427 -1.287219  0.513402 -0.005301  0.189279 -0.924604   \n",
       "332  1.423465 -1.404566 -0.327444  0.281870  1.136365  1.723241 -1.725096   \n",
       "333  0.356470  1.123745 -0.933219  0.525810 -0.889419  0.999575  1.884598   \n",
       "334 -0.824148  0.085650 -0.076755  0.455379  0.246723 -0.323226 -0.679215   \n",
       "335 -0.127880 -0.422532  0.152169 -1.090901 -0.301478  0.352250 -0.072848   \n",
       "336 -0.146226 -0.384283 -0.986603  0.347412 -0.335649  0.549421 -1.125597   \n",
       "337  1.472153 -0.972228 -0.133663  0.082710  0.740923  0.531293 -0.840607   \n",
       "338 -0.456135 -0.040692  2.599987  2.013634 -0.074048  0.699033 -0.367732   \n",
       "339  0.199952  1.533377 -0.834032  0.360015 -0.631507 -0.470706  2.482422   \n",
       "340 -0.133477 -0.373511  0.864971 -2.012486 -0.053010  1.852188 -0.642114   \n",
       "341  0.195446  0.093291 -0.674742  0.154730 -0.674479  0.050682 -0.423200   \n",
       "342 -0.035970 -0.467859 -1.224252  0.653701  0.116760  2.371741  0.350227   \n",
       "343  0.197936  0.174806 -0.231514 -0.408073 -0.620177  0.326987 -0.316636   \n",
       "344 -0.734757 -0.019290 -1.589464  0.786915  0.188284  1.379813 -1.282396   \n",
       "345 -1.062561  0.175754 -0.150195  1.450560  0.300127 -0.997197 -1.044866   \n",
       "346 -0.077830 -0.320047  0.419044 -1.408831 -0.406938  0.525774  0.850306   \n",
       "347  1.424047 -1.335482 -0.047273 -0.052808 -0.885869 -0.821740 -0.321385   \n",
       "348  1.426656 -1.357723 -0.304057  0.266019 -0.286396  0.040887 -0.919443   \n",
       "349 -0.421858  0.103611 -0.205606  0.990012 -0.147521 -0.228645 -1.006426   \n",
       "350 -0.791279  0.004316 -0.351439  1.390501 -0.051356  0.442421  1.300206   \n",
       "351  1.525218 -0.541349  0.094171 -0.153951  4.182298  0.944707  0.100574   \n",
       "352 -0.400854 -0.247820  1.234477 -1.592875 -0.061667  0.427942  0.017642   \n",
       "353 -0.944012  0.158801 -0.494481 -0.667725  0.048722 -1.041966  0.612755   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.125752 -0.172811 -1.267331 -1.771462 -0.501306  0.296134  \n",
       "1    1.176856 -0.012022  0.035788  0.513550 -0.220818 -0.498881  \n",
       "2   -0.668523  1.635779  0.115754 -0.914374 -0.289210  0.679937  \n",
       "3    0.610198 -0.978994 -1.487230 -1.857298 -0.362586  0.584306  \n",
       "4   -0.986912 -0.006150 -1.001963  0.307408 -0.171837  0.416459  \n",
       "5    0.195159 -0.394252  0.754895 -0.054449  3.939962 -0.256343  \n",
       "6   -0.408277  3.289767  0.921860  0.607383  0.310273  1.934371  \n",
       "7    0.631071 -0.554251  1.049112  0.595754 -0.264482  0.098367  \n",
       "8    0.685738  0.060267  0.240304 -0.260171 -0.345022 -0.977767  \n",
       "9    1.019661 -1.045355  0.728018  0.269853  3.768397 -0.865074  \n",
       "10   0.052045 -1.475142  0.964716  0.580170 -0.526890  3.695478  \n",
       "11  -1.359378  0.125921 -1.069896 -0.435476  0.335398  0.233901  \n",
       "12  -0.635800  1.411689 -0.034218  0.026586 -0.222119  0.644681  \n",
       "13   3.627855  0.834177 -0.305158  0.030605 -0.827660 -0.294085  \n",
       "14   3.382434  0.488574 -0.065362 -0.991493 -0.928332 -0.957187  \n",
       "15  -0.165131  1.597335 -1.654309  0.477349 -0.238305  0.806332  \n",
       "16   0.647583  0.264772 -0.954217  0.657336  4.091099 -0.468007  \n",
       "17   0.760112 -0.009755  1.270550  0.603574 -0.282384 -0.934310  \n",
       "18  -1.264696 -0.251943 -0.784355  0.594379 -0.225215 -0.516801  \n",
       "19   0.270853  0.533549 -0.278017 -0.256943 -0.159516  1.272878  \n",
       "20   0.243423 -0.493480  0.820438 -0.000126 -0.280933 -0.702675  \n",
       "21   0.176057  0.658007  0.088739 -0.017581 -0.200698  0.979237  \n",
       "22   0.714248 -0.279995 -0.538967 -1.754797 -0.429055 -0.052801  \n",
       "23  -1.539723 -0.511106 -0.225811  0.887479 -0.116359 -0.620534  \n",
       "24  -0.084254 -2.660340 -0.417255 -0.456178 -0.660758  0.809331  \n",
       "25  -1.329676 -1.265713  0.452782 -0.624106  0.027833 -0.248861  \n",
       "26  -0.676499  0.307313  1.529051  0.819056  0.106207 -0.124282  \n",
       "27   0.267120  0.826970  2.020085 -3.937981 -0.269015  1.479730  \n",
       "28   0.613298 -0.103903  0.294610 -0.112098 -0.186023 -0.970029  \n",
       "29   0.576692 -0.106322 -0.719618 -0.340360 -0.287602  0.048091  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324 -0.942075  1.348960 -0.156008 -0.450447 -0.167151  0.098929  \n",
       "325  0.206861 -2.599742 -0.679201 -0.256533 -0.516969  0.534755  \n",
       "326 -0.706664 -1.151996 -0.788001  1.688322 -0.269644 -0.713522  \n",
       "327  0.045463 -1.388278  1.004437  1.593126 -0.459578 -1.373151  \n",
       "328  1.953437  0.265062 -1.395970  0.522529 -0.342571 -0.815108  \n",
       "329 -0.391193  0.071180 -0.702808  0.813267 -0.251879 -0.768778  \n",
       "330  0.564823  0.417845  0.566093  0.646313 -0.044244 -0.164187  \n",
       "331 -0.714949  1.490871  0.395190  0.041914 -0.270665  0.437375  \n",
       "332  0.398486 -0.753861 -0.512377  0.023830 -0.252973  0.189492  \n",
       "333 -0.494448  1.574206 -0.295988  0.026064 -0.094441  0.154127  \n",
       "334  0.111718 -2.984972 -1.232753  2.838079 -0.386188  1.017576  \n",
       "335 -0.811853 -0.211932 -1.731636  0.992609 -0.048400  0.811001  \n",
       "336 -1.430948  0.742985 -1.589639  0.149407 -0.093774 -0.686834  \n",
       "337  0.493511 -0.384282 -0.656741 -1.713876 -0.325242 -0.006139  \n",
       "338 -0.427186  3.169238  0.951461  0.845506  0.314297  1.829259  \n",
       "339 -0.134929 -1.467272  1.261561  1.124268 -0.344816 -1.194008  \n",
       "340 -0.699432 -0.825240 -2.137400  0.036622  0.021078  1.373298  \n",
       "341 -1.656176 -0.758245 -0.422877  0.556423 -0.095854 -0.889029  \n",
       "342 -0.105625 -2.684684  0.362394  0.224631 -0.483569  3.346229  \n",
       "343 -1.566828 -0.924376 -0.802616  0.570587 -0.034229 -0.615597  \n",
       "344  0.086254 -0.042861  0.826787  0.598042  3.973727 -1.264901  \n",
       "345  1.169793  0.471431 -1.895855  0.366942 -0.492975 -0.593682  \n",
       "346 -0.651299 -0.127834 -0.059416 -0.119636 -0.087696 -1.513201  \n",
       "347  0.994797  0.244490  0.392686 -0.244980  4.024945  2.431384  \n",
       "348  0.784602 -0.134163 -0.228937  0.448984 -0.348608  0.212757  \n",
       "349 -0.215783  1.153468  2.968010  1.083063 -0.241957 -0.681613  \n",
       "350  1.631244  0.628999 -0.233673  0.390213 -0.520131 -1.751054  \n",
       "351 -0.510013 -0.382875 -0.328020 -0.053195  0.050772  0.416897  \n",
       "352 -0.932233  0.208401  0.497495  0.460779  0.066186 -0.304442  \n",
       "353 -0.188151  0.285467  0.888652 -0.951077 -0.418927 -0.168896  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(100, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 480us/step - loss: 3048.0376\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 176.5291\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 95.3427\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 80.2436\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 70.2134\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 64.4270\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 61.2061\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.7741\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 57.8245\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.9162\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.0910\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.0208\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.6997\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 51.8309\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 51.2303\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.8773\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.4343\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.3549\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 46.3015\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 45.6184\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 49.7396: 0s - loss: 52.223\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 45.1649\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.1313\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.5852\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 42.9271\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.3287\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 42.8432\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 41.3745\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.2242\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 40.2710\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 39.8519\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.8035\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 38.4530\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.3209\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.0295\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 39.8680\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.1207\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.2474\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.5750\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 38.6437\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 35.2182\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.5887\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 36.1152\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.2587\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.3803\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.1895\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.7784\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.4479\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.0486\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.8895\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 32.4187\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.6188\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 31.3924\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.1078\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.4994\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.4287\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.7941\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5592\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.4727\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.2143\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8402\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8944\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2467\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.9558\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.5496\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.3672\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.9535\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.5571\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.4195\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.8340\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8078\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.9281\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6288\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.6416\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3271\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.7480\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.2224\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7066\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.1655\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.8483\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.1359\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.2941\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9905\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.2486\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.4214\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.4189\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9319\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.2645\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.1441\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2434\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1099\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.0460\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.3605\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.3636\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.7426\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 28.5507\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.3722\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5131\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8276\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 85us/step - loss: 25.1825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12a399b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 33., 38.,  7., 21., 31., 15., 12., 21., 21., 17., -0., 35.,\n",
       "        17., 12., 26., 30., 20., 20., 21., 18., 19., 39., 26., 19., -2.,\n",
       "        18., 13.,  8., 12., 27., 21., 23., 17., 27., 34., 19., 23., 18.,\n",
       "        32., 19.,  4., 27., 25., 20., 20., 13., 15., 21., 13., 19.,  2.,\n",
       "        27., 26., 23., 23.,  5., 30.,  8., 23., 28., 22., 15., 45., 29.,\n",
       "        29., 29., 26., 26., 17., 20., 26., 15., 39., 38., 16., 15., 28.,\n",
       "        27., 32., 18., 20., 24., 16., 21., 15., 23., 23., 21., 11., -0.,\n",
       "        21., 19., 16., 31., 24., 16., 22., 21., 24., 23.,  9., 15., 12.,\n",
       "        16., 20., 28., -0., 32., 18., 35., 22., 15., 11., 30., 23., 15.,\n",
       "        26., 24., 17., 20., 21., 14., 22., 23., 22., 11.,  9.,  1., 22.,\n",
       "        16., 18., 19., 14., 36., 16., 25., 40., 26., 22., 23., 12., 35.,\n",
       "        10., 29., 26., 10., 14., 37.,  9., 12., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 658us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.237410595542507"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(20, activation=\"linear\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 876us/step - loss: 26924.7320\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 975.4848\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 445.0723\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 301.0799\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 254.7654\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 238.6879\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 208.5906\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 188.2223\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 173.5753\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 159.0455\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 143.5154\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 134.4230\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 124.9297\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 117.5244\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 172us/step - loss: 111.4953\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 104.3667\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 100.4452\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 97.1617\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 93.0085\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 93.5031\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 91.9857\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 84.6021\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 80.4292\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 79.0003\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 77.5642\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 74.8707\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 72.9683\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 70.5012\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 72.4415\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 67.6650\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 65.6015\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 64.4491\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 66.1959\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.4042\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 61.3659\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 60.8396\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 61.8317\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 59.1458\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 56.4659\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.2032\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.7569\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 52.8686\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 52.5503\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 52.1430\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.6791\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.2368\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 50.2895\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 50.1829\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.4730\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.1743\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.7010\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.2215\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 47.7996\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 48.0764\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 48.0232\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 49.2792\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 45.9510\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 47.0360\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 47.4369\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.2400\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.7679\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 45.0190\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.3086\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.0026\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.3546\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 41.9442\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.7752\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.2663\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 43.0015\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.8154\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.3341\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 43.3126\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.3049\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.5823\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 43.2965\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.5176\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.4674\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.7657\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.4619\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 46.1198\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.8508\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.0977\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.6115\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.4320\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.7730\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.9909\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 144us/step - loss: 38.1876\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.4668\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.3818\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.0314\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.7754\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 42.5444\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.5340\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.6605\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.3363\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 37.0880\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.6352\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.0382\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.4437\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.5694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x124bb9b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25., 36., 39.,  7., 24., 35., 20.,  9., 25., 20., 22.,  7., 39.,\n",
       "        20., 17., 27., 37., 28., 25., 27., 25., 24., 38., 27., 25.,  2.,\n",
       "        18., 11., 15., 16., 32., 25., 26., 21., 30., 38., 20., 28., 23.,\n",
       "        34., 23., 10., 32., 31., 26., 24., 19., 20., 28., 18., 25.,  1.,\n",
       "        26., 23., 31., 27.,  8., 32., 17., 29., 29., 28., 19., 45., 31.,\n",
       "        34., 34., 31., 33., 23., 23., 34., 15., 37., 41., 22., 19., 31.,\n",
       "        31., 36., 25., 24., 29., 22., 22., 20., 27., 22., 29., 16., -1.,\n",
       "        24., 23., 23., 34., 27., 19., 25., 27., 28., 27., 11., 19., 14.,\n",
       "        23., 26., 35.,  4., 37., 24., 39., 22., 16., 11., 32., 25., 22.,\n",
       "        33., 32., 19., 23., 27., 19., 28., 27., 29., 16., 14.,  7., 27.,\n",
       "        18., 12., 26., 17., 41., 32., 30., 39., 31., 26., 27., 15., 39.,\n",
       "        12., 32., 26., 15., 17., 37., 10., 14., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 855us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39.009564751072936"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(20, activation=\"linear\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 621us/step - loss: 733.6700\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 93.7893\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 76.9471\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 76.0735\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 73.2314\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 69.4296\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 68.1540\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 67.5511\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 67.4442\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.7561\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.2278\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 64.0508\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.5200\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 59.6385\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 62.4739\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 60.9130\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 59.5773\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.9922\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.9843\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 56.8985\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 56.6545\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.5471\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 57.7596\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.5546\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.5607\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 54.1309\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 54.0456\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.9607\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 54.5995\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 54.4422\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 57.5632\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 55.8013\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 51.8275\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.2005\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 57.3288\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 50.0358\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.4267\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.8801\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.4568\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 49.1337\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 50.2301\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.0504\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 46.3637\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 48.4021\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.9454\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.1051\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 46.1376\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 44.9584\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 45.5204\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 42.6765\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.2438\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.4057\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 42.6678\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 53.7446\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.5716\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.8743\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 42.4035\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.4395\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.2296\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.5175\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.7308\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.7595\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.0208\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.6086\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 44.3060\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.4494\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.4704\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 47.6982\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.4742\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.8765\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.8560\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.3661\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.7095\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.3655\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.7086\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.5005\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.2995\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.3117\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.4682\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.0265\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.9638\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.5204\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.5554\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.0847\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.4060\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.9467\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.2579\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.1805\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.6381\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.0385\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.0514\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.5694\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.6964\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.4567\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.7916\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 33.1473\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.3513\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.9386\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.9474\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 113us/step - loss: 38.6194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x124bbd68>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 32., 37.,  9., 23., 33., 19., 15., 23., 20., 19.,  5., 37.,\n",
       "        19., 16., 25., 31., 24., 23., 24., 21., 21., 35., 24., 21., -0.,\n",
       "        18., 15., 12., 11., 28., 23., 25., 20., 28., 49., 19., 26., 19.,\n",
       "        31., 21.,  8., 28., 26., 24., 20., 16., 16., 23., 15., 23., -3.,\n",
       "        25., 24., 23., 25.,  9., 34.,  6., 24., 26., 25., 19., 54., 28.,\n",
       "        28., 28., 27., 29., 19., 21., 30.,  9., 31., 36., 20., 17., 29.,\n",
       "        29., 30., 23., 22., 25., 19., 18., 17., 25., 23., 25., 13.,  1.,\n",
       "        18., 21., 19., 32., 24., 17., 21., 23., 25., 23., 10., 17., 15.,\n",
       "        19., 22., 31., -0., 35., 20., 37., 21., 14.,  7., 29., 23., 18.,\n",
       "        28., 25., 19., 22., 23., 15., 24., 25., 25., 10., 11.,  4., 25.,\n",
       "        19., 20., 21., 16., 34., 22., 27., 33., 28., 24., 24., 14., 32.,\n",
       "        11., 29., 24., 12., 16., 34., 10., 15., 27.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.34155112818668"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.218296</td>\n",
       "      <td>0.336704</td>\n",
       "      <td>-0.426186</td>\n",
       "      <td>-0.886752</td>\n",
       "      <td>0.380047</td>\n",
       "      <td>-1.187510</td>\n",
       "      <td>-0.391259</td>\n",
       "      <td>0.125752</td>\n",
       "      <td>-0.172811</td>\n",
       "      <td>-1.267331</td>\n",
       "      <td>-1.771462</td>\n",
       "      <td>-0.501306</td>\n",
       "      <td>0.296134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410900</td>\n",
       "      <td>-1.292493</td>\n",
       "      <td>1.055464</td>\n",
       "      <td>-1.463581</td>\n",
       "      <td>-0.607597</td>\n",
       "      <td>-0.256340</td>\n",
       "      <td>0.067925</td>\n",
       "      <td>1.176856</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>-0.220818</td>\n",
       "      <td>-0.498881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.551091</td>\n",
       "      <td>0.086810</td>\n",
       "      <td>-1.064214</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>-0.056779</td>\n",
       "      <td>-0.404564</td>\n",
       "      <td>-0.352776</td>\n",
       "      <td>-0.668523</td>\n",
       "      <td>1.635779</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>-0.914374</td>\n",
       "      <td>-0.289210</td>\n",
       "      <td>0.679937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>1.007146</td>\n",
       "      <td>-2.389351</td>\n",
       "      <td>0.140114</td>\n",
       "      <td>-0.508026</td>\n",
       "      <td>0.103962</td>\n",
       "      <td>0.610198</td>\n",
       "      <td>-0.978994</td>\n",
       "      <td>-1.487230</td>\n",
       "      <td>-1.857298</td>\n",
       "      <td>-0.362586</td>\n",
       "      <td>0.584306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115420</td>\n",
       "      <td>-0.424497</td>\n",
       "      <td>-0.599070</td>\n",
       "      <td>-0.126995</td>\n",
       "      <td>-0.378454</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>-0.435759</td>\n",
       "      <td>-0.986912</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>-1.001963</td>\n",
       "      <td>0.307408</td>\n",
       "      <td>-0.171837</td>\n",
       "      <td>0.416459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.568687</td>\n",
       "      <td>-0.017722</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-0.158364</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.930286</td>\n",
       "      <td>-0.793835</td>\n",
       "      <td>0.195159</td>\n",
       "      <td>-0.394252</td>\n",
       "      <td>0.754895</td>\n",
       "      <td>-0.054449</td>\n",
       "      <td>3.939962</td>\n",
       "      <td>-0.256343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.447170</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>2.683609</td>\n",
       "      <td>1.917981</td>\n",
       "      <td>-0.119569</td>\n",
       "      <td>0.329389</td>\n",
       "      <td>-0.053554</td>\n",
       "      <td>-0.408277</td>\n",
       "      <td>3.289767</td>\n",
       "      <td>0.921860</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.310273</td>\n",
       "      <td>1.934371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.967308</td>\n",
       "      <td>0.106104</td>\n",
       "      <td>1.077655</td>\n",
       "      <td>-1.022205</td>\n",
       "      <td>0.391836</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>-0.112093</td>\n",
       "      <td>0.631071</td>\n",
       "      <td>-0.554251</td>\n",
       "      <td>1.049112</td>\n",
       "      <td>0.595754</td>\n",
       "      <td>-0.264482</td>\n",
       "      <td>0.098367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.446440</td>\n",
       "      <td>-1.186458</td>\n",
       "      <td>-0.223272</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>-0.011630</td>\n",
       "      <td>-0.288014</td>\n",
       "      <td>-0.546646</td>\n",
       "      <td>0.685738</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>-0.260171</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.977767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.743204</td>\n",
       "      <td>-0.016091</td>\n",
       "      <td>-1.406325</td>\n",
       "      <td>0.539970</td>\n",
       "      <td>0.063506</td>\n",
       "      <td>0.855115</td>\n",
       "      <td>-0.100882</td>\n",
       "      <td>1.019661</td>\n",
       "      <td>-1.045355</td>\n",
       "      <td>0.728018</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>3.768397</td>\n",
       "      <td>-0.865074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>-1.128775</td>\n",
       "      <td>0.598142</td>\n",
       "      <td>-0.700726</td>\n",
       "      <td>-0.792189</td>\n",
       "      <td>2.491377</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>-1.475142</td>\n",
       "      <td>0.964716</td>\n",
       "      <td>0.580170</td>\n",
       "      <td>-0.526890</td>\n",
       "      <td>3.695478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.109496</td>\n",
       "      <td>-0.463290</td>\n",
       "      <td>3.319455</td>\n",
       "      <td>2.483666</td>\n",
       "      <td>-0.436228</td>\n",
       "      <td>0.296471</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>-1.359378</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>-1.069896</td>\n",
       "      <td>-0.435476</td>\n",
       "      <td>0.335398</td>\n",
       "      <td>0.233901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.563461</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.916949</td>\n",
       "      <td>0.047773</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.193161</td>\n",
       "      <td>-0.672598</td>\n",
       "      <td>-0.635800</td>\n",
       "      <td>1.411689</td>\n",
       "      <td>-0.034218</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.644681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.227955</td>\n",
       "      <td>0.397238</td>\n",
       "      <td>-1.018147</td>\n",
       "      <td>-0.282160</td>\n",
       "      <td>0.326452</td>\n",
       "      <td>2.019800</td>\n",
       "      <td>2.784529</td>\n",
       "      <td>3.627855</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>-0.305158</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>-0.827660</td>\n",
       "      <td>-0.294085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.184482</td>\n",
       "      <td>0.636922</td>\n",
       "      <td>-1.831814</td>\n",
       "      <td>0.768341</td>\n",
       "      <td>0.404875</td>\n",
       "      <td>3.168186</td>\n",
       "      <td>1.429387</td>\n",
       "      <td>3.382434</td>\n",
       "      <td>0.488574</td>\n",
       "      <td>-0.065362</td>\n",
       "      <td>-0.991493</td>\n",
       "      <td>-0.928332</td>\n",
       "      <td>-0.957187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.770244</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.887590</td>\n",
       "      <td>-0.119189</td>\n",
       "      <td>-0.104687</td>\n",
       "      <td>-0.106483</td>\n",
       "      <td>0.990349</td>\n",
       "      <td>-0.165131</td>\n",
       "      <td>1.597335</td>\n",
       "      <td>-1.654309</td>\n",
       "      <td>0.477349</td>\n",
       "      <td>-0.238305</td>\n",
       "      <td>0.806332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.049209</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>-0.191747</td>\n",
       "      <td>0.451898</td>\n",
       "      <td>0.354904</td>\n",
       "      <td>0.686849</td>\n",
       "      <td>-0.510539</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>0.264772</td>\n",
       "      <td>-0.954217</td>\n",
       "      <td>0.657336</td>\n",
       "      <td>4.091099</td>\n",
       "      <td>-0.468007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.686215</td>\n",
       "      <td>-0.075888</td>\n",
       "      <td>1.192591</td>\n",
       "      <td>1.485459</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>-0.011337</td>\n",
       "      <td>-0.086963</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>1.270550</td>\n",
       "      <td>0.603574</td>\n",
       "      <td>-0.282384</td>\n",
       "      <td>-0.934310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.784367</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>-0.780065</td>\n",
       "      <td>-0.207366</td>\n",
       "      <td>-0.016780</td>\n",
       "      <td>-0.963678</td>\n",
       "      <td>-0.534382</td>\n",
       "      <td>-1.264696</td>\n",
       "      <td>-0.251943</td>\n",
       "      <td>-0.784355</td>\n",
       "      <td>0.594379</td>\n",
       "      <td>-0.225215</td>\n",
       "      <td>-0.516801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.717640</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.989287</td>\n",
       "      <td>-2.451317</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.077713</td>\n",
       "      <td>0.384208</td>\n",
       "      <td>0.270853</td>\n",
       "      <td>0.533549</td>\n",
       "      <td>-0.278017</td>\n",
       "      <td>-0.256943</td>\n",
       "      <td>-0.159516</td>\n",
       "      <td>1.272878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.624073</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.160763</td>\n",
       "      <td>0.031376</td>\n",
       "      <td>-0.234554</td>\n",
       "      <td>-0.241636</td>\n",
       "      <td>0.243423</td>\n",
       "      <td>-0.493480</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.280933</td>\n",
       "      <td>-0.702675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.715731</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.572144</td>\n",
       "      <td>-1.919670</td>\n",
       "      <td>0.174060</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>0.208287</td>\n",
       "      <td>0.176057</td>\n",
       "      <td>0.658007</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>-0.017581</td>\n",
       "      <td>-0.200698</td>\n",
       "      <td>0.979237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.421298</td>\n",
       "      <td>-1.406029</td>\n",
       "      <td>-0.310320</td>\n",
       "      <td>0.269410</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.218211</td>\n",
       "      <td>-0.958624</td>\n",
       "      <td>0.714248</td>\n",
       "      <td>-0.279995</td>\n",
       "      <td>-0.538967</td>\n",
       "      <td>-1.754797</td>\n",
       "      <td>-0.429055</td>\n",
       "      <td>-0.052801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.115556</td>\n",
       "      <td>-0.540635</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>-0.074706</td>\n",
       "      <td>-0.683186</td>\n",
       "      <td>-0.629395</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>-1.539723</td>\n",
       "      <td>-0.511106</td>\n",
       "      <td>-0.225811</td>\n",
       "      <td>0.887479</td>\n",
       "      <td>-0.116359</td>\n",
       "      <td>-0.620534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.810639</td>\n",
       "      <td>0.069947</td>\n",
       "      <td>-0.996857</td>\n",
       "      <td>1.638662</td>\n",
       "      <td>0.107503</td>\n",
       "      <td>-0.951199</td>\n",
       "      <td>-0.879962</td>\n",
       "      <td>-0.084254</td>\n",
       "      <td>-2.660340</td>\n",
       "      <td>-0.417255</td>\n",
       "      <td>-0.456178</td>\n",
       "      <td>-0.660758</td>\n",
       "      <td>0.809331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.105027</td>\n",
       "      <td>-0.365970</td>\n",
       "      <td>1.965839</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>-0.438936</td>\n",
       "      <td>-0.648371</td>\n",
       "      <td>0.423267</td>\n",
       "      <td>-1.329676</td>\n",
       "      <td>-1.265713</td>\n",
       "      <td>0.452782</td>\n",
       "      <td>-0.624106</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>-0.248861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.572685</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>2.236526</td>\n",
       "      <td>2.417969</td>\n",
       "      <td>-0.146365</td>\n",
       "      <td>0.462122</td>\n",
       "      <td>0.541046</td>\n",
       "      <td>-0.676499</td>\n",
       "      <td>0.307313</td>\n",
       "      <td>1.529051</td>\n",
       "      <td>0.819056</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>-0.124282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.492915</td>\n",
       "      <td>-0.203387</td>\n",
       "      <td>1.777558</td>\n",
       "      <td>-1.572743</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>-0.118156</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.826970</td>\n",
       "      <td>2.020085</td>\n",
       "      <td>-3.937981</td>\n",
       "      <td>-0.269015</td>\n",
       "      <td>1.479730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.452100</td>\n",
       "      <td>-1.043974</td>\n",
       "      <td>0.526998</td>\n",
       "      <td>-0.762193</td>\n",
       "      <td>0.790775</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>-0.189807</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>-0.103903</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>-0.112098</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>-0.970029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.751558</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>0.426210</td>\n",
       "      <td>-1.772618</td>\n",
       "      <td>0.183135</td>\n",
       "      <td>0.663843</td>\n",
       "      <td>0.573432</td>\n",
       "      <td>0.576692</td>\n",
       "      <td>-0.106322</td>\n",
       "      <td>-0.719618</td>\n",
       "      <td>-0.340360</td>\n",
       "      <td>-0.287602</td>\n",
       "      <td>0.048091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.341859</td>\n",
       "      <td>1.772573</td>\n",
       "      <td>-1.265405</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>-0.069995</td>\n",
       "      <td>0.509438</td>\n",
       "      <td>-1.132676</td>\n",
       "      <td>-0.942075</td>\n",
       "      <td>1.348960</td>\n",
       "      <td>-0.156008</td>\n",
       "      <td>-0.450447</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>0.098929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.826799</td>\n",
       "      <td>0.112487</td>\n",
       "      <td>0.247452</td>\n",
       "      <td>0.055284</td>\n",
       "      <td>0.105849</td>\n",
       "      <td>-1.312153</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>0.206861</td>\n",
       "      <td>-2.599742</td>\n",
       "      <td>-0.679201</td>\n",
       "      <td>-0.256533</td>\n",
       "      <td>-0.516969</td>\n",
       "      <td>0.534755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.641654</td>\n",
       "      <td>-0.038538</td>\n",
       "      <td>-0.551487</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.734961</td>\n",
       "      <td>-0.838139</td>\n",
       "      <td>-0.706664</td>\n",
       "      <td>-1.151996</td>\n",
       "      <td>-0.788001</td>\n",
       "      <td>1.688322</td>\n",
       "      <td>-0.269644</td>\n",
       "      <td>-0.713522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.079148</td>\n",
       "      <td>-1.116960</td>\n",
       "      <td>0.596164</td>\n",
       "      <td>-0.749896</td>\n",
       "      <td>-0.961395</td>\n",
       "      <td>2.613610</td>\n",
       "      <td>0.045463</td>\n",
       "      <td>-1.388278</td>\n",
       "      <td>1.004437</td>\n",
       "      <td>1.593126</td>\n",
       "      <td>-0.459578</td>\n",
       "      <td>-1.373151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-0.813866</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>1.064336</td>\n",
       "      <td>-0.424341</td>\n",
       "      <td>0.102291</td>\n",
       "      <td>0.844122</td>\n",
       "      <td>1.986576</td>\n",
       "      <td>1.953437</td>\n",
       "      <td>0.265062</td>\n",
       "      <td>-1.395970</td>\n",
       "      <td>0.522529</td>\n",
       "      <td>-0.342571</td>\n",
       "      <td>-0.815108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-0.921492</td>\n",
       "      <td>0.112342</td>\n",
       "      <td>-0.365070</td>\n",
       "      <td>-0.821385</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>-0.452206</td>\n",
       "      <td>-0.469554</td>\n",
       "      <td>-0.391193</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>-0.702808</td>\n",
       "      <td>0.813267</td>\n",
       "      <td>-0.251879</td>\n",
       "      <td>-0.768778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.991131</td>\n",
       "      <td>3.384534</td>\n",
       "      <td>0.421641</td>\n",
       "      <td>-0.237522</td>\n",
       "      <td>-1.409536</td>\n",
       "      <td>-0.691933</td>\n",
       "      <td>-0.216972</td>\n",
       "      <td>0.564823</td>\n",
       "      <td>0.417845</td>\n",
       "      <td>0.566093</td>\n",
       "      <td>0.646313</td>\n",
       "      <td>-0.044244</td>\n",
       "      <td>-0.164187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.569081</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>-1.287219</td>\n",
       "      <td>0.513402</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>0.189279</td>\n",
       "      <td>-0.924604</td>\n",
       "      <td>-0.714949</td>\n",
       "      <td>1.490871</td>\n",
       "      <td>0.395190</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.270665</td>\n",
       "      <td>0.437375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.423465</td>\n",
       "      <td>-1.404566</td>\n",
       "      <td>-0.327444</td>\n",
       "      <td>0.281870</td>\n",
       "      <td>1.136365</td>\n",
       "      <td>1.723241</td>\n",
       "      <td>-1.725096</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>-0.753861</td>\n",
       "      <td>-0.512377</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>-0.252973</td>\n",
       "      <td>0.189492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.356470</td>\n",
       "      <td>1.123745</td>\n",
       "      <td>-0.933219</td>\n",
       "      <td>0.525810</td>\n",
       "      <td>-0.889419</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.884598</td>\n",
       "      <td>-0.494448</td>\n",
       "      <td>1.574206</td>\n",
       "      <td>-0.295988</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>-0.094441</td>\n",
       "      <td>0.154127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.824148</td>\n",
       "      <td>0.085650</td>\n",
       "      <td>-0.076755</td>\n",
       "      <td>0.455379</td>\n",
       "      <td>0.246723</td>\n",
       "      <td>-0.323226</td>\n",
       "      <td>-0.679215</td>\n",
       "      <td>0.111718</td>\n",
       "      <td>-2.984972</td>\n",
       "      <td>-1.232753</td>\n",
       "      <td>2.838079</td>\n",
       "      <td>-0.386188</td>\n",
       "      <td>1.017576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-0.127880</td>\n",
       "      <td>-0.422532</td>\n",
       "      <td>0.152169</td>\n",
       "      <td>-1.090901</td>\n",
       "      <td>-0.301478</td>\n",
       "      <td>0.352250</td>\n",
       "      <td>-0.072848</td>\n",
       "      <td>-0.811853</td>\n",
       "      <td>-0.211932</td>\n",
       "      <td>-1.731636</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>-0.048400</td>\n",
       "      <td>0.811001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.146226</td>\n",
       "      <td>-0.384283</td>\n",
       "      <td>-0.986603</td>\n",
       "      <td>0.347412</td>\n",
       "      <td>-0.335649</td>\n",
       "      <td>0.549421</td>\n",
       "      <td>-1.125597</td>\n",
       "      <td>-1.430948</td>\n",
       "      <td>0.742985</td>\n",
       "      <td>-1.589639</td>\n",
       "      <td>0.149407</td>\n",
       "      <td>-0.093774</td>\n",
       "      <td>-0.686834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.472153</td>\n",
       "      <td>-0.972228</td>\n",
       "      <td>-0.133663</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>0.740923</td>\n",
       "      <td>0.531293</td>\n",
       "      <td>-0.840607</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>-0.384282</td>\n",
       "      <td>-0.656741</td>\n",
       "      <td>-1.713876</td>\n",
       "      <td>-0.325242</td>\n",
       "      <td>-0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.456135</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>2.599987</td>\n",
       "      <td>2.013634</td>\n",
       "      <td>-0.074048</td>\n",
       "      <td>0.699033</td>\n",
       "      <td>-0.367732</td>\n",
       "      <td>-0.427186</td>\n",
       "      <td>3.169238</td>\n",
       "      <td>0.951461</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>1.829259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.199952</td>\n",
       "      <td>1.533377</td>\n",
       "      <td>-0.834032</td>\n",
       "      <td>0.360015</td>\n",
       "      <td>-0.631507</td>\n",
       "      <td>-0.470706</td>\n",
       "      <td>2.482422</td>\n",
       "      <td>-0.134929</td>\n",
       "      <td>-1.467272</td>\n",
       "      <td>1.261561</td>\n",
       "      <td>1.124268</td>\n",
       "      <td>-0.344816</td>\n",
       "      <td>-1.194008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.133477</td>\n",
       "      <td>-0.373511</td>\n",
       "      <td>0.864971</td>\n",
       "      <td>-2.012486</td>\n",
       "      <td>-0.053010</td>\n",
       "      <td>1.852188</td>\n",
       "      <td>-0.642114</td>\n",
       "      <td>-0.699432</td>\n",
       "      <td>-0.825240</td>\n",
       "      <td>-2.137400</td>\n",
       "      <td>0.036622</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>1.373298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>-0.674742</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>-0.674479</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>-0.423200</td>\n",
       "      <td>-1.656176</td>\n",
       "      <td>-0.758245</td>\n",
       "      <td>-0.422877</td>\n",
       "      <td>0.556423</td>\n",
       "      <td>-0.095854</td>\n",
       "      <td>-0.889029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.035970</td>\n",
       "      <td>-0.467859</td>\n",
       "      <td>-1.224252</td>\n",
       "      <td>0.653701</td>\n",
       "      <td>0.116760</td>\n",
       "      <td>2.371741</td>\n",
       "      <td>0.350227</td>\n",
       "      <td>-0.105625</td>\n",
       "      <td>-2.684684</td>\n",
       "      <td>0.362394</td>\n",
       "      <td>0.224631</td>\n",
       "      <td>-0.483569</td>\n",
       "      <td>3.346229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>-0.231514</td>\n",
       "      <td>-0.408073</td>\n",
       "      <td>-0.620177</td>\n",
       "      <td>0.326987</td>\n",
       "      <td>-0.316636</td>\n",
       "      <td>-1.566828</td>\n",
       "      <td>-0.924376</td>\n",
       "      <td>-0.802616</td>\n",
       "      <td>0.570587</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>-0.615597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.734757</td>\n",
       "      <td>-0.019290</td>\n",
       "      <td>-1.589464</td>\n",
       "      <td>0.786915</td>\n",
       "      <td>0.188284</td>\n",
       "      <td>1.379813</td>\n",
       "      <td>-1.282396</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>-0.042861</td>\n",
       "      <td>0.826787</td>\n",
       "      <td>0.598042</td>\n",
       "      <td>3.973727</td>\n",
       "      <td>-1.264901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-1.062561</td>\n",
       "      <td>0.175754</td>\n",
       "      <td>-0.150195</td>\n",
       "      <td>1.450560</td>\n",
       "      <td>0.300127</td>\n",
       "      <td>-0.997197</td>\n",
       "      <td>-1.044866</td>\n",
       "      <td>1.169793</td>\n",
       "      <td>0.471431</td>\n",
       "      <td>-1.895855</td>\n",
       "      <td>0.366942</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.593682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.077830</td>\n",
       "      <td>-0.320047</td>\n",
       "      <td>0.419044</td>\n",
       "      <td>-1.408831</td>\n",
       "      <td>-0.406938</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>-0.651299</td>\n",
       "      <td>-0.127834</td>\n",
       "      <td>-0.059416</td>\n",
       "      <td>-0.119636</td>\n",
       "      <td>-0.087696</td>\n",
       "      <td>-1.513201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.424047</td>\n",
       "      <td>-1.335482</td>\n",
       "      <td>-0.047273</td>\n",
       "      <td>-0.052808</td>\n",
       "      <td>-0.885869</td>\n",
       "      <td>-0.821740</td>\n",
       "      <td>-0.321385</td>\n",
       "      <td>0.994797</td>\n",
       "      <td>0.244490</td>\n",
       "      <td>0.392686</td>\n",
       "      <td>-0.244980</td>\n",
       "      <td>4.024945</td>\n",
       "      <td>2.431384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1.426656</td>\n",
       "      <td>-1.357723</td>\n",
       "      <td>-0.304057</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>-0.286396</td>\n",
       "      <td>0.040887</td>\n",
       "      <td>-0.919443</td>\n",
       "      <td>0.784602</td>\n",
       "      <td>-0.134163</td>\n",
       "      <td>-0.228937</td>\n",
       "      <td>0.448984</td>\n",
       "      <td>-0.348608</td>\n",
       "      <td>0.212757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.421858</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>-0.205606</td>\n",
       "      <td>0.990012</td>\n",
       "      <td>-0.147521</td>\n",
       "      <td>-0.228645</td>\n",
       "      <td>-1.006426</td>\n",
       "      <td>-0.215783</td>\n",
       "      <td>1.153468</td>\n",
       "      <td>2.968010</td>\n",
       "      <td>1.083063</td>\n",
       "      <td>-0.241957</td>\n",
       "      <td>-0.681613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.791279</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.351439</td>\n",
       "      <td>1.390501</td>\n",
       "      <td>-0.051356</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>1.300206</td>\n",
       "      <td>1.631244</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>-0.233673</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>-0.520131</td>\n",
       "      <td>-1.751054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1.525218</td>\n",
       "      <td>-0.541349</td>\n",
       "      <td>0.094171</td>\n",
       "      <td>-0.153951</td>\n",
       "      <td>4.182298</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>-0.510013</td>\n",
       "      <td>-0.382875</td>\n",
       "      <td>-0.328020</td>\n",
       "      <td>-0.053195</td>\n",
       "      <td>0.050772</td>\n",
       "      <td>0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.400854</td>\n",
       "      <td>-0.247820</td>\n",
       "      <td>1.234477</td>\n",
       "      <td>-1.592875</td>\n",
       "      <td>-0.061667</td>\n",
       "      <td>0.427942</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>-0.932233</td>\n",
       "      <td>0.208401</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0.460779</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>-0.304442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.944012</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>-0.494481</td>\n",
       "      <td>-0.667725</td>\n",
       "      <td>0.048722</td>\n",
       "      <td>-1.041966</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>-0.188151</td>\n",
       "      <td>0.285467</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>-0.951077</td>\n",
       "      <td>-0.418927</td>\n",
       "      <td>-0.168896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -1.218296  0.336704 -0.426186 -0.886752  0.380047 -1.187510 -0.391259   \n",
       "1    1.410900 -1.292493  1.055464 -1.463581 -0.607597 -0.256340  0.067925   \n",
       "2   -0.551091  0.086810 -1.064214  0.249742 -0.056779 -0.404564 -0.352776   \n",
       "3   -0.580706  0.126584  1.007146 -2.389351  0.140114 -0.508026  0.103962   \n",
       "4   -0.115420 -0.424497 -0.599070 -0.126995 -0.378454  0.132858 -0.435759   \n",
       "5   -0.568687 -0.017722 -0.741355 -0.158364  0.000028 -0.930286 -0.793835   \n",
       "6   -0.447170  0.045592  2.683609  1.917981 -0.119569  0.329389 -0.053554   \n",
       "7   -0.967308  0.106104  1.077655 -1.022205  0.391836  0.588200 -0.112093   \n",
       "8    1.446440 -1.186458 -0.223272  0.184505 -0.011630 -0.288014 -0.546646   \n",
       "9   -0.743204 -0.016091 -1.406325  0.539970  0.063506  0.855115 -0.100882   \n",
       "10   0.011236 -0.053868 -1.128775  0.598142 -0.700726 -0.792189  2.491377   \n",
       "11  -0.109496 -0.463290  3.319455  2.483666 -0.436228  0.296471  0.442018   \n",
       "12  -0.563461  0.004313 -0.916949  0.047773  0.015107  0.193161 -0.672598   \n",
       "13  -1.227955  0.397238 -1.018147 -0.282160  0.326452  2.019800  2.784529   \n",
       "14  -1.184482  0.636922 -1.831814  0.768341  0.404875  3.168186  1.429387   \n",
       "15  -0.770244 -0.004625 -0.887590 -0.119189 -0.104687 -0.106483  0.990349   \n",
       "16  -1.049209  0.245458 -0.191747  0.451898  0.354904  0.686849 -0.510539   \n",
       "17  -0.686215 -0.075888  1.192591  1.485459  0.039956 -0.011337 -0.086963   \n",
       "18  -0.784367  0.049567 -0.780065 -0.207366 -0.016780 -0.963678 -0.534382   \n",
       "19  -0.717640 -0.008363  0.989287 -2.451317  0.204783  0.077713  0.384208   \n",
       "20  -0.624073  0.068307  0.862734  0.160763  0.031376 -0.234554 -0.241636   \n",
       "21  -0.715731 -0.050616  0.572144 -1.919670  0.174060 -0.069824  0.208287   \n",
       "22   1.421298 -1.406029 -0.310320  0.269410  0.025199  0.218211 -0.958624   \n",
       "23   0.115556 -0.540635 -0.533333 -0.074706 -0.683186 -0.629395  0.157352   \n",
       "24  -0.810639  0.069947 -0.996857  1.638662  0.107503 -0.951199 -0.879962   \n",
       "25  -0.105027 -0.365970  1.965839  0.244274 -0.438936 -0.648371  0.423267   \n",
       "26  -0.572685 -0.102770  2.236526  2.417969 -0.146365  0.462122  0.541046   \n",
       "27  -0.492915 -0.203387  1.777558 -1.572743  0.071259 -0.118156  0.251742   \n",
       "28   1.452100 -1.043974  0.526998 -0.762193  0.790775  0.227564 -0.189807   \n",
       "29  -0.751558  0.126659  0.426210 -1.772618  0.183135  0.663843  0.573432   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324 -0.341859  1.772573 -1.265405  0.645878 -0.069995  0.509438 -1.132676   \n",
       "325 -0.826799  0.112487  0.247452  0.055284  0.105849 -1.312153  0.193734   \n",
       "326 -0.641654 -0.038538 -0.551487 -0.429577 -0.006266 -0.734961 -0.838139   \n",
       "327  0.027163  0.079148 -1.116960  0.596164 -0.749896 -0.961395  2.613610   \n",
       "328 -0.813866  0.015304  1.064336 -0.424341  0.102291  0.844122  1.986576   \n",
       "329 -0.921492  0.112342 -0.365070 -0.821385  0.201869 -0.452206 -0.469554   \n",
       "330  1.991131  3.384534  0.421641 -0.237522 -1.409536 -0.691933 -0.216972   \n",
       "331 -0.569081 -0.093427 -1.287219  0.513402 -0.005301  0.189279 -0.924604   \n",
       "332  1.423465 -1.404566 -0.327444  0.281870  1.136365  1.723241 -1.725096   \n",
       "333  0.356470  1.123745 -0.933219  0.525810 -0.889419  0.999575  1.884598   \n",
       "334 -0.824148  0.085650 -0.076755  0.455379  0.246723 -0.323226 -0.679215   \n",
       "335 -0.127880 -0.422532  0.152169 -1.090901 -0.301478  0.352250 -0.072848   \n",
       "336 -0.146226 -0.384283 -0.986603  0.347412 -0.335649  0.549421 -1.125597   \n",
       "337  1.472153 -0.972228 -0.133663  0.082710  0.740923  0.531293 -0.840607   \n",
       "338 -0.456135 -0.040692  2.599987  2.013634 -0.074048  0.699033 -0.367732   \n",
       "339  0.199952  1.533377 -0.834032  0.360015 -0.631507 -0.470706  2.482422   \n",
       "340 -0.133477 -0.373511  0.864971 -2.012486 -0.053010  1.852188 -0.642114   \n",
       "341  0.195446  0.093291 -0.674742  0.154730 -0.674479  0.050682 -0.423200   \n",
       "342 -0.035970 -0.467859 -1.224252  0.653701  0.116760  2.371741  0.350227   \n",
       "343  0.197936  0.174806 -0.231514 -0.408073 -0.620177  0.326987 -0.316636   \n",
       "344 -0.734757 -0.019290 -1.589464  0.786915  0.188284  1.379813 -1.282396   \n",
       "345 -1.062561  0.175754 -0.150195  1.450560  0.300127 -0.997197 -1.044866   \n",
       "346 -0.077830 -0.320047  0.419044 -1.408831 -0.406938  0.525774  0.850306   \n",
       "347  1.424047 -1.335482 -0.047273 -0.052808 -0.885869 -0.821740 -0.321385   \n",
       "348  1.426656 -1.357723 -0.304057  0.266019 -0.286396  0.040887 -0.919443   \n",
       "349 -0.421858  0.103611 -0.205606  0.990012 -0.147521 -0.228645 -1.006426   \n",
       "350 -0.791279  0.004316 -0.351439  1.390501 -0.051356  0.442421  1.300206   \n",
       "351  1.525218 -0.541349  0.094171 -0.153951  4.182298  0.944707  0.100574   \n",
       "352 -0.400854 -0.247820  1.234477 -1.592875 -0.061667  0.427942  0.017642   \n",
       "353 -0.944012  0.158801 -0.494481 -0.667725  0.048722 -1.041966  0.612755   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.125752 -0.172811 -1.267331 -1.771462 -0.501306  0.296134  \n",
       "1    1.176856 -0.012022  0.035788  0.513550 -0.220818 -0.498881  \n",
       "2   -0.668523  1.635779  0.115754 -0.914374 -0.289210  0.679937  \n",
       "3    0.610198 -0.978994 -1.487230 -1.857298 -0.362586  0.584306  \n",
       "4   -0.986912 -0.006150 -1.001963  0.307408 -0.171837  0.416459  \n",
       "5    0.195159 -0.394252  0.754895 -0.054449  3.939962 -0.256343  \n",
       "6   -0.408277  3.289767  0.921860  0.607383  0.310273  1.934371  \n",
       "7    0.631071 -0.554251  1.049112  0.595754 -0.264482  0.098367  \n",
       "8    0.685738  0.060267  0.240304 -0.260171 -0.345022 -0.977767  \n",
       "9    1.019661 -1.045355  0.728018  0.269853  3.768397 -0.865074  \n",
       "10   0.052045 -1.475142  0.964716  0.580170 -0.526890  3.695478  \n",
       "11  -1.359378  0.125921 -1.069896 -0.435476  0.335398  0.233901  \n",
       "12  -0.635800  1.411689 -0.034218  0.026586 -0.222119  0.644681  \n",
       "13   3.627855  0.834177 -0.305158  0.030605 -0.827660 -0.294085  \n",
       "14   3.382434  0.488574 -0.065362 -0.991493 -0.928332 -0.957187  \n",
       "15  -0.165131  1.597335 -1.654309  0.477349 -0.238305  0.806332  \n",
       "16   0.647583  0.264772 -0.954217  0.657336  4.091099 -0.468007  \n",
       "17   0.760112 -0.009755  1.270550  0.603574 -0.282384 -0.934310  \n",
       "18  -1.264696 -0.251943 -0.784355  0.594379 -0.225215 -0.516801  \n",
       "19   0.270853  0.533549 -0.278017 -0.256943 -0.159516  1.272878  \n",
       "20   0.243423 -0.493480  0.820438 -0.000126 -0.280933 -0.702675  \n",
       "21   0.176057  0.658007  0.088739 -0.017581 -0.200698  0.979237  \n",
       "22   0.714248 -0.279995 -0.538967 -1.754797 -0.429055 -0.052801  \n",
       "23  -1.539723 -0.511106 -0.225811  0.887479 -0.116359 -0.620534  \n",
       "24  -0.084254 -2.660340 -0.417255 -0.456178 -0.660758  0.809331  \n",
       "25  -1.329676 -1.265713  0.452782 -0.624106  0.027833 -0.248861  \n",
       "26  -0.676499  0.307313  1.529051  0.819056  0.106207 -0.124282  \n",
       "27   0.267120  0.826970  2.020085 -3.937981 -0.269015  1.479730  \n",
       "28   0.613298 -0.103903  0.294610 -0.112098 -0.186023 -0.970029  \n",
       "29   0.576692 -0.106322 -0.719618 -0.340360 -0.287602  0.048091  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324 -0.942075  1.348960 -0.156008 -0.450447 -0.167151  0.098929  \n",
       "325  0.206861 -2.599742 -0.679201 -0.256533 -0.516969  0.534755  \n",
       "326 -0.706664 -1.151996 -0.788001  1.688322 -0.269644 -0.713522  \n",
       "327  0.045463 -1.388278  1.004437  1.593126 -0.459578 -1.373151  \n",
       "328  1.953437  0.265062 -1.395970  0.522529 -0.342571 -0.815108  \n",
       "329 -0.391193  0.071180 -0.702808  0.813267 -0.251879 -0.768778  \n",
       "330  0.564823  0.417845  0.566093  0.646313 -0.044244 -0.164187  \n",
       "331 -0.714949  1.490871  0.395190  0.041914 -0.270665  0.437375  \n",
       "332  0.398486 -0.753861 -0.512377  0.023830 -0.252973  0.189492  \n",
       "333 -0.494448  1.574206 -0.295988  0.026064 -0.094441  0.154127  \n",
       "334  0.111718 -2.984972 -1.232753  2.838079 -0.386188  1.017576  \n",
       "335 -0.811853 -0.211932 -1.731636  0.992609 -0.048400  0.811001  \n",
       "336 -1.430948  0.742985 -1.589639  0.149407 -0.093774 -0.686834  \n",
       "337  0.493511 -0.384282 -0.656741 -1.713876 -0.325242 -0.006139  \n",
       "338 -0.427186  3.169238  0.951461  0.845506  0.314297  1.829259  \n",
       "339 -0.134929 -1.467272  1.261561  1.124268 -0.344816 -1.194008  \n",
       "340 -0.699432 -0.825240 -2.137400  0.036622  0.021078  1.373298  \n",
       "341 -1.656176 -0.758245 -0.422877  0.556423 -0.095854 -0.889029  \n",
       "342 -0.105625 -2.684684  0.362394  0.224631 -0.483569  3.346229  \n",
       "343 -1.566828 -0.924376 -0.802616  0.570587 -0.034229 -0.615597  \n",
       "344  0.086254 -0.042861  0.826787  0.598042  3.973727 -1.264901  \n",
       "345  1.169793  0.471431 -1.895855  0.366942 -0.492975 -0.593682  \n",
       "346 -0.651299 -0.127834 -0.059416 -0.119636 -0.087696 -1.513201  \n",
       "347  0.994797  0.244490  0.392686 -0.244980  4.024945  2.431384  \n",
       "348  0.784602 -0.134163 -0.228937  0.448984 -0.348608  0.212757  \n",
       "349 -0.215783  1.153468  2.968010  1.083063 -0.241957 -0.681613  \n",
       "350  1.631244  0.628999 -0.233673  0.390213 -0.520131 -1.751054  \n",
       "351 -0.510013 -0.382875 -0.328020 -0.053195  0.050772  0.416897  \n",
       "352 -0.932233  0.208401  0.497495  0.460779  0.066186 -0.304442  \n",
       "353 -0.188151  0.285467  0.888652 -0.951077 -0.418927 -0.168896  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(100, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(100, activation=\"linear\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 876us/step - loss: 1948.4589\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 128.1181\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 88.8762\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 80.2390\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 66.6198\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 57.4152\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 60.0279\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 54.1722\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 52.1461\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.5447\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 67.5550\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.1181\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 52.2236\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 44.6548\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 42.7817\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 42.0153\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 44.7626\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 49.3222\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.6754\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.7238\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 257us/step - loss: 38.0600\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 356us/step - loss: 41.6280\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.9277\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.0234\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.8411\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 52.0469\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 43.9096\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.4476\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 53.2543\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 39.7221\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 59.4782\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 56.2605\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 47.7686\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.3326\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.4455\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 37.1735\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 45.7838\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 39.2213\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 60.4455\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.0697\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.0039\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 30.3006\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.1500\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 35.7341\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.9548\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 37.4288\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 285us/step - loss: 41.7986\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 280us/step - loss: 33.8263\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.9264\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 31.9471\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 33.4890\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.6615\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 41.4484\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.5181\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.5986\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.5741\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 79.7715\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 260us/step - loss: 38.7180\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 32.0940\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 36.3664\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.3905\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 60.1300\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.4864\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.3823\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.8350\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 29.8270\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.4749\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 29.6827\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.7982\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.6343\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.3952\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.3331\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 30.8163\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.0034\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.9197\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.2524\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 28.9998\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 36.5590\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.4379\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.5902\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.0727\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.9897\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 32.9091\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.3779\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.5263\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 30.0344\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.1709\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 29.0719\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 28.8071\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 29.7899\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 35.4944\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.8166\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.7886\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.5469\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.7889\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 198us/step - loss: 31.3752\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.4845\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 26.5650\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.6146\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 169us/step - loss: 45.5747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17e8d978>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15., 31., 38., 20., 21., 29., 12., 24., 20., 25., 14., -1., 36.,\n",
       "        15., 10., 25., 28., 18., 16., 19., 15., 16., 34., 25., 16., -5.,\n",
       "        24., 23.,  6., 19., 26., 19., 19., 16., 25., 41., 17., 21., 17.,\n",
       "        29., 14.,  1., 24., 24., 19., 24.,  9., 11., 19.,  9., 18.,  7.,\n",
       "        26., 26., 23., 20.,  4., 36., 14., 23., 26., 21., 14., 57., 28.,\n",
       "        28., 28., 26., 31., 13., 19., 26., 19., 38., 39., 15., 15., 26.,\n",
       "        26., 32., 17., 19., 23., 13., 17., 13., 21., 23., 19.,  6., -2.,\n",
       "        24., 16., 13., 29., 23., 22., 19., 20., 24., 23.,  5., 11., 21.,\n",
       "        13., 17., 24., 13., 34., 16., 36., 21., 11., 16., 29., 21., 12.,\n",
       "        23., 23., 17., 17., 20.,  9., 22., 19., 21., 12.,  8., -1., 21.,\n",
       "        15., 29., 16., 21., 37., 13., 23., 39., 24., 20., 22., 10., 34.,\n",
       "         5., 26., 24.,  5., 11., 33., 19., 21., 26.]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 921us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.27073428505346"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 706us/step - loss: 1760.3887\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 277.5811\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 100.9235\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 79.3677\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 75.8973\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 72.4150\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 70.8193\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 68.2440\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 68.0854\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 67.4606\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 65.1068\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.6673\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 64.4788\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 63.2633\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 60.5224\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 59.9318\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 58.8030\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.1258\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 56.9975\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 254us/step - loss: 57.8858\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.9244\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.9433\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.2112\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.7421\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 54.7861\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 51.0896\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 254us/step - loss: 49.9537\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 50.2736\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 48.9909\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.8588\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 48.3541\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 46.7549\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 47.2295\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 44.8304\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 45.6344\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.0166\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 44.2040\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 45.8647\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.7281\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 43.3958\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 41.4197\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 41.8528\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 42.8264\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 254us/step - loss: 43.6625\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 40.0365\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.1988\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 40.5747\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.2339\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 37.5195\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.4091\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 37.4265\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 36.2120\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.8986\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.5198\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.2357\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.4851\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.6278\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.1454\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.5664\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.8709\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.5808\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.2101\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.9171\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.7281\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.3776\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.8397\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.2153\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.3057\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.1761\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.6098\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 34.2779\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 31.8772\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.7349\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3384\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5815\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.1777\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.9898\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.4051\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9999\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.1670\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.9974\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.0714\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.2498\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.8394\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9740\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.0878\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.1407\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3477\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5095\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6219\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.4562\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.5692\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2849\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1791\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.2048\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 198us/step - loss: 29.8721\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8218\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5903\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1548\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9869\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0614\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 29.5055\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5028\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 30.5709\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0300\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.0860\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3732\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.5165\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.8941\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.5896\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.7270\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.6553\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.8834\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1059\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7309\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.0744\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.8439\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5343\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.5729\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.6274\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.8377\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1293\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.5730\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.1933\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.2090\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0054\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 29.5563\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.0090\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8857\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.6560\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1594\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6091\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8946\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.7555\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.6098\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.0305\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.1488\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 28.0916\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.7730\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7672\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.1575\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.8545\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.1271\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.2592\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6249\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.9934\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.5515\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.3400\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.3917\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0027\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9999\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.1912\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.9646\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.9698\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.0999\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1932\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9830\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.7343\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.2015\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.7659\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0411\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8176\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.4124\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6186\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3506\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9409\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0526\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1790\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6652\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.4609\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0321\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5495\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.9038\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9714\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.2356\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9012\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2927\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2844\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3524\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.8490\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.8405\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9070\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.9101\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.6598\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1639\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.6309\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.0245\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.3681\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8717\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 26.6757\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.4483\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.4737\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9968\n",
      "Epoch 194/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.4076\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9231\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7220\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5863\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3741\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4518\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5102\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.7868\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8072\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.5621\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.9783\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.8971\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2281\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.1831\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0881\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9714\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4315\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.6003\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7631\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5765\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9006\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9326\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.0418\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9707\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7366\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3032\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.7700\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2143\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6365\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1363\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.5262\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 25.4015\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.9992\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.2946\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.8459\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2074\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5064\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.7544\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8557\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2880\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2947\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.1444\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.5336\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7109\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9550\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.6173\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.6355\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5532\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7837\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.0576\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2726\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9131\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.3279\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.6112\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.2883\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2924\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.3034\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7538\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.3039\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.2506\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0345\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.3087\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.0985\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.5469\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0530\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.3921\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7273\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9463\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2615\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5159\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7737\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.5358\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 25.7285\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.6978\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4127\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4264\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5165\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 29.0313\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.2517\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.4291\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2671\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2151\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.6647\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2543\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.6110\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 24.7488\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1154\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2027\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3722\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.1783\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 25.4053\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.5473\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2093\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.6363\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.8431\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.1632\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.9749\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.9003\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1256\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.5113\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4518\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4978\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.1890\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.6152\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.0473\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.4823\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18633940>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26., 41., 39., 14., 27., 40., 18., 20., 25., 21., 26., 10., 38.,\n",
       "        24., 16., 34., 34., 29., 25., 25., 25., 27., 46., 30., 24.,  5.,\n",
       "        22., 20., 17., 17., 31., 26., 28., 24., 34., 31., 24., 27., 21.,\n",
       "        41., 23., 12., 32., 29., 24., 25., 22., 23., 29., 22., 25.,  5.,\n",
       "        30., 30., 25., 29.,  8., 34., 11., 27., 34., 25., 20., 46., 35.,\n",
       "        39., 34., 32., 32., 23., 25., 27., 15., 38., 42., 21., 22., 35.,\n",
       "        34., 38., 24., 24., 27., 25., 28., 18., 28., 27., 26., 18.,  3.,\n",
       "        25., 24., 26., 38., 26., 22., 27., 25., 28., 26., 12., 20., 20.,\n",
       "        23., 24., 31.,  6., 35., 23., 37., 25., 19., 14., 36., 26., 23.,\n",
       "        30., 27., 22., 24., 25., 21., 26., 30., 26., 18., 12.,  9., 27.,\n",
       "        23., 22., 23., 20., 39., 23., 30., 39., 32., 28., 30., 19., 40.,\n",
       "        12., 36., 29., 18., 17., 45., 16., 18., 35.]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.741849397358145"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 706us/step - loss: 10009.1847\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 996.7487\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 130.4134\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 106.3297\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 92.8392\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 84.9679\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 81.5539\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 79.6200\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 78.4645\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 77.7245\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 76.8865\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 75.9093\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 78.55 - 0s 169us/step - loss: 75.5060\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 74.9645\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 73.8524\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 73.2771\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 72.5290\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 71.6938\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 71.3705\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 70.6930\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 69.7130\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 69.0400\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 68.7580\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 68.1168\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 229us/step - loss: 67.6936\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 66.6212\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 65.9592\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 65.1860\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 64.2114\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 63.0735\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.9837\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 62.6280\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 61.2406\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 60.4786\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 59.7936\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.9254\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 58.8927\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 58.3600\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 57.5727\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 57.8810\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 55.5634\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 54.8718\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 54.1011\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 54.2861\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 53.1801\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.1986\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 52.6182\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.4172\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.8851\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 49.0141\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.3222\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 48.5413\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 47.1651\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.8607\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.9090\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.7734\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.7687\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 45.6954\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 45.7878\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 43.8606\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 43.0538\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.0617\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.3239\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 41.2607\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 39.4762\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 40.4754\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 39.6169\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.3539\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.6324\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.7055\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.0188\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.9323\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.8676\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.2105\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.0420\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.7075\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.0604\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.0426\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.0936\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.7490\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.2734\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 232us/step - loss: 36.0579\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.0783\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.7437\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.8905\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.4567\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.1853\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.1953\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.2399\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.6510\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 32.0832\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.8271\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5116\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7291\n",
      "Epoch 95/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.2423\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 169us/step - loss: 32.5276\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.6103\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.8327\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6957\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1433\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3652\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.0689\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5085\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.1872\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.9602\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 34.5480\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.7082\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1503\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.1440\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7082\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.1613\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.4680\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.8066\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.9177\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.9040\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.6534\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.4409\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.5200\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.7183\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5044\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.1002\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.1473\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9183\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.8929\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0472\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.9760\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2180\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6098\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.6553\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0864\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0211\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 64.17 - 0s 113us/step - loss: 28.7607\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3501\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7265\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9199\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8238\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.1166\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.5072\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.9267\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.3968\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.7254\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0978\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.2290\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2794\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.4209\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2590\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.1255\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6263\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.5508\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1749\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0744\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.1625\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.5822\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 25.7637\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.5821\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2590\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.5025\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0606\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.7017\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.3056\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.2584\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8131\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.8768\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.4515\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9829\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2890\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.2806\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 25.8157\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5479\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.6579\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 24.8016\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.5448\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8473\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8033\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.1039\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.2150\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.0717\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9945\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.7587\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4834\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.7389\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.7756\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9390\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.8268\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.9947\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.3921\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3471\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6659\n",
      "Epoch 189/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2835\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 24.9151\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6701\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.3743\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.4231\n",
      "Epoch 194/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.4229\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.1674\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0488\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.7090\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5115\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.4852\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.7328\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.8214\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5514\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4568\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3846\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.1898\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.2229\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8969\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8851\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.4939\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8681\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3740\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.5971\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.7302\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.5164\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.6758\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.0673\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8935\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.1438\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.5931\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.2258\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.0382\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.3861\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.5891\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.1361\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.4410\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.5718\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.7200\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.2561\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.9987\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.1748\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.5831\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.9885\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.1989\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.1178\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.9759\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.9446\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.0930\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.5053\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.0555\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.6412\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6702\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.0949\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.2611\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.3697\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.6445\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.2205\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.0820\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.8759\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.5822\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.5548\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.4904\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.0769\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.0699\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.6509\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.3435\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.6119\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.3384\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 21.4331\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.8062\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.0600\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.2846\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.1847\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.5328\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.0805\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.2816\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.6945\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.0594\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.0383\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 23.8917\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.4377\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.7570\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 23.1854\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.3284\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.5786\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.7155\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.6308\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.1930\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.7010\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 20.9014\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.4913\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.3572\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.4441\n",
      "Epoch 283/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 22.8075\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 113us/step - loss: 21.8152\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.3760\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 22.0551\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 22.0087\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 254us/step - loss: 20.6172\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 20.3559\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.0704\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.2829\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.2559\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 20.8432\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 21.5409\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.4613\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 23.0574\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 22.8173\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 20.6977\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 20.8593\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 21.0416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18633b38>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23., 37., 37., 10., 21., 38., 19., 13., 23., 18., 19.,  5., 34.,\n",
       "        18., 10., 28., 31., 25., 20., 23., 22., 21., 42., 27., 25.,  1.,\n",
       "        18., 15., 10., 15., 30., 21., 25., 18., 29., 45., 23., 25., 17.,\n",
       "        35., 20.,  7., 28., 27., 21., 21., 15., 16., 27., 16., 20., 18.,\n",
       "        28., 29., 19., 24., 16., 35., 10., 23., 30., 23., 17., 63., 32.,\n",
       "        31., 32., 29., 30., 21., 20., 24., 16., 37., 39., 16., 15., 33.,\n",
       "        29., 33., 17., 20., 25., 20., 19., 14., 24., 26., 24., 12.,  1.,\n",
       "        22., 23., 19., 35., 25., 17., 21., 22., 25., 23., 15., 14., 14.,\n",
       "        20., 20., 30.,  5., 31., 24., 34., 24., 20., 20., 33., 24., 17.,\n",
       "        26., 22., 17., 19., 22., 14., 24., 25., 22., 14., 13.,  3., 24.,\n",
       "        17.,  9., 19., 15., 35., 21., 26., 38., 30., 22., 27., 14., 37.,\n",
       "        16., 31., 29., 12., 14., 42., 12., 11., 31.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.10125039753161"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.218296</td>\n",
       "      <td>0.336704</td>\n",
       "      <td>-0.426186</td>\n",
       "      <td>-0.886752</td>\n",
       "      <td>0.380047</td>\n",
       "      <td>-1.187510</td>\n",
       "      <td>-0.391259</td>\n",
       "      <td>0.125752</td>\n",
       "      <td>-0.172811</td>\n",
       "      <td>-1.267331</td>\n",
       "      <td>-1.771462</td>\n",
       "      <td>-0.501306</td>\n",
       "      <td>0.296134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410900</td>\n",
       "      <td>-1.292493</td>\n",
       "      <td>1.055464</td>\n",
       "      <td>-1.463581</td>\n",
       "      <td>-0.607597</td>\n",
       "      <td>-0.256340</td>\n",
       "      <td>0.067925</td>\n",
       "      <td>1.176856</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>-0.220818</td>\n",
       "      <td>-0.498881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.551091</td>\n",
       "      <td>0.086810</td>\n",
       "      <td>-1.064214</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>-0.056779</td>\n",
       "      <td>-0.404564</td>\n",
       "      <td>-0.352776</td>\n",
       "      <td>-0.668523</td>\n",
       "      <td>1.635779</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>-0.914374</td>\n",
       "      <td>-0.289210</td>\n",
       "      <td>0.679937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>1.007146</td>\n",
       "      <td>-2.389351</td>\n",
       "      <td>0.140114</td>\n",
       "      <td>-0.508026</td>\n",
       "      <td>0.103962</td>\n",
       "      <td>0.610198</td>\n",
       "      <td>-0.978994</td>\n",
       "      <td>-1.487230</td>\n",
       "      <td>-1.857298</td>\n",
       "      <td>-0.362586</td>\n",
       "      <td>0.584306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115420</td>\n",
       "      <td>-0.424497</td>\n",
       "      <td>-0.599070</td>\n",
       "      <td>-0.126995</td>\n",
       "      <td>-0.378454</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>-0.435759</td>\n",
       "      <td>-0.986912</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>-1.001963</td>\n",
       "      <td>0.307408</td>\n",
       "      <td>-0.171837</td>\n",
       "      <td>0.416459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.568687</td>\n",
       "      <td>-0.017722</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-0.158364</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.930286</td>\n",
       "      <td>-0.793835</td>\n",
       "      <td>0.195159</td>\n",
       "      <td>-0.394252</td>\n",
       "      <td>0.754895</td>\n",
       "      <td>-0.054449</td>\n",
       "      <td>3.939962</td>\n",
       "      <td>-0.256343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.447170</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>2.683609</td>\n",
       "      <td>1.917981</td>\n",
       "      <td>-0.119569</td>\n",
       "      <td>0.329389</td>\n",
       "      <td>-0.053554</td>\n",
       "      <td>-0.408277</td>\n",
       "      <td>3.289767</td>\n",
       "      <td>0.921860</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.310273</td>\n",
       "      <td>1.934371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.967308</td>\n",
       "      <td>0.106104</td>\n",
       "      <td>1.077655</td>\n",
       "      <td>-1.022205</td>\n",
       "      <td>0.391836</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>-0.112093</td>\n",
       "      <td>0.631071</td>\n",
       "      <td>-0.554251</td>\n",
       "      <td>1.049112</td>\n",
       "      <td>0.595754</td>\n",
       "      <td>-0.264482</td>\n",
       "      <td>0.098367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.446440</td>\n",
       "      <td>-1.186458</td>\n",
       "      <td>-0.223272</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>-0.011630</td>\n",
       "      <td>-0.288014</td>\n",
       "      <td>-0.546646</td>\n",
       "      <td>0.685738</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>-0.260171</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.977767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.743204</td>\n",
       "      <td>-0.016091</td>\n",
       "      <td>-1.406325</td>\n",
       "      <td>0.539970</td>\n",
       "      <td>0.063506</td>\n",
       "      <td>0.855115</td>\n",
       "      <td>-0.100882</td>\n",
       "      <td>1.019661</td>\n",
       "      <td>-1.045355</td>\n",
       "      <td>0.728018</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>3.768397</td>\n",
       "      <td>-0.865074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>-1.128775</td>\n",
       "      <td>0.598142</td>\n",
       "      <td>-0.700726</td>\n",
       "      <td>-0.792189</td>\n",
       "      <td>2.491377</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>-1.475142</td>\n",
       "      <td>0.964716</td>\n",
       "      <td>0.580170</td>\n",
       "      <td>-0.526890</td>\n",
       "      <td>3.695478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.109496</td>\n",
       "      <td>-0.463290</td>\n",
       "      <td>3.319455</td>\n",
       "      <td>2.483666</td>\n",
       "      <td>-0.436228</td>\n",
       "      <td>0.296471</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>-1.359378</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>-1.069896</td>\n",
       "      <td>-0.435476</td>\n",
       "      <td>0.335398</td>\n",
       "      <td>0.233901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.563461</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.916949</td>\n",
       "      <td>0.047773</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.193161</td>\n",
       "      <td>-0.672598</td>\n",
       "      <td>-0.635800</td>\n",
       "      <td>1.411689</td>\n",
       "      <td>-0.034218</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.644681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.227955</td>\n",
       "      <td>0.397238</td>\n",
       "      <td>-1.018147</td>\n",
       "      <td>-0.282160</td>\n",
       "      <td>0.326452</td>\n",
       "      <td>2.019800</td>\n",
       "      <td>2.784529</td>\n",
       "      <td>3.627855</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>-0.305158</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>-0.827660</td>\n",
       "      <td>-0.294085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.184482</td>\n",
       "      <td>0.636922</td>\n",
       "      <td>-1.831814</td>\n",
       "      <td>0.768341</td>\n",
       "      <td>0.404875</td>\n",
       "      <td>3.168186</td>\n",
       "      <td>1.429387</td>\n",
       "      <td>3.382434</td>\n",
       "      <td>0.488574</td>\n",
       "      <td>-0.065362</td>\n",
       "      <td>-0.991493</td>\n",
       "      <td>-0.928332</td>\n",
       "      <td>-0.957187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.770244</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.887590</td>\n",
       "      <td>-0.119189</td>\n",
       "      <td>-0.104687</td>\n",
       "      <td>-0.106483</td>\n",
       "      <td>0.990349</td>\n",
       "      <td>-0.165131</td>\n",
       "      <td>1.597335</td>\n",
       "      <td>-1.654309</td>\n",
       "      <td>0.477349</td>\n",
       "      <td>-0.238305</td>\n",
       "      <td>0.806332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.049209</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>-0.191747</td>\n",
       "      <td>0.451898</td>\n",
       "      <td>0.354904</td>\n",
       "      <td>0.686849</td>\n",
       "      <td>-0.510539</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>0.264772</td>\n",
       "      <td>-0.954217</td>\n",
       "      <td>0.657336</td>\n",
       "      <td>4.091099</td>\n",
       "      <td>-0.468007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.686215</td>\n",
       "      <td>-0.075888</td>\n",
       "      <td>1.192591</td>\n",
       "      <td>1.485459</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>-0.011337</td>\n",
       "      <td>-0.086963</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>1.270550</td>\n",
       "      <td>0.603574</td>\n",
       "      <td>-0.282384</td>\n",
       "      <td>-0.934310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.784367</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>-0.780065</td>\n",
       "      <td>-0.207366</td>\n",
       "      <td>-0.016780</td>\n",
       "      <td>-0.963678</td>\n",
       "      <td>-0.534382</td>\n",
       "      <td>-1.264696</td>\n",
       "      <td>-0.251943</td>\n",
       "      <td>-0.784355</td>\n",
       "      <td>0.594379</td>\n",
       "      <td>-0.225215</td>\n",
       "      <td>-0.516801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.717640</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.989287</td>\n",
       "      <td>-2.451317</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.077713</td>\n",
       "      <td>0.384208</td>\n",
       "      <td>0.270853</td>\n",
       "      <td>0.533549</td>\n",
       "      <td>-0.278017</td>\n",
       "      <td>-0.256943</td>\n",
       "      <td>-0.159516</td>\n",
       "      <td>1.272878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.624073</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.160763</td>\n",
       "      <td>0.031376</td>\n",
       "      <td>-0.234554</td>\n",
       "      <td>-0.241636</td>\n",
       "      <td>0.243423</td>\n",
       "      <td>-0.493480</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.280933</td>\n",
       "      <td>-0.702675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.715731</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.572144</td>\n",
       "      <td>-1.919670</td>\n",
       "      <td>0.174060</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>0.208287</td>\n",
       "      <td>0.176057</td>\n",
       "      <td>0.658007</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>-0.017581</td>\n",
       "      <td>-0.200698</td>\n",
       "      <td>0.979237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.421298</td>\n",
       "      <td>-1.406029</td>\n",
       "      <td>-0.310320</td>\n",
       "      <td>0.269410</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.218211</td>\n",
       "      <td>-0.958624</td>\n",
       "      <td>0.714248</td>\n",
       "      <td>-0.279995</td>\n",
       "      <td>-0.538967</td>\n",
       "      <td>-1.754797</td>\n",
       "      <td>-0.429055</td>\n",
       "      <td>-0.052801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.115556</td>\n",
       "      <td>-0.540635</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>-0.074706</td>\n",
       "      <td>-0.683186</td>\n",
       "      <td>-0.629395</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>-1.539723</td>\n",
       "      <td>-0.511106</td>\n",
       "      <td>-0.225811</td>\n",
       "      <td>0.887479</td>\n",
       "      <td>-0.116359</td>\n",
       "      <td>-0.620534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.810639</td>\n",
       "      <td>0.069947</td>\n",
       "      <td>-0.996857</td>\n",
       "      <td>1.638662</td>\n",
       "      <td>0.107503</td>\n",
       "      <td>-0.951199</td>\n",
       "      <td>-0.879962</td>\n",
       "      <td>-0.084254</td>\n",
       "      <td>-2.660340</td>\n",
       "      <td>-0.417255</td>\n",
       "      <td>-0.456178</td>\n",
       "      <td>-0.660758</td>\n",
       "      <td>0.809331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.105027</td>\n",
       "      <td>-0.365970</td>\n",
       "      <td>1.965839</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>-0.438936</td>\n",
       "      <td>-0.648371</td>\n",
       "      <td>0.423267</td>\n",
       "      <td>-1.329676</td>\n",
       "      <td>-1.265713</td>\n",
       "      <td>0.452782</td>\n",
       "      <td>-0.624106</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>-0.248861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.572685</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>2.236526</td>\n",
       "      <td>2.417969</td>\n",
       "      <td>-0.146365</td>\n",
       "      <td>0.462122</td>\n",
       "      <td>0.541046</td>\n",
       "      <td>-0.676499</td>\n",
       "      <td>0.307313</td>\n",
       "      <td>1.529051</td>\n",
       "      <td>0.819056</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>-0.124282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.492915</td>\n",
       "      <td>-0.203387</td>\n",
       "      <td>1.777558</td>\n",
       "      <td>-1.572743</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>-0.118156</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.826970</td>\n",
       "      <td>2.020085</td>\n",
       "      <td>-3.937981</td>\n",
       "      <td>-0.269015</td>\n",
       "      <td>1.479730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.452100</td>\n",
       "      <td>-1.043974</td>\n",
       "      <td>0.526998</td>\n",
       "      <td>-0.762193</td>\n",
       "      <td>0.790775</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>-0.189807</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>-0.103903</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>-0.112098</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>-0.970029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.751558</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>0.426210</td>\n",
       "      <td>-1.772618</td>\n",
       "      <td>0.183135</td>\n",
       "      <td>0.663843</td>\n",
       "      <td>0.573432</td>\n",
       "      <td>0.576692</td>\n",
       "      <td>-0.106322</td>\n",
       "      <td>-0.719618</td>\n",
       "      <td>-0.340360</td>\n",
       "      <td>-0.287602</td>\n",
       "      <td>0.048091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.341859</td>\n",
       "      <td>1.772573</td>\n",
       "      <td>-1.265405</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>-0.069995</td>\n",
       "      <td>0.509438</td>\n",
       "      <td>-1.132676</td>\n",
       "      <td>-0.942075</td>\n",
       "      <td>1.348960</td>\n",
       "      <td>-0.156008</td>\n",
       "      <td>-0.450447</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>0.098929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.826799</td>\n",
       "      <td>0.112487</td>\n",
       "      <td>0.247452</td>\n",
       "      <td>0.055284</td>\n",
       "      <td>0.105849</td>\n",
       "      <td>-1.312153</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>0.206861</td>\n",
       "      <td>-2.599742</td>\n",
       "      <td>-0.679201</td>\n",
       "      <td>-0.256533</td>\n",
       "      <td>-0.516969</td>\n",
       "      <td>0.534755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.641654</td>\n",
       "      <td>-0.038538</td>\n",
       "      <td>-0.551487</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.734961</td>\n",
       "      <td>-0.838139</td>\n",
       "      <td>-0.706664</td>\n",
       "      <td>-1.151996</td>\n",
       "      <td>-0.788001</td>\n",
       "      <td>1.688322</td>\n",
       "      <td>-0.269644</td>\n",
       "      <td>-0.713522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.079148</td>\n",
       "      <td>-1.116960</td>\n",
       "      <td>0.596164</td>\n",
       "      <td>-0.749896</td>\n",
       "      <td>-0.961395</td>\n",
       "      <td>2.613610</td>\n",
       "      <td>0.045463</td>\n",
       "      <td>-1.388278</td>\n",
       "      <td>1.004437</td>\n",
       "      <td>1.593126</td>\n",
       "      <td>-0.459578</td>\n",
       "      <td>-1.373151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-0.813866</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>1.064336</td>\n",
       "      <td>-0.424341</td>\n",
       "      <td>0.102291</td>\n",
       "      <td>0.844122</td>\n",
       "      <td>1.986576</td>\n",
       "      <td>1.953437</td>\n",
       "      <td>0.265062</td>\n",
       "      <td>-1.395970</td>\n",
       "      <td>0.522529</td>\n",
       "      <td>-0.342571</td>\n",
       "      <td>-0.815108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-0.921492</td>\n",
       "      <td>0.112342</td>\n",
       "      <td>-0.365070</td>\n",
       "      <td>-0.821385</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>-0.452206</td>\n",
       "      <td>-0.469554</td>\n",
       "      <td>-0.391193</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>-0.702808</td>\n",
       "      <td>0.813267</td>\n",
       "      <td>-0.251879</td>\n",
       "      <td>-0.768778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.991131</td>\n",
       "      <td>3.384534</td>\n",
       "      <td>0.421641</td>\n",
       "      <td>-0.237522</td>\n",
       "      <td>-1.409536</td>\n",
       "      <td>-0.691933</td>\n",
       "      <td>-0.216972</td>\n",
       "      <td>0.564823</td>\n",
       "      <td>0.417845</td>\n",
       "      <td>0.566093</td>\n",
       "      <td>0.646313</td>\n",
       "      <td>-0.044244</td>\n",
       "      <td>-0.164187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.569081</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>-1.287219</td>\n",
       "      <td>0.513402</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>0.189279</td>\n",
       "      <td>-0.924604</td>\n",
       "      <td>-0.714949</td>\n",
       "      <td>1.490871</td>\n",
       "      <td>0.395190</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.270665</td>\n",
       "      <td>0.437375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.423465</td>\n",
       "      <td>-1.404566</td>\n",
       "      <td>-0.327444</td>\n",
       "      <td>0.281870</td>\n",
       "      <td>1.136365</td>\n",
       "      <td>1.723241</td>\n",
       "      <td>-1.725096</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>-0.753861</td>\n",
       "      <td>-0.512377</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>-0.252973</td>\n",
       "      <td>0.189492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.356470</td>\n",
       "      <td>1.123745</td>\n",
       "      <td>-0.933219</td>\n",
       "      <td>0.525810</td>\n",
       "      <td>-0.889419</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.884598</td>\n",
       "      <td>-0.494448</td>\n",
       "      <td>1.574206</td>\n",
       "      <td>-0.295988</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>-0.094441</td>\n",
       "      <td>0.154127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.824148</td>\n",
       "      <td>0.085650</td>\n",
       "      <td>-0.076755</td>\n",
       "      <td>0.455379</td>\n",
       "      <td>0.246723</td>\n",
       "      <td>-0.323226</td>\n",
       "      <td>-0.679215</td>\n",
       "      <td>0.111718</td>\n",
       "      <td>-2.984972</td>\n",
       "      <td>-1.232753</td>\n",
       "      <td>2.838079</td>\n",
       "      <td>-0.386188</td>\n",
       "      <td>1.017576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-0.127880</td>\n",
       "      <td>-0.422532</td>\n",
       "      <td>0.152169</td>\n",
       "      <td>-1.090901</td>\n",
       "      <td>-0.301478</td>\n",
       "      <td>0.352250</td>\n",
       "      <td>-0.072848</td>\n",
       "      <td>-0.811853</td>\n",
       "      <td>-0.211932</td>\n",
       "      <td>-1.731636</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>-0.048400</td>\n",
       "      <td>0.811001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.146226</td>\n",
       "      <td>-0.384283</td>\n",
       "      <td>-0.986603</td>\n",
       "      <td>0.347412</td>\n",
       "      <td>-0.335649</td>\n",
       "      <td>0.549421</td>\n",
       "      <td>-1.125597</td>\n",
       "      <td>-1.430948</td>\n",
       "      <td>0.742985</td>\n",
       "      <td>-1.589639</td>\n",
       "      <td>0.149407</td>\n",
       "      <td>-0.093774</td>\n",
       "      <td>-0.686834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.472153</td>\n",
       "      <td>-0.972228</td>\n",
       "      <td>-0.133663</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>0.740923</td>\n",
       "      <td>0.531293</td>\n",
       "      <td>-0.840607</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>-0.384282</td>\n",
       "      <td>-0.656741</td>\n",
       "      <td>-1.713876</td>\n",
       "      <td>-0.325242</td>\n",
       "      <td>-0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.456135</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>2.599987</td>\n",
       "      <td>2.013634</td>\n",
       "      <td>-0.074048</td>\n",
       "      <td>0.699033</td>\n",
       "      <td>-0.367732</td>\n",
       "      <td>-0.427186</td>\n",
       "      <td>3.169238</td>\n",
       "      <td>0.951461</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>1.829259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.199952</td>\n",
       "      <td>1.533377</td>\n",
       "      <td>-0.834032</td>\n",
       "      <td>0.360015</td>\n",
       "      <td>-0.631507</td>\n",
       "      <td>-0.470706</td>\n",
       "      <td>2.482422</td>\n",
       "      <td>-0.134929</td>\n",
       "      <td>-1.467272</td>\n",
       "      <td>1.261561</td>\n",
       "      <td>1.124268</td>\n",
       "      <td>-0.344816</td>\n",
       "      <td>-1.194008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.133477</td>\n",
       "      <td>-0.373511</td>\n",
       "      <td>0.864971</td>\n",
       "      <td>-2.012486</td>\n",
       "      <td>-0.053010</td>\n",
       "      <td>1.852188</td>\n",
       "      <td>-0.642114</td>\n",
       "      <td>-0.699432</td>\n",
       "      <td>-0.825240</td>\n",
       "      <td>-2.137400</td>\n",
       "      <td>0.036622</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>1.373298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>-0.674742</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>-0.674479</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>-0.423200</td>\n",
       "      <td>-1.656176</td>\n",
       "      <td>-0.758245</td>\n",
       "      <td>-0.422877</td>\n",
       "      <td>0.556423</td>\n",
       "      <td>-0.095854</td>\n",
       "      <td>-0.889029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.035970</td>\n",
       "      <td>-0.467859</td>\n",
       "      <td>-1.224252</td>\n",
       "      <td>0.653701</td>\n",
       "      <td>0.116760</td>\n",
       "      <td>2.371741</td>\n",
       "      <td>0.350227</td>\n",
       "      <td>-0.105625</td>\n",
       "      <td>-2.684684</td>\n",
       "      <td>0.362394</td>\n",
       "      <td>0.224631</td>\n",
       "      <td>-0.483569</td>\n",
       "      <td>3.346229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>-0.231514</td>\n",
       "      <td>-0.408073</td>\n",
       "      <td>-0.620177</td>\n",
       "      <td>0.326987</td>\n",
       "      <td>-0.316636</td>\n",
       "      <td>-1.566828</td>\n",
       "      <td>-0.924376</td>\n",
       "      <td>-0.802616</td>\n",
       "      <td>0.570587</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>-0.615597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.734757</td>\n",
       "      <td>-0.019290</td>\n",
       "      <td>-1.589464</td>\n",
       "      <td>0.786915</td>\n",
       "      <td>0.188284</td>\n",
       "      <td>1.379813</td>\n",
       "      <td>-1.282396</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>-0.042861</td>\n",
       "      <td>0.826787</td>\n",
       "      <td>0.598042</td>\n",
       "      <td>3.973727</td>\n",
       "      <td>-1.264901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-1.062561</td>\n",
       "      <td>0.175754</td>\n",
       "      <td>-0.150195</td>\n",
       "      <td>1.450560</td>\n",
       "      <td>0.300127</td>\n",
       "      <td>-0.997197</td>\n",
       "      <td>-1.044866</td>\n",
       "      <td>1.169793</td>\n",
       "      <td>0.471431</td>\n",
       "      <td>-1.895855</td>\n",
       "      <td>0.366942</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.593682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.077830</td>\n",
       "      <td>-0.320047</td>\n",
       "      <td>0.419044</td>\n",
       "      <td>-1.408831</td>\n",
       "      <td>-0.406938</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>-0.651299</td>\n",
       "      <td>-0.127834</td>\n",
       "      <td>-0.059416</td>\n",
       "      <td>-0.119636</td>\n",
       "      <td>-0.087696</td>\n",
       "      <td>-1.513201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.424047</td>\n",
       "      <td>-1.335482</td>\n",
       "      <td>-0.047273</td>\n",
       "      <td>-0.052808</td>\n",
       "      <td>-0.885869</td>\n",
       "      <td>-0.821740</td>\n",
       "      <td>-0.321385</td>\n",
       "      <td>0.994797</td>\n",
       "      <td>0.244490</td>\n",
       "      <td>0.392686</td>\n",
       "      <td>-0.244980</td>\n",
       "      <td>4.024945</td>\n",
       "      <td>2.431384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1.426656</td>\n",
       "      <td>-1.357723</td>\n",
       "      <td>-0.304057</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>-0.286396</td>\n",
       "      <td>0.040887</td>\n",
       "      <td>-0.919443</td>\n",
       "      <td>0.784602</td>\n",
       "      <td>-0.134163</td>\n",
       "      <td>-0.228937</td>\n",
       "      <td>0.448984</td>\n",
       "      <td>-0.348608</td>\n",
       "      <td>0.212757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.421858</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>-0.205606</td>\n",
       "      <td>0.990012</td>\n",
       "      <td>-0.147521</td>\n",
       "      <td>-0.228645</td>\n",
       "      <td>-1.006426</td>\n",
       "      <td>-0.215783</td>\n",
       "      <td>1.153468</td>\n",
       "      <td>2.968010</td>\n",
       "      <td>1.083063</td>\n",
       "      <td>-0.241957</td>\n",
       "      <td>-0.681613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.791279</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.351439</td>\n",
       "      <td>1.390501</td>\n",
       "      <td>-0.051356</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>1.300206</td>\n",
       "      <td>1.631244</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>-0.233673</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>-0.520131</td>\n",
       "      <td>-1.751054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1.525218</td>\n",
       "      <td>-0.541349</td>\n",
       "      <td>0.094171</td>\n",
       "      <td>-0.153951</td>\n",
       "      <td>4.182298</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>-0.510013</td>\n",
       "      <td>-0.382875</td>\n",
       "      <td>-0.328020</td>\n",
       "      <td>-0.053195</td>\n",
       "      <td>0.050772</td>\n",
       "      <td>0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.400854</td>\n",
       "      <td>-0.247820</td>\n",
       "      <td>1.234477</td>\n",
       "      <td>-1.592875</td>\n",
       "      <td>-0.061667</td>\n",
       "      <td>0.427942</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>-0.932233</td>\n",
       "      <td>0.208401</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0.460779</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>-0.304442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.944012</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>-0.494481</td>\n",
       "      <td>-0.667725</td>\n",
       "      <td>0.048722</td>\n",
       "      <td>-1.041966</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>-0.188151</td>\n",
       "      <td>0.285467</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>-0.951077</td>\n",
       "      <td>-0.418927</td>\n",
       "      <td>-0.168896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -1.218296  0.336704 -0.426186 -0.886752  0.380047 -1.187510 -0.391259   \n",
       "1    1.410900 -1.292493  1.055464 -1.463581 -0.607597 -0.256340  0.067925   \n",
       "2   -0.551091  0.086810 -1.064214  0.249742 -0.056779 -0.404564 -0.352776   \n",
       "3   -0.580706  0.126584  1.007146 -2.389351  0.140114 -0.508026  0.103962   \n",
       "4   -0.115420 -0.424497 -0.599070 -0.126995 -0.378454  0.132858 -0.435759   \n",
       "5   -0.568687 -0.017722 -0.741355 -0.158364  0.000028 -0.930286 -0.793835   \n",
       "6   -0.447170  0.045592  2.683609  1.917981 -0.119569  0.329389 -0.053554   \n",
       "7   -0.967308  0.106104  1.077655 -1.022205  0.391836  0.588200 -0.112093   \n",
       "8    1.446440 -1.186458 -0.223272  0.184505 -0.011630 -0.288014 -0.546646   \n",
       "9   -0.743204 -0.016091 -1.406325  0.539970  0.063506  0.855115 -0.100882   \n",
       "10   0.011236 -0.053868 -1.128775  0.598142 -0.700726 -0.792189  2.491377   \n",
       "11  -0.109496 -0.463290  3.319455  2.483666 -0.436228  0.296471  0.442018   \n",
       "12  -0.563461  0.004313 -0.916949  0.047773  0.015107  0.193161 -0.672598   \n",
       "13  -1.227955  0.397238 -1.018147 -0.282160  0.326452  2.019800  2.784529   \n",
       "14  -1.184482  0.636922 -1.831814  0.768341  0.404875  3.168186  1.429387   \n",
       "15  -0.770244 -0.004625 -0.887590 -0.119189 -0.104687 -0.106483  0.990349   \n",
       "16  -1.049209  0.245458 -0.191747  0.451898  0.354904  0.686849 -0.510539   \n",
       "17  -0.686215 -0.075888  1.192591  1.485459  0.039956 -0.011337 -0.086963   \n",
       "18  -0.784367  0.049567 -0.780065 -0.207366 -0.016780 -0.963678 -0.534382   \n",
       "19  -0.717640 -0.008363  0.989287 -2.451317  0.204783  0.077713  0.384208   \n",
       "20  -0.624073  0.068307  0.862734  0.160763  0.031376 -0.234554 -0.241636   \n",
       "21  -0.715731 -0.050616  0.572144 -1.919670  0.174060 -0.069824  0.208287   \n",
       "22   1.421298 -1.406029 -0.310320  0.269410  0.025199  0.218211 -0.958624   \n",
       "23   0.115556 -0.540635 -0.533333 -0.074706 -0.683186 -0.629395  0.157352   \n",
       "24  -0.810639  0.069947 -0.996857  1.638662  0.107503 -0.951199 -0.879962   \n",
       "25  -0.105027 -0.365970  1.965839  0.244274 -0.438936 -0.648371  0.423267   \n",
       "26  -0.572685 -0.102770  2.236526  2.417969 -0.146365  0.462122  0.541046   \n",
       "27  -0.492915 -0.203387  1.777558 -1.572743  0.071259 -0.118156  0.251742   \n",
       "28   1.452100 -1.043974  0.526998 -0.762193  0.790775  0.227564 -0.189807   \n",
       "29  -0.751558  0.126659  0.426210 -1.772618  0.183135  0.663843  0.573432   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324 -0.341859  1.772573 -1.265405  0.645878 -0.069995  0.509438 -1.132676   \n",
       "325 -0.826799  0.112487  0.247452  0.055284  0.105849 -1.312153  0.193734   \n",
       "326 -0.641654 -0.038538 -0.551487 -0.429577 -0.006266 -0.734961 -0.838139   \n",
       "327  0.027163  0.079148 -1.116960  0.596164 -0.749896 -0.961395  2.613610   \n",
       "328 -0.813866  0.015304  1.064336 -0.424341  0.102291  0.844122  1.986576   \n",
       "329 -0.921492  0.112342 -0.365070 -0.821385  0.201869 -0.452206 -0.469554   \n",
       "330  1.991131  3.384534  0.421641 -0.237522 -1.409536 -0.691933 -0.216972   \n",
       "331 -0.569081 -0.093427 -1.287219  0.513402 -0.005301  0.189279 -0.924604   \n",
       "332  1.423465 -1.404566 -0.327444  0.281870  1.136365  1.723241 -1.725096   \n",
       "333  0.356470  1.123745 -0.933219  0.525810 -0.889419  0.999575  1.884598   \n",
       "334 -0.824148  0.085650 -0.076755  0.455379  0.246723 -0.323226 -0.679215   \n",
       "335 -0.127880 -0.422532  0.152169 -1.090901 -0.301478  0.352250 -0.072848   \n",
       "336 -0.146226 -0.384283 -0.986603  0.347412 -0.335649  0.549421 -1.125597   \n",
       "337  1.472153 -0.972228 -0.133663  0.082710  0.740923  0.531293 -0.840607   \n",
       "338 -0.456135 -0.040692  2.599987  2.013634 -0.074048  0.699033 -0.367732   \n",
       "339  0.199952  1.533377 -0.834032  0.360015 -0.631507 -0.470706  2.482422   \n",
       "340 -0.133477 -0.373511  0.864971 -2.012486 -0.053010  1.852188 -0.642114   \n",
       "341  0.195446  0.093291 -0.674742  0.154730 -0.674479  0.050682 -0.423200   \n",
       "342 -0.035970 -0.467859 -1.224252  0.653701  0.116760  2.371741  0.350227   \n",
       "343  0.197936  0.174806 -0.231514 -0.408073 -0.620177  0.326987 -0.316636   \n",
       "344 -0.734757 -0.019290 -1.589464  0.786915  0.188284  1.379813 -1.282396   \n",
       "345 -1.062561  0.175754 -0.150195  1.450560  0.300127 -0.997197 -1.044866   \n",
       "346 -0.077830 -0.320047  0.419044 -1.408831 -0.406938  0.525774  0.850306   \n",
       "347  1.424047 -1.335482 -0.047273 -0.052808 -0.885869 -0.821740 -0.321385   \n",
       "348  1.426656 -1.357723 -0.304057  0.266019 -0.286396  0.040887 -0.919443   \n",
       "349 -0.421858  0.103611 -0.205606  0.990012 -0.147521 -0.228645 -1.006426   \n",
       "350 -0.791279  0.004316 -0.351439  1.390501 -0.051356  0.442421  1.300206   \n",
       "351  1.525218 -0.541349  0.094171 -0.153951  4.182298  0.944707  0.100574   \n",
       "352 -0.400854 -0.247820  1.234477 -1.592875 -0.061667  0.427942  0.017642   \n",
       "353 -0.944012  0.158801 -0.494481 -0.667725  0.048722 -1.041966  0.612755   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.125752 -0.172811 -1.267331 -1.771462 -0.501306  0.296134  \n",
       "1    1.176856 -0.012022  0.035788  0.513550 -0.220818 -0.498881  \n",
       "2   -0.668523  1.635779  0.115754 -0.914374 -0.289210  0.679937  \n",
       "3    0.610198 -0.978994 -1.487230 -1.857298 -0.362586  0.584306  \n",
       "4   -0.986912 -0.006150 -1.001963  0.307408 -0.171837  0.416459  \n",
       "5    0.195159 -0.394252  0.754895 -0.054449  3.939962 -0.256343  \n",
       "6   -0.408277  3.289767  0.921860  0.607383  0.310273  1.934371  \n",
       "7    0.631071 -0.554251  1.049112  0.595754 -0.264482  0.098367  \n",
       "8    0.685738  0.060267  0.240304 -0.260171 -0.345022 -0.977767  \n",
       "9    1.019661 -1.045355  0.728018  0.269853  3.768397 -0.865074  \n",
       "10   0.052045 -1.475142  0.964716  0.580170 -0.526890  3.695478  \n",
       "11  -1.359378  0.125921 -1.069896 -0.435476  0.335398  0.233901  \n",
       "12  -0.635800  1.411689 -0.034218  0.026586 -0.222119  0.644681  \n",
       "13   3.627855  0.834177 -0.305158  0.030605 -0.827660 -0.294085  \n",
       "14   3.382434  0.488574 -0.065362 -0.991493 -0.928332 -0.957187  \n",
       "15  -0.165131  1.597335 -1.654309  0.477349 -0.238305  0.806332  \n",
       "16   0.647583  0.264772 -0.954217  0.657336  4.091099 -0.468007  \n",
       "17   0.760112 -0.009755  1.270550  0.603574 -0.282384 -0.934310  \n",
       "18  -1.264696 -0.251943 -0.784355  0.594379 -0.225215 -0.516801  \n",
       "19   0.270853  0.533549 -0.278017 -0.256943 -0.159516  1.272878  \n",
       "20   0.243423 -0.493480  0.820438 -0.000126 -0.280933 -0.702675  \n",
       "21   0.176057  0.658007  0.088739 -0.017581 -0.200698  0.979237  \n",
       "22   0.714248 -0.279995 -0.538967 -1.754797 -0.429055 -0.052801  \n",
       "23  -1.539723 -0.511106 -0.225811  0.887479 -0.116359 -0.620534  \n",
       "24  -0.084254 -2.660340 -0.417255 -0.456178 -0.660758  0.809331  \n",
       "25  -1.329676 -1.265713  0.452782 -0.624106  0.027833 -0.248861  \n",
       "26  -0.676499  0.307313  1.529051  0.819056  0.106207 -0.124282  \n",
       "27   0.267120  0.826970  2.020085 -3.937981 -0.269015  1.479730  \n",
       "28   0.613298 -0.103903  0.294610 -0.112098 -0.186023 -0.970029  \n",
       "29   0.576692 -0.106322 -0.719618 -0.340360 -0.287602  0.048091  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324 -0.942075  1.348960 -0.156008 -0.450447 -0.167151  0.098929  \n",
       "325  0.206861 -2.599742 -0.679201 -0.256533 -0.516969  0.534755  \n",
       "326 -0.706664 -1.151996 -0.788001  1.688322 -0.269644 -0.713522  \n",
       "327  0.045463 -1.388278  1.004437  1.593126 -0.459578 -1.373151  \n",
       "328  1.953437  0.265062 -1.395970  0.522529 -0.342571 -0.815108  \n",
       "329 -0.391193  0.071180 -0.702808  0.813267 -0.251879 -0.768778  \n",
       "330  0.564823  0.417845  0.566093  0.646313 -0.044244 -0.164187  \n",
       "331 -0.714949  1.490871  0.395190  0.041914 -0.270665  0.437375  \n",
       "332  0.398486 -0.753861 -0.512377  0.023830 -0.252973  0.189492  \n",
       "333 -0.494448  1.574206 -0.295988  0.026064 -0.094441  0.154127  \n",
       "334  0.111718 -2.984972 -1.232753  2.838079 -0.386188  1.017576  \n",
       "335 -0.811853 -0.211932 -1.731636  0.992609 -0.048400  0.811001  \n",
       "336 -1.430948  0.742985 -1.589639  0.149407 -0.093774 -0.686834  \n",
       "337  0.493511 -0.384282 -0.656741 -1.713876 -0.325242 -0.006139  \n",
       "338 -0.427186  3.169238  0.951461  0.845506  0.314297  1.829259  \n",
       "339 -0.134929 -1.467272  1.261561  1.124268 -0.344816 -1.194008  \n",
       "340 -0.699432 -0.825240 -2.137400  0.036622  0.021078  1.373298  \n",
       "341 -1.656176 -0.758245 -0.422877  0.556423 -0.095854 -0.889029  \n",
       "342 -0.105625 -2.684684  0.362394  0.224631 -0.483569  3.346229  \n",
       "343 -1.566828 -0.924376 -0.802616  0.570587 -0.034229 -0.615597  \n",
       "344  0.086254 -0.042861  0.826787  0.598042  3.973727 -1.264901  \n",
       "345  1.169793  0.471431 -1.895855  0.366942 -0.492975 -0.593682  \n",
       "346 -0.651299 -0.127834 -0.059416 -0.119636 -0.087696 -1.513201  \n",
       "347  0.994797  0.244490  0.392686 -0.244980  4.024945  2.431384  \n",
       "348  0.784602 -0.134163 -0.228937  0.448984 -0.348608  0.212757  \n",
       "349 -0.215783  1.153468  2.968010  1.083063 -0.241957 -0.681613  \n",
       "350  1.631244  0.628999 -0.233673  0.390213 -0.520131 -1.751054  \n",
       "351 -0.510013 -0.382875 -0.328020 -0.053195  0.050772  0.416897  \n",
       "352 -0.932233  0.208401  0.497495  0.460779  0.066186 -0.304442  \n",
       "353 -0.188151  0.285467  0.888652 -0.951077 -0.418927 -0.168896  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "354/354 [==============================] - 0s 847us/step - loss: 15213.7705\n",
      "Epoch 2/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 2586.4260\n",
      "Epoch 3/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 1686.0155\n",
      "Epoch 4/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 1033.4029\n",
      "Epoch 5/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 582.0889\n",
      "Epoch 6/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 313.3432\n",
      "Epoch 7/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 209.5810\n",
      "Epoch 8/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 167.0743\n",
      "Epoch 9/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 148.8719\n",
      "Epoch 10/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 140.5908\n",
      "Epoch 11/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 136.6607\n",
      "Epoch 12/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 131.3143\n",
      "Epoch 13/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 127.9834\n",
      "Epoch 14/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 125.8745\n",
      "Epoch 15/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 122.2252\n",
      "Epoch 16/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 116.3415\n",
      "Epoch 17/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 112.5913\n",
      "Epoch 18/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 109.2869\n",
      "Epoch 19/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 108.1790\n",
      "Epoch 20/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 102.5496\n",
      "Epoch 21/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 103.6714\n",
      "Epoch 22/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 97.9256\n",
      "Epoch 23/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 94.7352\n",
      "Epoch 24/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 92.8781\n",
      "Epoch 25/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 91.7396\n",
      "Epoch 26/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 89.3766\n",
      "Epoch 27/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 91.9267\n",
      "Epoch 28/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 83.7152\n",
      "Epoch 29/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 80.8126\n",
      "Epoch 30/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 80.0923\n",
      "Epoch 31/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 79.2845\n",
      "Epoch 32/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 75.7397\n",
      "Epoch 33/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 74.6243\n",
      "Epoch 34/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 72.2224\n",
      "Epoch 35/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 70.0487\n",
      "Epoch 36/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 68.9399\n",
      "Epoch 37/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 69.1732\n",
      "Epoch 38/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 67.7009\n",
      "Epoch 39/300\n",
      "354/354 [==============================] - 0s 254us/step - loss: 64.7716\n",
      "Epoch 40/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.9558\n",
      "Epoch 41/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 61.4527\n",
      "Epoch 42/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 62.8743\n",
      "Epoch 43/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 61.4220\n",
      "Epoch 44/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 60.4658\n",
      "Epoch 45/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 57.8235\n",
      "Epoch 46/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 57.3691\n",
      "Epoch 47/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 56.9012\n",
      "Epoch 48/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 55.0210\n",
      "Epoch 49/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.0039\n",
      "Epoch 50/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 52.8735\n",
      "Epoch 51/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 54.0550\n",
      "Epoch 52/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 51.4402\n",
      "Epoch 53/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 53.4084\n",
      "Epoch 54/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 49.9858\n",
      "Epoch 55/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 49.1493\n",
      "Epoch 56/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 48.6064\n",
      "Epoch 57/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 50.4820\n",
      "Epoch 58/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 100.588 - 0s 113us/step - loss: 48.0306\n",
      "Epoch 59/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.4490\n",
      "Epoch 60/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 46.9588\n",
      "Epoch 61/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 48.7907\n",
      "Epoch 62/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 45.9452\n",
      "Epoch 63/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 44.7282\n",
      "Epoch 64/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.5771\n",
      "Epoch 65/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 43.0355\n",
      "Epoch 66/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 43.9639\n",
      "Epoch 67/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 44.1680\n",
      "Epoch 68/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 42.2926\n",
      "Epoch 69/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.5216\n",
      "Epoch 70/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 41.5903\n",
      "Epoch 71/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 43.4705\n",
      "Epoch 72/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 39.7362\n",
      "Epoch 73/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 40.3770\n",
      "Epoch 74/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 38.8861\n",
      "Epoch 75/300\n",
      "354/354 [==============================] - 0s 229us/step - loss: 38.7787\n",
      "Epoch 76/300\n",
      "354/354 [==============================] - 0s 223us/step - loss: 37.9056\n",
      "Epoch 77/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 38.1093\n",
      "Epoch 78/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.9825\n",
      "Epoch 79/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.4300\n",
      "Epoch 80/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.7437\n",
      "Epoch 81/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 37.7493\n",
      "Epoch 82/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.5896\n",
      "Epoch 83/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.5697\n",
      "Epoch 84/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 37.3940\n",
      "Epoch 85/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.0172\n",
      "Epoch 86/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.2461\n",
      "Epoch 87/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 38.9479\n",
      "Epoch 88/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.2593\n",
      "Epoch 89/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 34.9868\n",
      "Epoch 90/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 35.1291\n",
      "Epoch 91/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.6008\n",
      "Epoch 92/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 37.2056\n",
      "Epoch 93/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.4234\n",
      "Epoch 94/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.1025\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 35.4039\n",
      "Epoch 96/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.6587\n",
      "Epoch 97/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.8523\n",
      "Epoch 98/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.2939\n",
      "Epoch 99/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.5876\n",
      "Epoch 100/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.9605\n",
      "Epoch 101/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.4596\n",
      "Epoch 102/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.9398\n",
      "Epoch 103/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.8841\n",
      "Epoch 104/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.1534\n",
      "Epoch 105/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 32.7608\n",
      "Epoch 106/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 36.1276\n",
      "Epoch 107/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1099\n",
      "Epoch 108/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.9757\n",
      "Epoch 109/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9567\n",
      "Epoch 110/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5271\n",
      "Epoch 111/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.8202\n",
      "Epoch 112/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 35.1899\n",
      "Epoch 113/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.1197\n",
      "Epoch 114/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.3560\n",
      "Epoch 115/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.4693\n",
      "Epoch 116/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.0128\n",
      "Epoch 117/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.1147\n",
      "Epoch 118/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.5945\n",
      "Epoch 119/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.5499\n",
      "Epoch 120/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.3150\n",
      "Epoch 121/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.7958\n",
      "Epoch 122/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 33.0041\n",
      "Epoch 123/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.5943\n",
      "Epoch 124/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 30.8307\n",
      "Epoch 125/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.1989\n",
      "Epoch 126/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.5503\n",
      "Epoch 127/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.9059\n",
      "Epoch 128/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9740\n",
      "Epoch 129/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.7041\n",
      "Epoch 130/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.6548\n",
      "Epoch 131/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3604\n",
      "Epoch 132/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.6080\n",
      "Epoch 133/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.6337\n",
      "Epoch 134/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7526\n",
      "Epoch 135/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.8242\n",
      "Epoch 136/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.1032\n",
      "Epoch 137/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.2450\n",
      "Epoch 138/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3070\n",
      "Epoch 139/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.2749\n",
      "Epoch 140/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.7903\n",
      "Epoch 141/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.5262\n",
      "Epoch 142/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 34.2039\n",
      "Epoch 143/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.7380\n",
      "Epoch 144/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.2958\n",
      "Epoch 145/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.9584\n",
      "Epoch 146/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.3811\n",
      "Epoch 147/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6125\n",
      "Epoch 148/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.7668\n",
      "Epoch 149/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.4994\n",
      "Epoch 150/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.6684\n",
      "Epoch 151/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 35.5922\n",
      "Epoch 152/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.2660\n",
      "Epoch 153/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.4849\n",
      "Epoch 154/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.9388\n",
      "Epoch 155/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.3591\n",
      "Epoch 156/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 33.8657\n",
      "Epoch 157/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.6355\n",
      "Epoch 158/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2377\n",
      "Epoch 159/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.6272\n",
      "Epoch 160/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.2563\n",
      "Epoch 161/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.2419\n",
      "Epoch 162/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3486\n",
      "Epoch 163/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.2753\n",
      "Epoch 164/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.0279\n",
      "Epoch 165/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 29.0834\n",
      "Epoch 166/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.2101\n",
      "Epoch 167/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.5935\n",
      "Epoch 168/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.5657\n",
      "Epoch 169/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.9220\n",
      "Epoch 170/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.8357\n",
      "Epoch 171/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 36.2201\n",
      "Epoch 172/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 36.0912\n",
      "Epoch 173/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.1952\n",
      "Epoch 174/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.6714\n",
      "Epoch 175/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0184\n",
      "Epoch 176/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.8635\n",
      "Epoch 177/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.2742\n",
      "Epoch 178/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 30.3291\n",
      "Epoch 179/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 32.5406\n",
      "Epoch 180/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.0014\n",
      "Epoch 181/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.8134\n",
      "Epoch 182/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 30.19 - 0s 141us/step - loss: 30.5469\n",
      "Epoch 183/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.5524\n",
      "Epoch 184/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.8019\n",
      "Epoch 185/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.2220\n",
      "Epoch 186/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.9899\n",
      "Epoch 187/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.4020\n",
      "Epoch 188/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.7435\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 169us/step - loss: 29.0780\n",
      "Epoch 190/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0710\n",
      "Epoch 191/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 29.2411\n",
      "Epoch 192/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.5233\n",
      "Epoch 193/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 31.6669\n",
      "Epoch 194/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.3242\n",
      "Epoch 195/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 29.4202\n",
      "Epoch 196/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.7356\n",
      "Epoch 197/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.8201\n",
      "Epoch 198/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.7184\n",
      "Epoch 199/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.0002\n",
      "Epoch 200/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.2946\n",
      "Epoch 201/300\n",
      "354/354 [==============================] - ETA: 0s - loss: 13.53 - 0s 113us/step - loss: 29.1237\n",
      "Epoch 202/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.9079\n",
      "Epoch 203/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.3691\n",
      "Epoch 204/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.1938\n",
      "Epoch 205/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.2928\n",
      "Epoch 206/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.2960\n",
      "Epoch 207/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.2644\n",
      "Epoch 208/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.1479\n",
      "Epoch 209/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.5167\n",
      "Epoch 210/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6374\n",
      "Epoch 211/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9493\n",
      "Epoch 212/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.0682\n",
      "Epoch 213/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.4178\n",
      "Epoch 214/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 28.5898\n",
      "Epoch 215/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.8560\n",
      "Epoch 216/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.6669\n",
      "Epoch 217/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.5523\n",
      "Epoch 218/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 28.6474\n",
      "Epoch 219/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.0401\n",
      "Epoch 220/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.9559\n",
      "Epoch 221/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 27.0384\n",
      "Epoch 222/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 25.6952\n",
      "Epoch 223/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.0663\n",
      "Epoch 224/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0823\n",
      "Epoch 225/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.3446\n",
      "Epoch 226/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.4571\n",
      "Epoch 227/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7863\n",
      "Epoch 228/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 31.7102\n",
      "Epoch 229/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 28.0116\n",
      "Epoch 230/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.4875\n",
      "Epoch 231/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 25.0704\n",
      "Epoch 232/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 34.5454\n",
      "Epoch 233/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 30.7275\n",
      "Epoch 234/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6288\n",
      "Epoch 235/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.2926\n",
      "Epoch 236/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9915\n",
      "Epoch 237/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 26.4296\n",
      "Epoch 238/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 32.1324\n",
      "Epoch 239/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.8746\n",
      "Epoch 240/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 29.6798\n",
      "Epoch 241/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 27.6104\n",
      "Epoch 242/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 24.8336\n",
      "Epoch 243/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.3411\n",
      "Epoch 244/300\n",
      "354/354 [==============================] - 0s 172us/step - loss: 31.7048\n",
      "Epoch 245/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 25.5874\n",
      "Epoch 246/300\n",
      "354/354 [==============================] - 0s 311us/step - loss: 31.9699\n",
      "Epoch 247/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 26.0707\n",
      "Epoch 248/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3771\n",
      "Epoch 249/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7837\n",
      "Epoch 250/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8105\n",
      "Epoch 251/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 24.8714\n",
      "Epoch 252/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.5399\n",
      "Epoch 253/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.1813\n",
      "Epoch 254/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.5463\n",
      "Epoch 255/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 25.6594\n",
      "Epoch 256/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.4496\n",
      "Epoch 257/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.8696\n",
      "Epoch 258/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.7938\n",
      "Epoch 259/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 24.5285\n",
      "Epoch 260/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.2232\n",
      "Epoch 261/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.1008\n",
      "Epoch 262/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6563\n",
      "Epoch 263/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.1157\n",
      "Epoch 264/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.8690\n",
      "Epoch 265/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 31.7331\n",
      "Epoch 266/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 24.7661\n",
      "Epoch 267/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 25.7811\n",
      "Epoch 268/300\n",
      "354/354 [==============================] - 0s 226us/step - loss: 26.3096\n",
      "Epoch 269/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 27.2788\n",
      "Epoch 270/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.4792\n",
      "Epoch 271/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 33.3707\n",
      "Epoch 272/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6299\n",
      "Epoch 273/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9109\n",
      "Epoch 274/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.5904\n",
      "Epoch 275/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.9088\n",
      "Epoch 276/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 26.0702\n",
      "Epoch 277/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.8709\n",
      "Epoch 278/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.6846\n",
      "Epoch 279/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.5587\n",
      "Epoch 280/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.0850\n",
      "Epoch 281/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.2099\n",
      "Epoch 282/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.0214\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 141us/step - loss: 26.8207\n",
      "Epoch 284/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 24.3994\n",
      "Epoch 285/300\n",
      "354/354 [==============================] - 0s 169us/step - loss: 26.7200\n",
      "Epoch 286/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.4301\n",
      "Epoch 287/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.7086\n",
      "Epoch 288/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 25.9376\n",
      "Epoch 289/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 28.1631\n",
      "Epoch 290/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.2699\n",
      "Epoch 291/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.6593\n",
      "Epoch 292/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 26.6452\n",
      "Epoch 293/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 25.3593\n",
      "Epoch 294/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 27.6076\n",
      "Epoch 295/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.5577\n",
      "Epoch 296/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 24.3874\n",
      "Epoch 297/300\n",
      "354/354 [==============================] - 0s 113us/step - loss: 24.2822\n",
      "Epoch 298/300\n",
      "354/354 [==============================] - 0s 198us/step - loss: 33.5797\n",
      "Epoch 299/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 30.9695\n",
      "Epoch 300/300\n",
      "354/354 [==============================] - 0s 141us/step - loss: 31.1846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19f08860>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28., 39., 41., 13., 27., 42., 20., 18., 27., 24., 29., 12., 39.,\n",
       "        27., 18., 33., 34., 30., 26., 25., 27., 29., 45., 30., 28.,  6.,\n",
       "        24., 19., 19., 20., 32., 27., 29., 26., 33., 35., 25., 28., 23.,\n",
       "        39., 25., 13., 31., 29., 25., 24., 24., 25., 31., 24., 26., 16.,\n",
       "        31., 30., 26., 31., 12., 34., 16., 27., 34., 26., 22., 50., 36.,\n",
       "        35., 34., 34., 29., 26., 27., 29., 21., 39., 44., 22., 25., 35.,\n",
       "        34., 38., 24., 26., 28., 29., 26., 20., 29., 27., 27., 20.,  9.,\n",
       "        22., 25., 27., 38., 27., 23., 28., 26., 29., 27., 16., 18., 19.,\n",
       "        26., 27., 32.,  5., 37., 27., 38., 27., 23., 23., 36., 28., 24.,\n",
       "        30., 28., 24., 26., 26., 22., 28., 31., 26., 21., 14., 11., 28.,\n",
       "        26., 22., 26., 21., 41., 22., 31., 40., 32., 29., 31., 21., 40.,\n",
       "        17., 35., 30., 19., 20., 45., 16., 18., 35.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.37382728175113"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\", kernel_initializer='Zeros'))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 424us/step - loss: 3.2007\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1599\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1338\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1192\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.2039\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.1028\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.1479\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.2794\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.1374\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 3.1430\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0299\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.2390\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.1080\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.1371\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0995\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0626\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1637\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.3139\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.1136\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0841\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 3.1241\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.2619\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.2459\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.1064\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0254\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1021\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0999\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0405\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1214\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0553\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0324\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1515\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 424us/step - loss: 3.0641\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 480us/step - loss: 3.1630\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 3.0619\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 3.0719\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0320\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1144\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 2.9718\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0061\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 2.9764\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0382\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1183\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.1365\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0104\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0088\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0194\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0579\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0401\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0968\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0165\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9696\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 3.0019\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 376us/step - loss: 2.9270\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9531\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 3.0244\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.1240\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0364\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.1200\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.1307\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.9416\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9424\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0071\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0318\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 3.1370\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0142\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0483\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.0281\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9649\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9800\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9513\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.9764\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 3.4123\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.1531\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0225\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.1508\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 3.0614\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.9520\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9693\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9482\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.9120\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 3.0256\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.9351\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9879\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 2.9669\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.9667\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.9271\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.9438\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 427us/step - loss: 2.9097\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.1638\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 2.8916\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.9637\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.9970\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.9212\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.0744\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.9109\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 282us/step - loss: 2.9829\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 3.0314\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 2.9251\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 3.0772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2bf5ec50>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22., 30., 33., 13., 21., 31., 19., 17., 22., 19., 20.,  9., 34.,\n",
       "        19., 16., 23., 29., 25., 21., 22., 23., 21., 33., 26., 24.,  8.,\n",
       "        19., 17., 15., 14., 27., 22., 24., 20., 25., 32., 19., 25., 23.,\n",
       "        28., 20., 11., 26., 26., 22., 23., 18., 19., 25., 17., 21., 10.,\n",
       "        26., 28., 26., 23., 14., 30., 10., 26., 27., 23., 18., 38., 28.,\n",
       "        29., 30., 28., 28., 22., 21., 27., 13., 29., 35., 20., 18., 28.,\n",
       "        28., 31., 21., 21., 25., 20., 20., 18., 25., 27., 23., 15.,  9.,\n",
       "        22., 22., 22., 30., 24., 18., 22., 23., 24., 24., 14., 18., 17.,\n",
       "        21., 22., 27.,  7., 33., 24., 34., 22., 16., 13., 28., 24., 20.,\n",
       "        27., 26., 19., 21., 25., 17., 24., 24., 23., 14., 14., 10., 23.,\n",
       "        19., 18., 21., 17., 33., 24., 27., 30., 27., 23., 24., 16., 34.,\n",
       "        14., 26., 25., 15., 17., 32., 14., 15., 27.]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\", kernel_initializer='Zeros'))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 5.3230\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3372\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3423\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.5286\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4962\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 5.3913\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.4439\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.4299\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4158\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4720\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4483\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 5.4215\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4178\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4339\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.4217\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3918\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.5644\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3943\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3772\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4087\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4141\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3856\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4095\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4225\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4119\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3987\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4588\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.4130\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4595\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4470\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4020\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4270\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4444\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4182\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 537us/step - loss: 5.3764\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 486us/step - loss: 5.3915\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 5.4391\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3949\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.4024\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.5217\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4452\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3715\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4062\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4088\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3848\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3906\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3867\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3793\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4483\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4233\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4061\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4585\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 5.4019\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 5.3864\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3834\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.6965\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.7056\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4451\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.6039\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.6329\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4461\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.4853\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4191\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.4107\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3559\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3807\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 342us/step - loss: 5.3439\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3936\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3677\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3435\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3025\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3323\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3944\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.2876\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.2860\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.2634\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 5.2402\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3981\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.2733\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 5.2645\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.3154\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.2602\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.2739\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.2817\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.2856\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.2531\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 5.3399\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.2842\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 5.2820\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 5.255 - 0s 565us/step - loss: 5.2877\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 508us/step - loss: 5.2648\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 5.2313\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3054\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 5.4057\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 5.294 - 0s 339us/step - loss: 5.3366\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 5.3702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3488\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3437\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 5.1996\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a7b9828>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"elu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_absolute_error\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 100.4251\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 14.0262\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 10.6821\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 9.1403\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 8.4279\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 8.0675\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 7.5503\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 7.3940\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 6.9757\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 6.9877\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 6.6309\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 6.2638\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 6.3616\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 6.3498\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 6.1099\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.8765\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.6975\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.6376\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.8414\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 5.5567\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.5712\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.5124\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.5249\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.2423\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.4908\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3169\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.3055\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.2725\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.2352\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.3053\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.0710\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.2928\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.0985\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.2494\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.0321\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.0111\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.9663\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 5.0535\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.1052\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.9668\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.9102\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.9327\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.9710\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8682\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.7368\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.9030\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.9413\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 4.7002\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8965\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.9015\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.7344\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8583\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.6321\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8145\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.9123\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.6918\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8581\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.7810\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.6687\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.6639\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.4817\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8734\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.7544\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.6209\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.7868\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.8253\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.4583\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.8404\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.7670\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.5139\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 4.5847\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 4.6960\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 4.6257\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 4.6146\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 4.5270\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 4.5045\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.6543\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.4778\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.3455\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 4.3813\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 345us/step - loss: 4.5016\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.3888\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.8156\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 4.3343\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.7561\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.5850\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.7424\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.5527\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.5129\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.4260\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.4347\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.4633\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.5641\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 4.4558\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.3981\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.4189\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 254us/step - loss: 4.4638\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 198us/step - loss: 4.5344\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.6094\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.3583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2f434ba8>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 3.1922\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1736\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2415\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1393\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1241\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1245\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1542\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1248\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1207\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1262\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1147\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1218\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1195\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 0.1238\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1101\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1313\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1377\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1255\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1130\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1302\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1126\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1111\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1027\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1101\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1135\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1120\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1236\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1078\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1073\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 0.1077\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1063\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1191\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1050\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1105\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1084\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1064\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1077\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1014\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1016\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1029\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1057\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1051\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1001\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1117\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1382\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1119\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1020\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1055\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1090\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0992\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1048\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1050\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.1116\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0969\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 0.0948\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1044\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0963\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1205\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0941\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0972\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1017\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1011\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1080\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0967\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1102\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0953\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1003\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0953\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0962\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0999\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0944\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1028\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1007\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0875\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0981\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0930\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0899\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1000\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0931\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0936\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0913\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0848\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0891\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0881\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0933\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0838\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1129\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0807\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0831\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0863\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0808\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1065\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0914\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0874\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0873\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0848\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 254us/step - loss: 0.0992\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0941\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1087\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x33a7f898>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 1.1363\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.5043\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.4423\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3887\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3569\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3912\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.4075\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3373\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2851\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2683\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2664\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2557\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2466\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2387\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2340\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2100\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1987\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2002\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2602\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1997\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1699\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1587\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1472\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1396\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1355\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1339\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1290\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1307\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1231\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1448\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 0.1349\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1197\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1163\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1155\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1126\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1156\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1119\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1108\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1162\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1210\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 593us/step - loss: 0.1058\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 508us/step - loss: 0.1077\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 480us/step - loss: 0.1322\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1137\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.0907\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0993\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1300\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0858\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0915\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0903\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0829\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0781\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0765\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0776\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.0741\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0737\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0765\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0748\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0690\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0762\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0868\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0865\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0703\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.0720\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 424us/step - loss: 0.0733\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.0707\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 424us/step - loss: 0.0684\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 424us/step - loss: 0.0687\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0685\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0685\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0663\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.0680\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0647\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0738\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0770\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0632\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0621\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0662\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0651\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0710\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0635\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0653\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0647\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0747\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0650\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0644\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0619\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0595\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0843\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0689\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0596\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0630\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0596\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0636\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0650\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.0605\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 226us/step - loss: 0.0728\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0580\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0819\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.0554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x33cde2b0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"tanh\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 6.9685\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.2352\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 4.3280\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 3.7720\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.3659\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.0444\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.7805\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.5261\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.3209\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.1265\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.9312\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.8068\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.7007\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.6152\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.5337\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.4585\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.3808\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.3053\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.2420\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.1904\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.1427\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.0980\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.0550\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.0128\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.9655\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.9130\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.8741\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.8404\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.8098\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.7805\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.7532\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.7272\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7034\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.6806\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.6588\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.6379\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6179\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5990\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.5807\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.5631\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5464\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5298\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.5144\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.4997\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.4855\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.4720\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4588\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.4462\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4342\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4223\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.4111\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4003\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.3895\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 373us/step - loss: 0.3791\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3694\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3601\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3512\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3426\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.3342\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.3263\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3187\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.3112\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3041\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.2971\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2905\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2839\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2768\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2709\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2650\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2595\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2541\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2489\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2439\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2391\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2343\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2299\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2255\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2214\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2173\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2134\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2095\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2056\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2013\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1968\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1933\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1902\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1872\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1843\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1815\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1788\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1762\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1737\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1713\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1690\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1667\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1646\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 254us/step - loss: 0.1625\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1605\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1586\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x350565c0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 18., 18., 11., 18., 16., 18., 11., 18., 11., 16., 16., 18.,\n",
       "        16., 18., 18., 18., 16., 18., 18., 16., 16., 18., 18., 16., 16.,\n",
       "        11., 11., 16., 11., 18., 18., 18., 16., 18., 18., 18., 18., 18.,\n",
       "        18., 18., 16., 18., 18., 18., 18., 16., 16., 16., 16., 18., 14.,\n",
       "        18., 18., 18., 18., 18., 18., 11., 18., 18., 18., 18., 18., 18.,\n",
       "        16., 18., 18., 18., 16., 18., 18., 13., 18., 18., 18., 14., 18.,\n",
       "        18., 18., 18., 18., 18., 16., 18., 18., 18., 18., 18., 16., 18.,\n",
       "        18., 18., 16., 18., 18., 11., 18., 18., 18., 18., 18., 16., 11.,\n",
       "        16., 18., 18., 11., 18., 16., 18., 18., 18., 14., 18., 18., 16.,\n",
       "        18., 18., 18., 18., 18., 16., 18., 18., 18., 16., 18., 16., 18.,\n",
       "        14., 11., 18., 11., 18., 16., 18., 18., 18., 18., 18., 16., 18.,\n",
       "        18., 18., 18., 16., 18., 18., 11., 11., 18.]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15137190724674024"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = pre.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"tanh\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 7.5654\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 5.6681\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 4.6470\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 4.0568\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.6010\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 3.2555\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.9720\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.7335\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.5258\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.3451\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 2.1788\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.0274\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.8936\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.7826\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.6772\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.5850\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.5017\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.4220\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.3499\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.2857\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.2277\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.1735\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.1232\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.0760\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 1.0318\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.9908\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.9521\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.9158\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.8815\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.8493\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.8188\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.7897\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.7625\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.7363\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 0.7116\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 508us/step - loss: 0.6881\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 373us/step - loss: 0.6655\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.6442\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.6239\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.6045\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.5859\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 395us/step - loss: 0.5670\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.5480\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5309\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5145\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4996\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4856\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.4721\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.4591\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.4468\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4348\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.4234\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4122\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.4017\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3915\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3819\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3725\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3636\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3550\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3466\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3387\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3307\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3232\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.3160\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3091\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.3025\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2961\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2899\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2839\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2782\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2726\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2675\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2618\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2572\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2521\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2475\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2434\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2393\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2374\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2340\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2296\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2238\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2206\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2154\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2123\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2092\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2059\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2031\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2003\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1976\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 0.196 - 0s 311us/step - loss: 0.1951\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1926\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1902\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1879\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1857\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1835\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 311us/step - loss: 0.1814\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1795\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1776\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x36c3cdd8>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17., 17., 17., 14., 17., 17., 17., 14., 17., 14., 17., 17., 17.,\n",
       "        17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17.,\n",
       "        14., 14., 17., 14., 17., 17., 17., 17., 17., 17., 17., 17., 17.,\n",
       "        17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 14.,\n",
       "        17., 17., 17., 17., 17., 17., 14., 17., 17., 17., 17., 17., 17.,\n",
       "        17., 17., 17., 17., 17., 17., 17., 14., 17., 17., 17., 14., 17.,\n",
       "        17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17.,\n",
       "        17., 17., 17., 17., 17., 14., 17., 17., 17., 17., 17., 17., 14.,\n",
       "        17., 17., 17., 14., 17., 17., 17., 17., 17., 14., 17., 17., 17.,\n",
       "        17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17.,\n",
       "        15., 14., 17., 14., 17., 17., 17., 17., 17., 17., 17., 17., 17.,\n",
       "        17., 17., 17., 17., 17., 17., 14., 14., 17.]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16265550334202616"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.218296</td>\n",
       "      <td>0.336704</td>\n",
       "      <td>-0.426186</td>\n",
       "      <td>-0.886752</td>\n",
       "      <td>0.380047</td>\n",
       "      <td>-1.187510</td>\n",
       "      <td>-0.391259</td>\n",
       "      <td>0.125752</td>\n",
       "      <td>-0.172811</td>\n",
       "      <td>-1.267331</td>\n",
       "      <td>-1.771462</td>\n",
       "      <td>-0.501306</td>\n",
       "      <td>0.296134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410900</td>\n",
       "      <td>-1.292493</td>\n",
       "      <td>1.055464</td>\n",
       "      <td>-1.463581</td>\n",
       "      <td>-0.607597</td>\n",
       "      <td>-0.256340</td>\n",
       "      <td>0.067925</td>\n",
       "      <td>1.176856</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>-0.220818</td>\n",
       "      <td>-0.498881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.551091</td>\n",
       "      <td>0.086810</td>\n",
       "      <td>-1.064214</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>-0.056779</td>\n",
       "      <td>-0.404564</td>\n",
       "      <td>-0.352776</td>\n",
       "      <td>-0.668523</td>\n",
       "      <td>1.635779</td>\n",
       "      <td>0.115754</td>\n",
       "      <td>-0.914374</td>\n",
       "      <td>-0.289210</td>\n",
       "      <td>0.679937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.580706</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>1.007146</td>\n",
       "      <td>-2.389351</td>\n",
       "      <td>0.140114</td>\n",
       "      <td>-0.508026</td>\n",
       "      <td>0.103962</td>\n",
       "      <td>0.610198</td>\n",
       "      <td>-0.978994</td>\n",
       "      <td>-1.487230</td>\n",
       "      <td>-1.857298</td>\n",
       "      <td>-0.362586</td>\n",
       "      <td>0.584306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115420</td>\n",
       "      <td>-0.424497</td>\n",
       "      <td>-0.599070</td>\n",
       "      <td>-0.126995</td>\n",
       "      <td>-0.378454</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>-0.435759</td>\n",
       "      <td>-0.986912</td>\n",
       "      <td>-0.006150</td>\n",
       "      <td>-1.001963</td>\n",
       "      <td>0.307408</td>\n",
       "      <td>-0.171837</td>\n",
       "      <td>0.416459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.568687</td>\n",
       "      <td>-0.017722</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-0.158364</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.930286</td>\n",
       "      <td>-0.793835</td>\n",
       "      <td>0.195159</td>\n",
       "      <td>-0.394252</td>\n",
       "      <td>0.754895</td>\n",
       "      <td>-0.054449</td>\n",
       "      <td>3.939962</td>\n",
       "      <td>-0.256343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.447170</td>\n",
       "      <td>0.045592</td>\n",
       "      <td>2.683609</td>\n",
       "      <td>1.917981</td>\n",
       "      <td>-0.119569</td>\n",
       "      <td>0.329389</td>\n",
       "      <td>-0.053554</td>\n",
       "      <td>-0.408277</td>\n",
       "      <td>3.289767</td>\n",
       "      <td>0.921860</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.310273</td>\n",
       "      <td>1.934371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.967308</td>\n",
       "      <td>0.106104</td>\n",
       "      <td>1.077655</td>\n",
       "      <td>-1.022205</td>\n",
       "      <td>0.391836</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>-0.112093</td>\n",
       "      <td>0.631071</td>\n",
       "      <td>-0.554251</td>\n",
       "      <td>1.049112</td>\n",
       "      <td>0.595754</td>\n",
       "      <td>-0.264482</td>\n",
       "      <td>0.098367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.446440</td>\n",
       "      <td>-1.186458</td>\n",
       "      <td>-0.223272</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>-0.011630</td>\n",
       "      <td>-0.288014</td>\n",
       "      <td>-0.546646</td>\n",
       "      <td>0.685738</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>0.240304</td>\n",
       "      <td>-0.260171</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.977767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.743204</td>\n",
       "      <td>-0.016091</td>\n",
       "      <td>-1.406325</td>\n",
       "      <td>0.539970</td>\n",
       "      <td>0.063506</td>\n",
       "      <td>0.855115</td>\n",
       "      <td>-0.100882</td>\n",
       "      <td>1.019661</td>\n",
       "      <td>-1.045355</td>\n",
       "      <td>0.728018</td>\n",
       "      <td>0.269853</td>\n",
       "      <td>3.768397</td>\n",
       "      <td>-0.865074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>-1.128775</td>\n",
       "      <td>0.598142</td>\n",
       "      <td>-0.700726</td>\n",
       "      <td>-0.792189</td>\n",
       "      <td>2.491377</td>\n",
       "      <td>0.052045</td>\n",
       "      <td>-1.475142</td>\n",
       "      <td>0.964716</td>\n",
       "      <td>0.580170</td>\n",
       "      <td>-0.526890</td>\n",
       "      <td>3.695478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.109496</td>\n",
       "      <td>-0.463290</td>\n",
       "      <td>3.319455</td>\n",
       "      <td>2.483666</td>\n",
       "      <td>-0.436228</td>\n",
       "      <td>0.296471</td>\n",
       "      <td>0.442018</td>\n",
       "      <td>-1.359378</td>\n",
       "      <td>0.125921</td>\n",
       "      <td>-1.069896</td>\n",
       "      <td>-0.435476</td>\n",
       "      <td>0.335398</td>\n",
       "      <td>0.233901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.563461</td>\n",
       "      <td>0.004313</td>\n",
       "      <td>-0.916949</td>\n",
       "      <td>0.047773</td>\n",
       "      <td>0.015107</td>\n",
       "      <td>0.193161</td>\n",
       "      <td>-0.672598</td>\n",
       "      <td>-0.635800</td>\n",
       "      <td>1.411689</td>\n",
       "      <td>-0.034218</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>-0.222119</td>\n",
       "      <td>0.644681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.227955</td>\n",
       "      <td>0.397238</td>\n",
       "      <td>-1.018147</td>\n",
       "      <td>-0.282160</td>\n",
       "      <td>0.326452</td>\n",
       "      <td>2.019800</td>\n",
       "      <td>2.784529</td>\n",
       "      <td>3.627855</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>-0.305158</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>-0.827660</td>\n",
       "      <td>-0.294085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.184482</td>\n",
       "      <td>0.636922</td>\n",
       "      <td>-1.831814</td>\n",
       "      <td>0.768341</td>\n",
       "      <td>0.404875</td>\n",
       "      <td>3.168186</td>\n",
       "      <td>1.429387</td>\n",
       "      <td>3.382434</td>\n",
       "      <td>0.488574</td>\n",
       "      <td>-0.065362</td>\n",
       "      <td>-0.991493</td>\n",
       "      <td>-0.928332</td>\n",
       "      <td>-0.957187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.770244</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.887590</td>\n",
       "      <td>-0.119189</td>\n",
       "      <td>-0.104687</td>\n",
       "      <td>-0.106483</td>\n",
       "      <td>0.990349</td>\n",
       "      <td>-0.165131</td>\n",
       "      <td>1.597335</td>\n",
       "      <td>-1.654309</td>\n",
       "      <td>0.477349</td>\n",
       "      <td>-0.238305</td>\n",
       "      <td>0.806332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.049209</td>\n",
       "      <td>0.245458</td>\n",
       "      <td>-0.191747</td>\n",
       "      <td>0.451898</td>\n",
       "      <td>0.354904</td>\n",
       "      <td>0.686849</td>\n",
       "      <td>-0.510539</td>\n",
       "      <td>0.647583</td>\n",
       "      <td>0.264772</td>\n",
       "      <td>-0.954217</td>\n",
       "      <td>0.657336</td>\n",
       "      <td>4.091099</td>\n",
       "      <td>-0.468007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.686215</td>\n",
       "      <td>-0.075888</td>\n",
       "      <td>1.192591</td>\n",
       "      <td>1.485459</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>-0.011337</td>\n",
       "      <td>-0.086963</td>\n",
       "      <td>0.760112</td>\n",
       "      <td>-0.009755</td>\n",
       "      <td>1.270550</td>\n",
       "      <td>0.603574</td>\n",
       "      <td>-0.282384</td>\n",
       "      <td>-0.934310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.784367</td>\n",
       "      <td>0.049567</td>\n",
       "      <td>-0.780065</td>\n",
       "      <td>-0.207366</td>\n",
       "      <td>-0.016780</td>\n",
       "      <td>-0.963678</td>\n",
       "      <td>-0.534382</td>\n",
       "      <td>-1.264696</td>\n",
       "      <td>-0.251943</td>\n",
       "      <td>-0.784355</td>\n",
       "      <td>0.594379</td>\n",
       "      <td>-0.225215</td>\n",
       "      <td>-0.516801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.717640</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.989287</td>\n",
       "      <td>-2.451317</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.077713</td>\n",
       "      <td>0.384208</td>\n",
       "      <td>0.270853</td>\n",
       "      <td>0.533549</td>\n",
       "      <td>-0.278017</td>\n",
       "      <td>-0.256943</td>\n",
       "      <td>-0.159516</td>\n",
       "      <td>1.272878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.624073</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.160763</td>\n",
       "      <td>0.031376</td>\n",
       "      <td>-0.234554</td>\n",
       "      <td>-0.241636</td>\n",
       "      <td>0.243423</td>\n",
       "      <td>-0.493480</td>\n",
       "      <td>0.820438</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.280933</td>\n",
       "      <td>-0.702675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.715731</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.572144</td>\n",
       "      <td>-1.919670</td>\n",
       "      <td>0.174060</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>0.208287</td>\n",
       "      <td>0.176057</td>\n",
       "      <td>0.658007</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>-0.017581</td>\n",
       "      <td>-0.200698</td>\n",
       "      <td>0.979237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.421298</td>\n",
       "      <td>-1.406029</td>\n",
       "      <td>-0.310320</td>\n",
       "      <td>0.269410</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.218211</td>\n",
       "      <td>-0.958624</td>\n",
       "      <td>0.714248</td>\n",
       "      <td>-0.279995</td>\n",
       "      <td>-0.538967</td>\n",
       "      <td>-1.754797</td>\n",
       "      <td>-0.429055</td>\n",
       "      <td>-0.052801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.115556</td>\n",
       "      <td>-0.540635</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>-0.074706</td>\n",
       "      <td>-0.683186</td>\n",
       "      <td>-0.629395</td>\n",
       "      <td>0.157352</td>\n",
       "      <td>-1.539723</td>\n",
       "      <td>-0.511106</td>\n",
       "      <td>-0.225811</td>\n",
       "      <td>0.887479</td>\n",
       "      <td>-0.116359</td>\n",
       "      <td>-0.620534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.810639</td>\n",
       "      <td>0.069947</td>\n",
       "      <td>-0.996857</td>\n",
       "      <td>1.638662</td>\n",
       "      <td>0.107503</td>\n",
       "      <td>-0.951199</td>\n",
       "      <td>-0.879962</td>\n",
       "      <td>-0.084254</td>\n",
       "      <td>-2.660340</td>\n",
       "      <td>-0.417255</td>\n",
       "      <td>-0.456178</td>\n",
       "      <td>-0.660758</td>\n",
       "      <td>0.809331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.105027</td>\n",
       "      <td>-0.365970</td>\n",
       "      <td>1.965839</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>-0.438936</td>\n",
       "      <td>-0.648371</td>\n",
       "      <td>0.423267</td>\n",
       "      <td>-1.329676</td>\n",
       "      <td>-1.265713</td>\n",
       "      <td>0.452782</td>\n",
       "      <td>-0.624106</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>-0.248861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.572685</td>\n",
       "      <td>-0.102770</td>\n",
       "      <td>2.236526</td>\n",
       "      <td>2.417969</td>\n",
       "      <td>-0.146365</td>\n",
       "      <td>0.462122</td>\n",
       "      <td>0.541046</td>\n",
       "      <td>-0.676499</td>\n",
       "      <td>0.307313</td>\n",
       "      <td>1.529051</td>\n",
       "      <td>0.819056</td>\n",
       "      <td>0.106207</td>\n",
       "      <td>-0.124282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.492915</td>\n",
       "      <td>-0.203387</td>\n",
       "      <td>1.777558</td>\n",
       "      <td>-1.572743</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>-0.118156</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.267120</td>\n",
       "      <td>0.826970</td>\n",
       "      <td>2.020085</td>\n",
       "      <td>-3.937981</td>\n",
       "      <td>-0.269015</td>\n",
       "      <td>1.479730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.452100</td>\n",
       "      <td>-1.043974</td>\n",
       "      <td>0.526998</td>\n",
       "      <td>-0.762193</td>\n",
       "      <td>0.790775</td>\n",
       "      <td>0.227564</td>\n",
       "      <td>-0.189807</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>-0.103903</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>-0.112098</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>-0.970029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.751558</td>\n",
       "      <td>0.126659</td>\n",
       "      <td>0.426210</td>\n",
       "      <td>-1.772618</td>\n",
       "      <td>0.183135</td>\n",
       "      <td>0.663843</td>\n",
       "      <td>0.573432</td>\n",
       "      <td>0.576692</td>\n",
       "      <td>-0.106322</td>\n",
       "      <td>-0.719618</td>\n",
       "      <td>-0.340360</td>\n",
       "      <td>-0.287602</td>\n",
       "      <td>0.048091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.341859</td>\n",
       "      <td>1.772573</td>\n",
       "      <td>-1.265405</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>-0.069995</td>\n",
       "      <td>0.509438</td>\n",
       "      <td>-1.132676</td>\n",
       "      <td>-0.942075</td>\n",
       "      <td>1.348960</td>\n",
       "      <td>-0.156008</td>\n",
       "      <td>-0.450447</td>\n",
       "      <td>-0.167151</td>\n",
       "      <td>0.098929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.826799</td>\n",
       "      <td>0.112487</td>\n",
       "      <td>0.247452</td>\n",
       "      <td>0.055284</td>\n",
       "      <td>0.105849</td>\n",
       "      <td>-1.312153</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>0.206861</td>\n",
       "      <td>-2.599742</td>\n",
       "      <td>-0.679201</td>\n",
       "      <td>-0.256533</td>\n",
       "      <td>-0.516969</td>\n",
       "      <td>0.534755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.641654</td>\n",
       "      <td>-0.038538</td>\n",
       "      <td>-0.551487</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>-0.734961</td>\n",
       "      <td>-0.838139</td>\n",
       "      <td>-0.706664</td>\n",
       "      <td>-1.151996</td>\n",
       "      <td>-0.788001</td>\n",
       "      <td>1.688322</td>\n",
       "      <td>-0.269644</td>\n",
       "      <td>-0.713522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.079148</td>\n",
       "      <td>-1.116960</td>\n",
       "      <td>0.596164</td>\n",
       "      <td>-0.749896</td>\n",
       "      <td>-0.961395</td>\n",
       "      <td>2.613610</td>\n",
       "      <td>0.045463</td>\n",
       "      <td>-1.388278</td>\n",
       "      <td>1.004437</td>\n",
       "      <td>1.593126</td>\n",
       "      <td>-0.459578</td>\n",
       "      <td>-1.373151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-0.813866</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>1.064336</td>\n",
       "      <td>-0.424341</td>\n",
       "      <td>0.102291</td>\n",
       "      <td>0.844122</td>\n",
       "      <td>1.986576</td>\n",
       "      <td>1.953437</td>\n",
       "      <td>0.265062</td>\n",
       "      <td>-1.395970</td>\n",
       "      <td>0.522529</td>\n",
       "      <td>-0.342571</td>\n",
       "      <td>-0.815108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-0.921492</td>\n",
       "      <td>0.112342</td>\n",
       "      <td>-0.365070</td>\n",
       "      <td>-0.821385</td>\n",
       "      <td>0.201869</td>\n",
       "      <td>-0.452206</td>\n",
       "      <td>-0.469554</td>\n",
       "      <td>-0.391193</td>\n",
       "      <td>0.071180</td>\n",
       "      <td>-0.702808</td>\n",
       "      <td>0.813267</td>\n",
       "      <td>-0.251879</td>\n",
       "      <td>-0.768778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.991131</td>\n",
       "      <td>3.384534</td>\n",
       "      <td>0.421641</td>\n",
       "      <td>-0.237522</td>\n",
       "      <td>-1.409536</td>\n",
       "      <td>-0.691933</td>\n",
       "      <td>-0.216972</td>\n",
       "      <td>0.564823</td>\n",
       "      <td>0.417845</td>\n",
       "      <td>0.566093</td>\n",
       "      <td>0.646313</td>\n",
       "      <td>-0.044244</td>\n",
       "      <td>-0.164187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.569081</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>-1.287219</td>\n",
       "      <td>0.513402</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>0.189279</td>\n",
       "      <td>-0.924604</td>\n",
       "      <td>-0.714949</td>\n",
       "      <td>1.490871</td>\n",
       "      <td>0.395190</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>-0.270665</td>\n",
       "      <td>0.437375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.423465</td>\n",
       "      <td>-1.404566</td>\n",
       "      <td>-0.327444</td>\n",
       "      <td>0.281870</td>\n",
       "      <td>1.136365</td>\n",
       "      <td>1.723241</td>\n",
       "      <td>-1.725096</td>\n",
       "      <td>0.398486</td>\n",
       "      <td>-0.753861</td>\n",
       "      <td>-0.512377</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>-0.252973</td>\n",
       "      <td>0.189492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.356470</td>\n",
       "      <td>1.123745</td>\n",
       "      <td>-0.933219</td>\n",
       "      <td>0.525810</td>\n",
       "      <td>-0.889419</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.884598</td>\n",
       "      <td>-0.494448</td>\n",
       "      <td>1.574206</td>\n",
       "      <td>-0.295988</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>-0.094441</td>\n",
       "      <td>0.154127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-0.824148</td>\n",
       "      <td>0.085650</td>\n",
       "      <td>-0.076755</td>\n",
       "      <td>0.455379</td>\n",
       "      <td>0.246723</td>\n",
       "      <td>-0.323226</td>\n",
       "      <td>-0.679215</td>\n",
       "      <td>0.111718</td>\n",
       "      <td>-2.984972</td>\n",
       "      <td>-1.232753</td>\n",
       "      <td>2.838079</td>\n",
       "      <td>-0.386188</td>\n",
       "      <td>1.017576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-0.127880</td>\n",
       "      <td>-0.422532</td>\n",
       "      <td>0.152169</td>\n",
       "      <td>-1.090901</td>\n",
       "      <td>-0.301478</td>\n",
       "      <td>0.352250</td>\n",
       "      <td>-0.072848</td>\n",
       "      <td>-0.811853</td>\n",
       "      <td>-0.211932</td>\n",
       "      <td>-1.731636</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>-0.048400</td>\n",
       "      <td>0.811001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.146226</td>\n",
       "      <td>-0.384283</td>\n",
       "      <td>-0.986603</td>\n",
       "      <td>0.347412</td>\n",
       "      <td>-0.335649</td>\n",
       "      <td>0.549421</td>\n",
       "      <td>-1.125597</td>\n",
       "      <td>-1.430948</td>\n",
       "      <td>0.742985</td>\n",
       "      <td>-1.589639</td>\n",
       "      <td>0.149407</td>\n",
       "      <td>-0.093774</td>\n",
       "      <td>-0.686834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.472153</td>\n",
       "      <td>-0.972228</td>\n",
       "      <td>-0.133663</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>0.740923</td>\n",
       "      <td>0.531293</td>\n",
       "      <td>-0.840607</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>-0.384282</td>\n",
       "      <td>-0.656741</td>\n",
       "      <td>-1.713876</td>\n",
       "      <td>-0.325242</td>\n",
       "      <td>-0.006139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.456135</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>2.599987</td>\n",
       "      <td>2.013634</td>\n",
       "      <td>-0.074048</td>\n",
       "      <td>0.699033</td>\n",
       "      <td>-0.367732</td>\n",
       "      <td>-0.427186</td>\n",
       "      <td>3.169238</td>\n",
       "      <td>0.951461</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>1.829259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0.199952</td>\n",
       "      <td>1.533377</td>\n",
       "      <td>-0.834032</td>\n",
       "      <td>0.360015</td>\n",
       "      <td>-0.631507</td>\n",
       "      <td>-0.470706</td>\n",
       "      <td>2.482422</td>\n",
       "      <td>-0.134929</td>\n",
       "      <td>-1.467272</td>\n",
       "      <td>1.261561</td>\n",
       "      <td>1.124268</td>\n",
       "      <td>-0.344816</td>\n",
       "      <td>-1.194008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.133477</td>\n",
       "      <td>-0.373511</td>\n",
       "      <td>0.864971</td>\n",
       "      <td>-2.012486</td>\n",
       "      <td>-0.053010</td>\n",
       "      <td>1.852188</td>\n",
       "      <td>-0.642114</td>\n",
       "      <td>-0.699432</td>\n",
       "      <td>-0.825240</td>\n",
       "      <td>-2.137400</td>\n",
       "      <td>0.036622</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>1.373298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>-0.674742</td>\n",
       "      <td>0.154730</td>\n",
       "      <td>-0.674479</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>-0.423200</td>\n",
       "      <td>-1.656176</td>\n",
       "      <td>-0.758245</td>\n",
       "      <td>-0.422877</td>\n",
       "      <td>0.556423</td>\n",
       "      <td>-0.095854</td>\n",
       "      <td>-0.889029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.035970</td>\n",
       "      <td>-0.467859</td>\n",
       "      <td>-1.224252</td>\n",
       "      <td>0.653701</td>\n",
       "      <td>0.116760</td>\n",
       "      <td>2.371741</td>\n",
       "      <td>0.350227</td>\n",
       "      <td>-0.105625</td>\n",
       "      <td>-2.684684</td>\n",
       "      <td>0.362394</td>\n",
       "      <td>0.224631</td>\n",
       "      <td>-0.483569</td>\n",
       "      <td>3.346229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.174806</td>\n",
       "      <td>-0.231514</td>\n",
       "      <td>-0.408073</td>\n",
       "      <td>-0.620177</td>\n",
       "      <td>0.326987</td>\n",
       "      <td>-0.316636</td>\n",
       "      <td>-1.566828</td>\n",
       "      <td>-0.924376</td>\n",
       "      <td>-0.802616</td>\n",
       "      <td>0.570587</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>-0.615597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.734757</td>\n",
       "      <td>-0.019290</td>\n",
       "      <td>-1.589464</td>\n",
       "      <td>0.786915</td>\n",
       "      <td>0.188284</td>\n",
       "      <td>1.379813</td>\n",
       "      <td>-1.282396</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>-0.042861</td>\n",
       "      <td>0.826787</td>\n",
       "      <td>0.598042</td>\n",
       "      <td>3.973727</td>\n",
       "      <td>-1.264901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-1.062561</td>\n",
       "      <td>0.175754</td>\n",
       "      <td>-0.150195</td>\n",
       "      <td>1.450560</td>\n",
       "      <td>0.300127</td>\n",
       "      <td>-0.997197</td>\n",
       "      <td>-1.044866</td>\n",
       "      <td>1.169793</td>\n",
       "      <td>0.471431</td>\n",
       "      <td>-1.895855</td>\n",
       "      <td>0.366942</td>\n",
       "      <td>-0.492975</td>\n",
       "      <td>-0.593682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.077830</td>\n",
       "      <td>-0.320047</td>\n",
       "      <td>0.419044</td>\n",
       "      <td>-1.408831</td>\n",
       "      <td>-0.406938</td>\n",
       "      <td>0.525774</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>-0.651299</td>\n",
       "      <td>-0.127834</td>\n",
       "      <td>-0.059416</td>\n",
       "      <td>-0.119636</td>\n",
       "      <td>-0.087696</td>\n",
       "      <td>-1.513201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.424047</td>\n",
       "      <td>-1.335482</td>\n",
       "      <td>-0.047273</td>\n",
       "      <td>-0.052808</td>\n",
       "      <td>-0.885869</td>\n",
       "      <td>-0.821740</td>\n",
       "      <td>-0.321385</td>\n",
       "      <td>0.994797</td>\n",
       "      <td>0.244490</td>\n",
       "      <td>0.392686</td>\n",
       "      <td>-0.244980</td>\n",
       "      <td>4.024945</td>\n",
       "      <td>2.431384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1.426656</td>\n",
       "      <td>-1.357723</td>\n",
       "      <td>-0.304057</td>\n",
       "      <td>0.266019</td>\n",
       "      <td>-0.286396</td>\n",
       "      <td>0.040887</td>\n",
       "      <td>-0.919443</td>\n",
       "      <td>0.784602</td>\n",
       "      <td>-0.134163</td>\n",
       "      <td>-0.228937</td>\n",
       "      <td>0.448984</td>\n",
       "      <td>-0.348608</td>\n",
       "      <td>0.212757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.421858</td>\n",
       "      <td>0.103611</td>\n",
       "      <td>-0.205606</td>\n",
       "      <td>0.990012</td>\n",
       "      <td>-0.147521</td>\n",
       "      <td>-0.228645</td>\n",
       "      <td>-1.006426</td>\n",
       "      <td>-0.215783</td>\n",
       "      <td>1.153468</td>\n",
       "      <td>2.968010</td>\n",
       "      <td>1.083063</td>\n",
       "      <td>-0.241957</td>\n",
       "      <td>-0.681613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.791279</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.351439</td>\n",
       "      <td>1.390501</td>\n",
       "      <td>-0.051356</td>\n",
       "      <td>0.442421</td>\n",
       "      <td>1.300206</td>\n",
       "      <td>1.631244</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>-0.233673</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>-0.520131</td>\n",
       "      <td>-1.751054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>1.525218</td>\n",
       "      <td>-0.541349</td>\n",
       "      <td>0.094171</td>\n",
       "      <td>-0.153951</td>\n",
       "      <td>4.182298</td>\n",
       "      <td>0.944707</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>-0.510013</td>\n",
       "      <td>-0.382875</td>\n",
       "      <td>-0.328020</td>\n",
       "      <td>-0.053195</td>\n",
       "      <td>0.050772</td>\n",
       "      <td>0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.400854</td>\n",
       "      <td>-0.247820</td>\n",
       "      <td>1.234477</td>\n",
       "      <td>-1.592875</td>\n",
       "      <td>-0.061667</td>\n",
       "      <td>0.427942</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>-0.932233</td>\n",
       "      <td>0.208401</td>\n",
       "      <td>0.497495</td>\n",
       "      <td>0.460779</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>-0.304442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.944012</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>-0.494481</td>\n",
       "      <td>-0.667725</td>\n",
       "      <td>0.048722</td>\n",
       "      <td>-1.041966</td>\n",
       "      <td>0.612755</td>\n",
       "      <td>-0.188151</td>\n",
       "      <td>0.285467</td>\n",
       "      <td>0.888652</td>\n",
       "      <td>-0.951077</td>\n",
       "      <td>-0.418927</td>\n",
       "      <td>-0.168896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -1.218296  0.336704 -0.426186 -0.886752  0.380047 -1.187510 -0.391259   \n",
       "1    1.410900 -1.292493  1.055464 -1.463581 -0.607597 -0.256340  0.067925   \n",
       "2   -0.551091  0.086810 -1.064214  0.249742 -0.056779 -0.404564 -0.352776   \n",
       "3   -0.580706  0.126584  1.007146 -2.389351  0.140114 -0.508026  0.103962   \n",
       "4   -0.115420 -0.424497 -0.599070 -0.126995 -0.378454  0.132858 -0.435759   \n",
       "5   -0.568687 -0.017722 -0.741355 -0.158364  0.000028 -0.930286 -0.793835   \n",
       "6   -0.447170  0.045592  2.683609  1.917981 -0.119569  0.329389 -0.053554   \n",
       "7   -0.967308  0.106104  1.077655 -1.022205  0.391836  0.588200 -0.112093   \n",
       "8    1.446440 -1.186458 -0.223272  0.184505 -0.011630 -0.288014 -0.546646   \n",
       "9   -0.743204 -0.016091 -1.406325  0.539970  0.063506  0.855115 -0.100882   \n",
       "10   0.011236 -0.053868 -1.128775  0.598142 -0.700726 -0.792189  2.491377   \n",
       "11  -0.109496 -0.463290  3.319455  2.483666 -0.436228  0.296471  0.442018   \n",
       "12  -0.563461  0.004313 -0.916949  0.047773  0.015107  0.193161 -0.672598   \n",
       "13  -1.227955  0.397238 -1.018147 -0.282160  0.326452  2.019800  2.784529   \n",
       "14  -1.184482  0.636922 -1.831814  0.768341  0.404875  3.168186  1.429387   \n",
       "15  -0.770244 -0.004625 -0.887590 -0.119189 -0.104687 -0.106483  0.990349   \n",
       "16  -1.049209  0.245458 -0.191747  0.451898  0.354904  0.686849 -0.510539   \n",
       "17  -0.686215 -0.075888  1.192591  1.485459  0.039956 -0.011337 -0.086963   \n",
       "18  -0.784367  0.049567 -0.780065 -0.207366 -0.016780 -0.963678 -0.534382   \n",
       "19  -0.717640 -0.008363  0.989287 -2.451317  0.204783  0.077713  0.384208   \n",
       "20  -0.624073  0.068307  0.862734  0.160763  0.031376 -0.234554 -0.241636   \n",
       "21  -0.715731 -0.050616  0.572144 -1.919670  0.174060 -0.069824  0.208287   \n",
       "22   1.421298 -1.406029 -0.310320  0.269410  0.025199  0.218211 -0.958624   \n",
       "23   0.115556 -0.540635 -0.533333 -0.074706 -0.683186 -0.629395  0.157352   \n",
       "24  -0.810639  0.069947 -0.996857  1.638662  0.107503 -0.951199 -0.879962   \n",
       "25  -0.105027 -0.365970  1.965839  0.244274 -0.438936 -0.648371  0.423267   \n",
       "26  -0.572685 -0.102770  2.236526  2.417969 -0.146365  0.462122  0.541046   \n",
       "27  -0.492915 -0.203387  1.777558 -1.572743  0.071259 -0.118156  0.251742   \n",
       "28   1.452100 -1.043974  0.526998 -0.762193  0.790775  0.227564 -0.189807   \n",
       "29  -0.751558  0.126659  0.426210 -1.772618  0.183135  0.663843  0.573432   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "324 -0.341859  1.772573 -1.265405  0.645878 -0.069995  0.509438 -1.132676   \n",
       "325 -0.826799  0.112487  0.247452  0.055284  0.105849 -1.312153  0.193734   \n",
       "326 -0.641654 -0.038538 -0.551487 -0.429577 -0.006266 -0.734961 -0.838139   \n",
       "327  0.027163  0.079148 -1.116960  0.596164 -0.749896 -0.961395  2.613610   \n",
       "328 -0.813866  0.015304  1.064336 -0.424341  0.102291  0.844122  1.986576   \n",
       "329 -0.921492  0.112342 -0.365070 -0.821385  0.201869 -0.452206 -0.469554   \n",
       "330  1.991131  3.384534  0.421641 -0.237522 -1.409536 -0.691933 -0.216972   \n",
       "331 -0.569081 -0.093427 -1.287219  0.513402 -0.005301  0.189279 -0.924604   \n",
       "332  1.423465 -1.404566 -0.327444  0.281870  1.136365  1.723241 -1.725096   \n",
       "333  0.356470  1.123745 -0.933219  0.525810 -0.889419  0.999575  1.884598   \n",
       "334 -0.824148  0.085650 -0.076755  0.455379  0.246723 -0.323226 -0.679215   \n",
       "335 -0.127880 -0.422532  0.152169 -1.090901 -0.301478  0.352250 -0.072848   \n",
       "336 -0.146226 -0.384283 -0.986603  0.347412 -0.335649  0.549421 -1.125597   \n",
       "337  1.472153 -0.972228 -0.133663  0.082710  0.740923  0.531293 -0.840607   \n",
       "338 -0.456135 -0.040692  2.599987  2.013634 -0.074048  0.699033 -0.367732   \n",
       "339  0.199952  1.533377 -0.834032  0.360015 -0.631507 -0.470706  2.482422   \n",
       "340 -0.133477 -0.373511  0.864971 -2.012486 -0.053010  1.852188 -0.642114   \n",
       "341  0.195446  0.093291 -0.674742  0.154730 -0.674479  0.050682 -0.423200   \n",
       "342 -0.035970 -0.467859 -1.224252  0.653701  0.116760  2.371741  0.350227   \n",
       "343  0.197936  0.174806 -0.231514 -0.408073 -0.620177  0.326987 -0.316636   \n",
       "344 -0.734757 -0.019290 -1.589464  0.786915  0.188284  1.379813 -1.282396   \n",
       "345 -1.062561  0.175754 -0.150195  1.450560  0.300127 -0.997197 -1.044866   \n",
       "346 -0.077830 -0.320047  0.419044 -1.408831 -0.406938  0.525774  0.850306   \n",
       "347  1.424047 -1.335482 -0.047273 -0.052808 -0.885869 -0.821740 -0.321385   \n",
       "348  1.426656 -1.357723 -0.304057  0.266019 -0.286396  0.040887 -0.919443   \n",
       "349 -0.421858  0.103611 -0.205606  0.990012 -0.147521 -0.228645 -1.006426   \n",
       "350 -0.791279  0.004316 -0.351439  1.390501 -0.051356  0.442421  1.300206   \n",
       "351  1.525218 -0.541349  0.094171 -0.153951  4.182298  0.944707  0.100574   \n",
       "352 -0.400854 -0.247820  1.234477 -1.592875 -0.061667  0.427942  0.017642   \n",
       "353 -0.944012  0.158801 -0.494481 -0.667725  0.048722 -1.041966  0.612755   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0    0.125752 -0.172811 -1.267331 -1.771462 -0.501306  0.296134  \n",
       "1    1.176856 -0.012022  0.035788  0.513550 -0.220818 -0.498881  \n",
       "2   -0.668523  1.635779  0.115754 -0.914374 -0.289210  0.679937  \n",
       "3    0.610198 -0.978994 -1.487230 -1.857298 -0.362586  0.584306  \n",
       "4   -0.986912 -0.006150 -1.001963  0.307408 -0.171837  0.416459  \n",
       "5    0.195159 -0.394252  0.754895 -0.054449  3.939962 -0.256343  \n",
       "6   -0.408277  3.289767  0.921860  0.607383  0.310273  1.934371  \n",
       "7    0.631071 -0.554251  1.049112  0.595754 -0.264482  0.098367  \n",
       "8    0.685738  0.060267  0.240304 -0.260171 -0.345022 -0.977767  \n",
       "9    1.019661 -1.045355  0.728018  0.269853  3.768397 -0.865074  \n",
       "10   0.052045 -1.475142  0.964716  0.580170 -0.526890  3.695478  \n",
       "11  -1.359378  0.125921 -1.069896 -0.435476  0.335398  0.233901  \n",
       "12  -0.635800  1.411689 -0.034218  0.026586 -0.222119  0.644681  \n",
       "13   3.627855  0.834177 -0.305158  0.030605 -0.827660 -0.294085  \n",
       "14   3.382434  0.488574 -0.065362 -0.991493 -0.928332 -0.957187  \n",
       "15  -0.165131  1.597335 -1.654309  0.477349 -0.238305  0.806332  \n",
       "16   0.647583  0.264772 -0.954217  0.657336  4.091099 -0.468007  \n",
       "17   0.760112 -0.009755  1.270550  0.603574 -0.282384 -0.934310  \n",
       "18  -1.264696 -0.251943 -0.784355  0.594379 -0.225215 -0.516801  \n",
       "19   0.270853  0.533549 -0.278017 -0.256943 -0.159516  1.272878  \n",
       "20   0.243423 -0.493480  0.820438 -0.000126 -0.280933 -0.702675  \n",
       "21   0.176057  0.658007  0.088739 -0.017581 -0.200698  0.979237  \n",
       "22   0.714248 -0.279995 -0.538967 -1.754797 -0.429055 -0.052801  \n",
       "23  -1.539723 -0.511106 -0.225811  0.887479 -0.116359 -0.620534  \n",
       "24  -0.084254 -2.660340 -0.417255 -0.456178 -0.660758  0.809331  \n",
       "25  -1.329676 -1.265713  0.452782 -0.624106  0.027833 -0.248861  \n",
       "26  -0.676499  0.307313  1.529051  0.819056  0.106207 -0.124282  \n",
       "27   0.267120  0.826970  2.020085 -3.937981 -0.269015  1.479730  \n",
       "28   0.613298 -0.103903  0.294610 -0.112098 -0.186023 -0.970029  \n",
       "29   0.576692 -0.106322 -0.719618 -0.340360 -0.287602  0.048091  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "324 -0.942075  1.348960 -0.156008 -0.450447 -0.167151  0.098929  \n",
       "325  0.206861 -2.599742 -0.679201 -0.256533 -0.516969  0.534755  \n",
       "326 -0.706664 -1.151996 -0.788001  1.688322 -0.269644 -0.713522  \n",
       "327  0.045463 -1.388278  1.004437  1.593126 -0.459578 -1.373151  \n",
       "328  1.953437  0.265062 -1.395970  0.522529 -0.342571 -0.815108  \n",
       "329 -0.391193  0.071180 -0.702808  0.813267 -0.251879 -0.768778  \n",
       "330  0.564823  0.417845  0.566093  0.646313 -0.044244 -0.164187  \n",
       "331 -0.714949  1.490871  0.395190  0.041914 -0.270665  0.437375  \n",
       "332  0.398486 -0.753861 -0.512377  0.023830 -0.252973  0.189492  \n",
       "333 -0.494448  1.574206 -0.295988  0.026064 -0.094441  0.154127  \n",
       "334  0.111718 -2.984972 -1.232753  2.838079 -0.386188  1.017576  \n",
       "335 -0.811853 -0.211932 -1.731636  0.992609 -0.048400  0.811001  \n",
       "336 -1.430948  0.742985 -1.589639  0.149407 -0.093774 -0.686834  \n",
       "337  0.493511 -0.384282 -0.656741 -1.713876 -0.325242 -0.006139  \n",
       "338 -0.427186  3.169238  0.951461  0.845506  0.314297  1.829259  \n",
       "339 -0.134929 -1.467272  1.261561  1.124268 -0.344816 -1.194008  \n",
       "340 -0.699432 -0.825240 -2.137400  0.036622  0.021078  1.373298  \n",
       "341 -1.656176 -0.758245 -0.422877  0.556423 -0.095854 -0.889029  \n",
       "342 -0.105625 -2.684684  0.362394  0.224631 -0.483569  3.346229  \n",
       "343 -1.566828 -0.924376 -0.802616  0.570587 -0.034229 -0.615597  \n",
       "344  0.086254 -0.042861  0.826787  0.598042  3.973727 -1.264901  \n",
       "345  1.169793  0.471431 -1.895855  0.366942 -0.492975 -0.593682  \n",
       "346 -0.651299 -0.127834 -0.059416 -0.119636 -0.087696 -1.513201  \n",
       "347  0.994797  0.244490  0.392686 -0.244980  4.024945  2.431384  \n",
       "348  0.784602 -0.134163 -0.228937  0.448984 -0.348608  0.212757  \n",
       "349 -0.215783  1.153468  2.968010  1.083063 -0.241957 -0.681613  \n",
       "350  1.631244  0.628999 -0.233673  0.390213 -0.520131 -1.751054  \n",
       "351 -0.510013 -0.382875 -0.328020 -0.053195  0.050772  0.416897  \n",
       "352 -0.932233  0.208401  0.497495  0.460779  0.066186 -0.304442  \n",
       "353 -0.188151  0.285467  0.888652 -0.951077 -0.418927 -0.168896  \n",
       "\n",
       "[354 rows x 13 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = dec.PCA(n_components=13, whiten=True)\n",
    "pca.fit(x_train)\n",
    "x_train_white = pd.DataFrame(pca.transform(x_train), columns=x.columns)\n",
    "x_train_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"tanh\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_logarithmic_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 4.3484\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 3.4010\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 2.8549\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 2.4541\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 2.1995\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.9771\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.8088\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.6647\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.5421\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.4340\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.3377\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 1.2505\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 1.1681\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.0879\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 1.0202\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.9615\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.9087\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.8604\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.8162\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.7751\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.7374\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.7028\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.6706\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.6408\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.6130\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.5870\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.5623\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5389\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.5129\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4874\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.4662\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.4477\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.4308\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.4147\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.3998\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3858\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.3725\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.3600\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.3479\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 429us/step - loss: 0.3357\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3235\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.3124\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.3026\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2937\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.2845\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2734\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2658\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2587\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.2520\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.2455\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.2395\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.2338\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.2282\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.2230\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.2180\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2133\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2088\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2045\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.2005\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1967\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1930\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1895\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1862\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1831\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1801\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1772\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1746\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1717\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1690\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1671\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1647\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1623\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1603\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1584\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1565\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1557\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1539\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1517\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 0.1453\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 0.1437\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1415\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1398\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1383\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1368\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1355\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1342\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1331\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1326\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1314\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1303\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1293\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1279\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1270\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 0.1262\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1255\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1248\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 282us/step - loss: 0.1241\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1235\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 0.1228\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 0.1223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x35724978>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20., 21., 21., 11., 21., 18., 21., 11., 21., 11., 18., 18., 21.,\n",
       "        18., 21., 21., 21., 18., 21., 21., 19., 18., 21., 21., 20., 18.,\n",
       "        11., 11., 18., 11., 21., 21., 21., 16., 21., 21., 21., 21., 21.,\n",
       "        21., 21., 18., 21., 21., 21., 21., 18., 18., 20., 18., 21., 15.,\n",
       "        21., 21., 21., 21., 21., 21., 11., 21., 21., 21., 21., 21., 21.,\n",
       "        21., 21., 21., 21., 20., 21., 21., 11., 21., 21., 21., 13., 21.,\n",
       "        21., 21., 21., 21., 21., 18., 18., 21., 21., 21., 21., 18., 21.,\n",
       "        21., 21., 18., 21., 21., 11., 21., 21., 21., 21., 21., 17., 11.,\n",
       "        19., 21., 21., 11., 21., 20., 21., 21., 21., 15., 21., 21., 18.,\n",
       "        21., 21., 21., 21., 21., 18., 21., 21., 21., 18., 21., 18., 21.,\n",
       "        13.,  8., 21., 11., 21., 18., 21., 21., 21., 21., 21., 18., 21.,\n",
       "        21., 21., 21., 18., 21., 21., 11., 11., 21.]], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(x_test).round().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerardh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.8, 41.7, 44. ,  8.3, 24.3, 50. , 15.2, 14.9, 21.7, 23.1, 17.8,\n",
       "        5. , 37.3, 14.2, 18.5, 29. , 23.6, 20.2, 19.3, 23.1, 22.6, 16.8,\n",
       "       50. , 23.7, 23. , 13.8, 11.7,  9.6, 10.5, 13.4, 22.1, 22.9, 16.5,\n",
       "       21.9, 31.6, 30.1, 21.7, 26.6, 20. , 50. , 19.4, 10.5, 23.6, 23.8,\n",
       "       16.2, 20.3, 17.1, 12.5, 22.7, 12.1, 18.9, 13.8, 24.8, 26.6, 18.5,\n",
       "       22.7, 16.5, 36.2, 10.4, 23.3, 29. , 19.9, 18.9, 50. , 30.5, 32.9,\n",
       "       31.1, 32.2, 26.4, 23.2, 21.7, 33. , 15.6, 36. , 50. , 19.8, 14.9,\n",
       "       34.6, 24.8, 33.2, 20.5, 21. , 21. , 17.8, 23.8, 20.1, 19.4, 24.7,\n",
       "       22.4, 11.3, 23.7, 18.8, 19.8, 18.4, 33.3, 23.1, 14.3, 15.3, 24.4,\n",
       "       23.2, 24.7, 14.6, 19.9, 14.1, 20. , 17.1, 23.9, 17.9, 27.9, 21.2,\n",
       "       28.5, 23.4, 13.4, 15.6, 29.8, 20.3, 15.1, 23.9, 20.5, 21.7, 18.3,\n",
       "       21.2, 23.2, 25. , 18.5, 21.4, 23.8, 14.8,  7.4, 23.1, 20.8, 15. ,\n",
       "       18. , 14.5, 45.4, 20.1, 23.1, 30.1, 24.1, 22. , 30.3, 19.1, 32.4,\n",
       "       11.8, 31.7, 24.1, 12.3, 19.7, 50. , 11.8, 10.9, 27. ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.as_matrix().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11386810164702565"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = kr.models.Sequential()\n",
    "\n",
    "m.add(kr.layers.Dense(20, input_dim=13, activation=\"relu\"))\n",
    "m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "#m.add(kr.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "m.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 3102.2132\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 993.0403\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 374.3282\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 195.4777\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 129.5303\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 99.3957\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 85.4008\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 73.8823\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 69.9708\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 65.0123\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 62.5461\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 60.3031\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 367us/step - loss: 64.1011\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 339us/step - loss: 57.8454\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 58.1741\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 52.6549\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 51.5852\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 50.5356\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 50.0977\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 48.3253\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 49.4559\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 48.9580\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 52.7720\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 45.4929\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 48.4648\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 43.5714\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 45.3250\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 41.5690\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 40.5740\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 43.1106\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 41.4821\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 42.2360\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 41.5447\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 39.3674\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 40.0901\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 38.9783\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 39.4601\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 39.5015\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.7724\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 38.2053\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 38.4948\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 37.3343\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 36.3288\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 36.3162\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 39.6791\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 35.1875\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 39.5861\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.4941\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 36.4210\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 36.7212\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 35.1622\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.1813\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 34.4924\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 35.2851\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 35.2500\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 33.6159\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 37.4141\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 35.7846\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 36.0662\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 38.6461\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 33.9628\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 34.1477\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 37.5841\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 40.3144\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 35.8581\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 35.1289\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 31.3781\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 33.4781\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 32.4807\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 37.9474\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 35.3194\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 33.4927\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 33.0104\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 32.0809\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 311us/step - loss: 31.6305\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 38.2486\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 34.0671\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 35.2575\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 31.1024\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 34.3259\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 34.3005\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 39.4899\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 35.9820\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 30.4171\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 32.2910\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 34.6116\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 34.0847\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 33.5446\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 34.5808\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 34.7983\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 32.9827\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 27.68 - 0s 282us/step - loss: 30.3862\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 30.6633\n",
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 37.0574\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 282us/step - loss: 33.5949\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 311us/step - loss: 37.3281\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 32.3253\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 30.1713\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 254us/step - loss: 32.0090\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - 0s 226us/step - loss: 30.6360\n",
      "dict_keys(['loss'])\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(x_train, y_train, epochs=100, batch_size=10)\n",
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
